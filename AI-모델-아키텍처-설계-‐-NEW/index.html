
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://zoro0rkd.github.io/AI-%EB%AA%A8%EB%8D%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%84%A4%EA%B3%84-%E2%80%90-NEW/">
      
      
        <link rel="prev" href="../Index/">
      
      
        <link rel="next" href="../AI-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%EA%B3%BC-%ED%8F%89%EA%B0%80-%E2%80%90-NEW/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.17">
    
    
      
        <title>ì•„í‚¤í…ì²˜ ì„¤ê³„ - Sang-ik Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Sang-ik Notes" class="md-header__button md-logo" aria-label="Sang-ik Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sang-ik Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ì•„í‚¤í…ì²˜ ì„¤ê³„
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Sang-ik Notes" class="md-nav__button md-logo" aria-label="Sang-ik Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Sang-ik Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../Index/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    í™ˆ
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI ëª¨ë¸ ê°œë°œ
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI ëª¨ë¸ ê°œë°œ
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    ì•„í‚¤í…ì²˜ ì„¤ê³„
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    ì•„í‚¤í…ì²˜ ì„¤ê³„
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. ëª¨ë¸ ì„¤ê³„ ê°œìš”
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. ëª¨ë¸ ì„¤ê³„ ê°œìš”">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-ai" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 ì„¤ê³„ ì‹œ ê³ ë ¤ ìš”ì†Œ (ì„±ëŠ¥, íš¨ìœ¨ì„±, í™•ì¥ì„±)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 ìµœì‹  ë™í–¥ ë° ë°œì „ ë°©í–¥
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. ì£¼ìš” ì•„í‚¤í…ì²˜ ê°œë…
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. ì£¼ìš” ì•„í‚¤í…ì²˜ ê°œë…">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-residual-block-skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Residual Block &amp; Skip Connection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Transformer ê¸°ë³¸ êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2 Transformer ê¸°ë³¸ êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      ì£¼ìš” êµ¬ì„± ìš”ì†Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      ì „ì²´ êµ¬ì¡° ìš”ì•½
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      ì°¸ê³ 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      Attention êµ¬ì¡°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-family-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Family Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert-family" class="md-nav__link">
    <span class="md-ellipsis">
      BERT Family
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 CNNê³¼ ë³€í˜• êµ¬ì¡°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 ìˆœí™˜ ì‹ ê²½ë§ ê³„ì—´
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.4 ìˆœí™˜ ì‹ ê²½ë§ ê³„ì—´">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn-lstm-gru" class="md-nav__link">
    <span class="md-ellipsis">
      RNN / LSTM / GRU
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.5 ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3d-cnn-convlstm" class="md-nav__link">
    <span class="md-ellipsis">
      3D CNN, ConvLSTM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. ìë™í™”ëœ ì•„í‚¤í…ì²˜ íƒìƒ‰
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. ìë™í™”ëœ ì•„í‚¤í…ì²˜ íƒìƒ‰">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-nas-neural-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 NAS (Neural Architecture Search)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 NAS (Neural Architecture Search)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nas" class="md-nav__link">
    <span class="md-ellipsis">
      NASë€ ë¬´ì—‡ì¸ê°€?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_1" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ í•µì‹¬ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_2" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ì¥ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_3" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ë„ì „ê³¼ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas-automl" class="md-nav__link">
    <span class="md-ellipsis">
      NASì™€ AutoMLì˜ ì°¨ì´
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_4" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ë¯¸ë˜ì™€ í™œìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-darts-differentiable-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 DARTS (Differentiable Architecture Search)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 DARTS (Differentiable Architecture Search)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-llm" class="md-nav__link">
    <span class="md-ellipsis">
      4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•„í‚¤í…ì²˜
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•„í‚¤í…ì²˜">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    <span class="md-ellipsis">
      1. êµ¬ì¡°ì™€ ì•„í‚¤í…ì²˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    <span class="md-ellipsis">
      2. í•™ìŠµ ë°©ì‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŠœë‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      4. í† í°í™”(Tokenization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      ìš©ì–´ ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. íŒŒì¸íŠœë‹ ì „ëµ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. íŒŒì¸íŠœë‹ ì „ëµ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-lora-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 LoRA (Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-instruction-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Instruction Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 Instruction Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_2" class="md-nav__link">
    <span class="md-ellipsis">
      1. ê°œë… ë° ëª©ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    <span class="md-ellipsis">
      2. ê¸°ì¡´ íŒŒì¸íŠœë‹ê³¼ì˜ ì°¨ì´ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    <span class="md-ellipsis">
      3. ë°ì´í„°ì…‹ êµ¬ì„±ê³¼ í•™ìŠµ ë°©ì‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. íš¨ê³¼ì™€ íŠ¹ì§•
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    <span class="md-ellipsis">
      5. ì‹¤ì œ ì ìš© ì˜ˆì‹œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. í•œê³„ì™€ ê³¼ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-supervised-fine-tuning-vs-instruction-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Supervised Fine-Tuning vs Instruction Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 Supervised Fine-Tuning vs Instruction Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      ë°ì´í„° êµ¬ì¡° ì°¨ì´
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      ëª©í‘œ ì°¨ì´
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      6. ìê¸°ì§€ë„ í•™ìŠµ(Self-Supervised Learning) êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. ìê¸°ì§€ë„ í•™ìŠµ(Self-Supervised Learning) êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#byol" class="md-nav__link">
    <span class="md-ellipsis">
      BYOL
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jigsaw-puzzle" class="md-nav__link">
    <span class="md-ellipsis">
      jigsaw puzzle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maemasked-auto-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      MAE(masked auto encoder)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rotnet" class="md-nav__link">
    <span class="md-ellipsis">
      RotNet
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      7. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) ê°œë…
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµì˜ ëŒ€í‘œì  ì˜ˆì‹œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      ì‹¤ì œ í™œìš© ì‚¬ë¡€
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµì˜ íŠ¹ì§•
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8. ì˜ìƒ ì²˜ë¦¬ìš© ì•„í‚¤í…ì²˜
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. ì˜ìƒ ì²˜ë¦¬ìš© ì•„í‚¤í…ì²˜">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cnn-convolutional-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      1ï¸âƒ£ CNN (Convolutional Neural Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-3d-cnn-c3d-convolutional-3d-networks" class="md-nav__link">
    <span class="md-ellipsis">
      2ï¸âƒ£ 3D CNN / C3D (Convolutional 3D Networks)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-convlstm-convolutional-long-short-term-memory" class="md-nav__link">
    <span class="md-ellipsis">
      3ï¸âƒ£ ConvLSTM (Convolutional Long Short-Term Memory)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-two-stream-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      4ï¸âƒ£ Two-Stream CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-i3d-inflated-3d-convnet" class="md-nav__link">
    <span class="md-ellipsis">
      5ï¸âƒ£ I3D (Inflated 3D ConvNet)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-video-transformer-timesformer-vivit" class="md-nav__link">
    <span class="md-ellipsis">
      6ï¸âƒ£ Video Transformer (TimeSformer, ViViT ë“±)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7-slowfast-networks" class="md-nav__link">
    <span class="md-ellipsis">
      7ï¸âƒ£ SlowFast Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§­ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ëª¨ë¸ ìš”ì•½
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”— ì°¸ê³  ë¬¸í—Œ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9" class="md-nav__link">
    <span class="md-ellipsis">
      9. ì•™ìƒë¸” êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. ì•™ìƒë¸” êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      1. ë°°ê¹…(Bagging): ë¶„ì‚° ê°ì†Œ ì¤‘ì‹¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      2. ë¶€ìŠ¤íŒ…(Boosting): í¸í–¥ ê°ì†Œ ì¤‘ì‹¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      3. ìŠ¤íƒœí‚¹(Stacking): ë¹„ì„ í˜• ì¡°í•©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„êµ í‘œ: ì•™ìƒë¸” ê¸°ë²• íŠ¹ì„±
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10" class="md-nav__link">
    <span class="md-ellipsis">
      10. ëª¨ë¸ ì„±ëŠ¥ ë° ê³¼ì í•©/ê³¼ì†Œì í•©
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      11. ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ê³ ë ¤
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ê³ ë ¤">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#oom-out-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      OOM (Out-Of-Memory)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OOM (Out-Of-Memory)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#oomout-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      OOM(Out Of Memory)ë€?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-oomout-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA OOM(Out Of Memory) ì™„í™” ë°©ë²•
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA OOM(Out Of Memory) ì™„í™” ë°©ë²•">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      1. ë°°ì¹˜ í¬ê¸°(batch size) ì¤„ì´ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_3" class="md-nav__link">
    <span class="md-ellipsis">
      2. ëª¨ë¸ í¬ê¸° ì¶•ì†Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      3. í˜¼í•© ì •ë°€ë„ í•™ìŠµ(Mixed Precision Training)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    <span class="md-ellipsis">
      4. ë¶ˆí•„ìš”í•œ ë³€ìˆ˜/í…ì„œ ì‚­ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_2" class="md-nav__link">
    <span class="md-ellipsis">
      5. ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-torchno_grad-modeleval" class="md-nav__link">
    <span class="md-ellipsis">
      6. torch.no_grad() ë° model.eval() ì‚¬ìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. ì…ë ¥ ë°ì´í„° í¬ê¸°/í•´ìƒë„ ì¤„ì´ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      8. ë°ì´í„° ë¶„í•  ë° DataLoader í™œìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#9_1" class="md-nav__link">
    <span class="md-ellipsis">
      9. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#10-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      10. ë” í° GPUë¡œ ì—…ê·¸ë ˆì´ë“œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      ì°¸ê³ : GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      GPU ë©”ëª¨ë¦¬ ì ˆê° ê¸°ë²•
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12_1" class="md-nav__link">
    <span class="md-ellipsis">
      12. ì¶”ê°€ ê³ ë ¤ ìš”ì†Œ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12. ì¶”ê°€ ê³ ë ¤ ìš”ì†Œ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pruning-quantization-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²• (Pruning, Quantization, Knowledge Distillation)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²• (Pruning, Quantization, Knowledge Distillation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      1. Pruning (ê°€ì§€ì¹˜ê¸°)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      2. Quantization (ì–‘ìí™”)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Knowledge Distillation (ì§€ì‹ ì¦ë¥˜)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ (CNN + Transformer)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-language-audio-text" class="md-nav__link">
    <span class="md-ellipsis">
      ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ ì„¤ê³„ (Vision-Language, Audio-Text)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì™€ êµ¬ì¡° ì„¤ê³„ì˜ ê´€ê³„
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explainability" class="md-nav__link">
    <span class="md-ellipsis">
      ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±(Explainability)ê³¼ ì„¤ê³„
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%EA%B3%BC-%ED%8F%89%EA%B0%80-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    í•™ìŠµê³¼ í‰ê°€
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EC%9C%A0%EC%9A%A9%ED%95%9C-%EC%82%AC%EC%9D%B4%ED%8A%B8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ìœ ìš©í•œ ì‚¬ì´íŠ¸
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. ëª¨ë¸ ì„¤ê³„ ê°œìš”
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. ëª¨ë¸ ì„¤ê³„ ê°œìš”">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-ai" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 ì„¤ê³„ ì‹œ ê³ ë ¤ ìš”ì†Œ (ì„±ëŠ¥, íš¨ìœ¨ì„±, í™•ì¥ì„±)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 ìµœì‹  ë™í–¥ ë° ë°œì „ ë°©í–¥
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. ì£¼ìš” ì•„í‚¤í…ì²˜ ê°œë…
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. ì£¼ìš” ì•„í‚¤í…ì²˜ ê°œë…">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-residual-block-skip-connection" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Residual Block &amp; Skip Connection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Transformer ê¸°ë³¸ êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2 Transformer ê¸°ë³¸ êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      ì£¼ìš” êµ¬ì„± ìš”ì†Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      ì „ì²´ êµ¬ì¡° ìš”ì•½
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      ì°¸ê³ 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      Attention êµ¬ì¡°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer-family-model" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Family Model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bert-family" class="md-nav__link">
    <span class="md-ellipsis">
      BERT Family
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 CNNê³¼ ë³€í˜• êµ¬ì¡°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 ìˆœí™˜ ì‹ ê²½ë§ ê³„ì—´
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.4 ìˆœí™˜ ì‹ ê²½ë§ ê³„ì—´">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rnn-lstm-gru" class="md-nav__link">
    <span class="md-ellipsis">
      RNN / LSTM / GRU
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.5 ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3d-cnn-convlstm" class="md-nav__link">
    <span class="md-ellipsis">
      3D CNN, ConvLSTM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. ìë™í™”ëœ ì•„í‚¤í…ì²˜ íƒìƒ‰
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. ìë™í™”ëœ ì•„í‚¤í…ì²˜ íƒìƒ‰">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-nas-neural-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 NAS (Neural Architecture Search)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 NAS (Neural Architecture Search)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nas" class="md-nav__link">
    <span class="md-ellipsis">
      NASë€ ë¬´ì—‡ì¸ê°€?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_1" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ í•µì‹¬ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_2" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ì¥ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_3" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ë„ì „ê³¼ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas-automl" class="md-nav__link">
    <span class="md-ellipsis">
      NASì™€ AutoMLì˜ ì°¨ì´
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nas_4" class="md-nav__link">
    <span class="md-ellipsis">
      NASì˜ ë¯¸ë˜ì™€ í™œìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-darts-differentiable-architecture-search" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 DARTS (Differentiable Architecture Search)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 DARTS (Differentiable Architecture Search)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-llm" class="md-nav__link">
    <span class="md-ellipsis">
      4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•„í‚¤í…ì²˜
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•„í‚¤í…ì²˜">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    <span class="md-ellipsis">
      1. êµ¬ì¡°ì™€ ì•„í‚¤í…ì²˜
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    <span class="md-ellipsis">
      2. í•™ìŠµ ë°©ì‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŠœë‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      4. í† í°í™”(Tokenization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      ìš©ì–´ ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. íŒŒì¸íŠœë‹ ì „ëµ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. íŒŒì¸íŠœë‹ ì „ëµ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-lora-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 LoRA (Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-instruction-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Instruction Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 Instruction Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_2" class="md-nav__link">
    <span class="md-ellipsis">
      1. ê°œë… ë° ëª©ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    <span class="md-ellipsis">
      2. ê¸°ì¡´ íŒŒì¸íŠœë‹ê³¼ì˜ ì°¨ì´ì 
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    <span class="md-ellipsis">
      3. ë°ì´í„°ì…‹ êµ¬ì„±ê³¼ í•™ìŠµ ë°©ì‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. íš¨ê³¼ì™€ íŠ¹ì§•
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    <span class="md-ellipsis">
      5. ì‹¤ì œ ì ìš© ì˜ˆì‹œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. í•œê³„ì™€ ê³¼ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-supervised-fine-tuning-vs-instruction-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Supervised Fine-Tuning vs Instruction Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 Supervised Fine-Tuning vs Instruction Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      ë°ì´í„° êµ¬ì¡° ì°¨ì´
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      ëª©í‘œ ì°¨ì´
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      6. ìê¸°ì§€ë„ í•™ìŠµ(Self-Supervised Learning) êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. ìê¸°ì§€ë„ í•™ìŠµ(Self-Supervised Learning) êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simclr" class="md-nav__link">
    <span class="md-ellipsis">
      SimCLR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#byol" class="md-nav__link">
    <span class="md-ellipsis">
      BYOL
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jigsaw-puzzle" class="md-nav__link">
    <span class="md-ellipsis">
      jigsaw puzzle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maemasked-auto-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      MAE(masked auto encoder)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rotnet" class="md-nav__link">
    <span class="md-ellipsis">
      RotNet
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      7. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) ê°œë…
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµì˜ ëŒ€í‘œì  ì˜ˆì‹œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      ì‹¤ì œ í™œìš© ì‚¬ë¡€
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„ì§€ë„ í•™ìŠµì˜ íŠ¹ì§•
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8. ì˜ìƒ ì²˜ë¦¬ìš© ì•„í‚¤í…ì²˜
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. ì˜ìƒ ì²˜ë¦¬ìš© ì•„í‚¤í…ì²˜">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cnn-convolutional-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      1ï¸âƒ£ CNN (Convolutional Neural Network)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-3d-cnn-c3d-convolutional-3d-networks" class="md-nav__link">
    <span class="md-ellipsis">
      2ï¸âƒ£ 3D CNN / C3D (Convolutional 3D Networks)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-convlstm-convolutional-long-short-term-memory" class="md-nav__link">
    <span class="md-ellipsis">
      3ï¸âƒ£ ConvLSTM (Convolutional Long Short-Term Memory)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-two-stream-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      4ï¸âƒ£ Two-Stream CNN
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-i3d-inflated-3d-convnet" class="md-nav__link">
    <span class="md-ellipsis">
      5ï¸âƒ£ I3D (Inflated 3D ConvNet)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-video-transformer-timesformer-vivit" class="md-nav__link">
    <span class="md-ellipsis">
      6ï¸âƒ£ Video Transformer (TimeSformer, ViViT ë“±)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7-slowfast-networks" class="md-nav__link">
    <span class="md-ellipsis">
      7ï¸âƒ£ SlowFast Networks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ§­ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ëª¨ë¸ ìš”ì•½
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    <span class="md-ellipsis">
      ğŸ”— ì°¸ê³  ë¬¸í—Œ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9" class="md-nav__link">
    <span class="md-ellipsis">
      9. ì•™ìƒë¸” êµ¬ì¡°
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. ì•™ìƒë¸” êµ¬ì¡°">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-bagging" class="md-nav__link">
    <span class="md-ellipsis">
      1. ë°°ê¹…(Bagging): ë¶„ì‚° ê°ì†Œ ì¤‘ì‹¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-boosting" class="md-nav__link">
    <span class="md-ellipsis">
      2. ë¶€ìŠ¤íŒ…(Boosting): í¸í–¥ ê°ì†Œ ì¤‘ì‹¬
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-stacking" class="md-nav__link">
    <span class="md-ellipsis">
      3. ìŠ¤íƒœí‚¹(Stacking): ë¹„ì„ í˜• ì¡°í•©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    <span class="md-ellipsis">
      ë¹„êµ í‘œ: ì•™ìƒë¸” ê¸°ë²• íŠ¹ì„±
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10" class="md-nav__link">
    <span class="md-ellipsis">
      10. ëª¨ë¸ ì„±ëŠ¥ ë° ê³¼ì í•©/ê³¼ì†Œì í•©
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      11. ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ê³ ë ¤
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ê³ ë ¤">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#oom-out-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      OOM (Out-Of-Memory)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OOM (Out-Of-Memory)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#oomout-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      OOM(Out Of Memory)ë€?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-oomout-of-memory" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA OOM(Out Of Memory) ì™„í™” ë°©ë²•
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA OOM(Out Of Memory) ì™„í™” ë°©ë²•">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      1. ë°°ì¹˜ í¬ê¸°(batch size) ì¤„ì´ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_3" class="md-nav__link">
    <span class="md-ellipsis">
      2. ëª¨ë¸ í¬ê¸° ì¶•ì†Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      3. í˜¼í•© ì •ë°€ë„ í•™ìŠµ(Mixed Precision Training)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    <span class="md-ellipsis">
      4. ë¶ˆí•„ìš”í•œ ë³€ìˆ˜/í…ì„œ ì‚­ì œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_2" class="md-nav__link">
    <span class="md-ellipsis">
      5. ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-torchno_grad-modeleval" class="md-nav__link">
    <span class="md-ellipsis">
      6. torch.no_grad() ë° model.eval() ì‚¬ìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. ì…ë ¥ ë°ì´í„° í¬ê¸°/í•´ìƒë„ ì¤„ì´ê¸°
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      8. ë°ì´í„° ë¶„í•  ë° DataLoader í™œìš©
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#9_1" class="md-nav__link">
    <span class="md-ellipsis">
      9. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#10-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      10. ë” í° GPUë¡œ ì—…ê·¸ë ˆì´ë“œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      ì°¸ê³ : GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" class="md-nav__link">
    <span class="md-ellipsis">
      ìš”ì•½
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      GPU ë©”ëª¨ë¦¬ ì ˆê° ê¸°ë²•
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12_1" class="md-nav__link">
    <span class="md-ellipsis">
      12. ì¶”ê°€ ê³ ë ¤ ìš”ì†Œ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="12. ì¶”ê°€ ê³ ë ¤ ìš”ì†Œ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pruning-quantization-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²• (Pruning, Quantization, Knowledge Distillation)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²• (Pruning, Quantization, Knowledge Distillation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-pruning" class="md-nav__link">
    <span class="md-ellipsis">
      1. Pruning (ê°€ì§€ì¹˜ê¸°)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      2. Quantization (ì–‘ìí™”)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Knowledge Distillation (ì§€ì‹ ì¦ë¥˜)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cnn-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ (CNN + Transformer)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-language-audio-text" class="md-nav__link">
    <span class="md-ellipsis">
      ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ ì„¤ê³„ (Vision-Language, Audio-Text)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" class="md-nav__link">
    <span class="md-ellipsis">
      í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì™€ êµ¬ì¡° ì„¤ê³„ì˜ ê´€ê³„
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#explainability" class="md-nav__link">
    <span class="md-ellipsis">
      ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±(Explainability)ê³¼ ì„¤ê³„
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>ì•„í‚¤í…ì²˜ ì„¤ê³„</h1>

<h2 id="1">1. ëª¨ë¸ ì„¤ê³„ ê°œìš”<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<p>AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ì— ê´€í•œ ê°ê°ì˜ í•­ëª©ì— ëŒ€í•´ ì•„ë˜ì™€ ê°™ì´ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<hr />
<h3 id="11-ai">1.1 AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜<a class="headerlink" href="#11-ai" title="Permanent link">&para;</a></h3>
<p>AI ëª¨ë¸ ì•„í‚¤í…ì²˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ëœ ëª¨ë¸ ë‚´ë¶€ì˜ êµ¬ì¡°ì™€ êµ¬ì„± ìš”ì†Œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì…ë ¥ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ë¡œ ë³€í™˜ë˜ëŠ” ì „ì²´ ê²½ë¡œë¥¼ ì„¤ê³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ì—ëŠ” ë ˆì´ì–´(ì¸µ) êµ¬ì¡°, ì—°ì‚° ë°©ì‹, ë°ì´í„° íë¦„, ê·¸ë¦¬ê³  ê° ê³„ì¸µ ë³„ë¡œ ì–´ë–¤ í•¨ìˆ˜ì™€ ì—°ì‚°ì´ ì ìš©ë˜ëŠ”ì§€ê°€ í¬í•¨ë©ë‹ˆë‹¤. ë¬¸ì œ ìœ í˜•(ë¶„ë¥˜, íšŒê·€, ìƒì„± ë“±)ì— ë”°ë¼ ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ í˜•íƒœê°€ ë‹¬ë¼ì§€ë©°, ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜(ë”¥ëŸ¬ë‹, íŠ¸ëœìŠ¤í¬ë¨¸, CNN ë“±)ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•  ë•ŒëŠ” ë„ë©”ì¸ ì§€ì‹ê³¼ ê²½í—˜, ë°ì´í„°ì˜ íŠ¹ì„±ì— ëŒ€í•œ ì¶©ë¶„í•œ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤[4][5].</p>
<hr />
<h3 id="12">1.2 ì„¤ê³„ ì‹œ ê³ ë ¤ ìš”ì†Œ (ì„±ëŠ¥, íš¨ìœ¨ì„±, í™•ì¥ì„±)<a class="headerlink" href="#12" title="Permanent link">&para;</a></h3>
<p>AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì‹œ í•µì‹¬ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<ul>
<li><strong>ì„±ëŠ¥</strong>: ëª¨ë¸ì´ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“± ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ì˜¤ë²„í”¼íŒ… ë°©ì§€, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ì ì ˆí•œ ëª¨ë¸ ì„ íƒ ë“±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.</li>
<li><strong>íš¨ìœ¨ì„±</strong>: ê³„ì‚° ìì›(ë©”ëª¨ë¦¬, ì—°ì‚° ì†ë„, ì—ë„ˆì§€ íš¨ìœ¨ì„± ë“±)ì„ ìµœì í™”í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ ë°ì´í„°ì™€ ë³µì¡í•œ ì—°ì‚°ì„ ë‹¤ë£¨ê¸° ë•Œë¬¸ì—, ë³‘ë ¬ ì²˜ë¦¬, ìµœì í™”ëœ ì—°ì‚°(ì˜ˆ: GPU ê°€ì†), íŠ¹í™”ëœ í•˜ë“œì›¨ì–´(AI ë°˜ë„ì²´ ì•„í‚¤í…ì²˜ ë“±) í™œìš©ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. íŠ¹íˆ AI ë°˜ë„ì²´ì—ì„œëŠ” ì—°ì‚° ì„±ëŠ¥, ë©”ëª¨ë¦¬ ëŒ€ì—­í­, ì „ë ¥ íš¨ìœ¨ì„±ì˜ ê· í˜•ì´ ì¤‘ìš”í•©ë‹ˆë‹¤[6][7].</li>
<li><strong>í™•ì¥ì„±</strong>: ëª¨ë¸ì´ ë” ë§ì€ ë°ì´í„°, ë” ë³µì¡í•œ ë¬¸ì œ, ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ ìš”êµ¬ì— ë§ì¶° ì‰½ê²Œ í™•ì¥ë  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ëª¨ë“ˆí˜• ì•„í‚¤í…ì²˜, í´ë¼ìš°ë“œ í™˜ê²½, PaaS(Platform as a Service) ê¸°ë°˜ì˜ ìœ ì—°í•œ ì¸í”„ë¼ê°€ í™œìš©ë©ë‹ˆë‹¤. ë°ì´í„°ì„¼í„°ì˜ ëª¨ë“ˆí˜• ì•„í‚¤í…ì²˜, DevOps ê¸°ë°˜ ìš´ì˜, ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ë„ í™•ì¥ì„± ì¸¡ë©´ì—ì„œ ì¤‘ì‹œë©ë‹ˆë‹¤[5][6].</li>
</ul>
<hr />
<h3 id="13">1.3 ìµœì‹  ë™í–¥ ë° ë°œì „ ë°©í–¥<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<p>AI ëª¨ë¸ ì•„í‚¤í…ì²˜ëŠ” ìµœê·¼ ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.</p>
<ul>
<li><strong>ìƒì„±í˜• AI ë° ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜</strong>: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì²˜ë¦¬í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ ê¸‰ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ìƒì„±í˜• AI(Generative AI) ì—­ì‹œ ê¸°ì—… ë¹„ì¦ˆë‹ˆìŠ¤ í˜ì‹ ì˜ í•µì‹¬ ê¸°ìˆ ë¡œ ë¶€ìƒí•˜ê³  ìˆìœ¼ë©°, íŒ¨í„´í™”ëœ ì„¤ê³„ì™€ í”„ë ˆì„ì›Œí¬ ì ìš©ì„ í†µí•œ ëª¨ë¸ êµ¬ì¶•ì´ í™•ì‚° ì¤‘ì…ë‹ˆë‹¤[5][10].</li>
<li><strong>í´ë¼ìš°ë“œ ë° ë¶„ì‚°ì²˜ë¦¬</strong>: AI ì›Œí¬ë¡œë“œê°€ ì ì°¨ í´ë¼ìš°ë“œ ê¸°ë°˜ ì¸í”„ë¼ ë° ë¶„ì‚° í™˜ê²½ìœ¼ë¡œ ì´ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. í´ë¼ìš°ë“œ PaaS, ëª¨ë“ˆí˜• ë°ì´í„°ì„¼í„°, ìë™í™”ëœ ì»´í“¨íŒ… ìì› í• ë‹¹ ë“±ìœ¼ë¡œ ì´ˆê¸° íˆ¬ì ë¹„ìš©ì„ ì¤„ì´ê³  ìœ ì—°ì„±ì„ í™•ë³´í•˜ëŠ” ë°©í–¥ì…ë‹ˆë‹¤[6].</li>
<li><strong>AI í•˜ë“œì›¨ì–´ ì „ë¬¸í™”</strong>: íŠ¹ì • AI ì—°ì‚°ì— íŠ¹í™”ëœ ë°˜ë„ì²´(AI SoC)ì™€ ëŒ€ê·œëª¨ ë³‘ë ¬ ì—°ì‚° êµ¬ì¡°ê°€ ë„ì…ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì—°ì‚° ì†ë„ì™€ ì—ë„ˆì§€ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤[7].</li>
<li><strong>ì—”í„°í”„ë¼ì´ì¦ˆ ì ìš© ê°€ì´ë“œë¼ì¸ í‘œì¤€í™”</strong>: ë°ì´í„° ë° ëª¨ë¸ ì•ˆì „ì„±, ë³´ì•ˆ, ì‹ ë¢°ì„±, ê±°ë²„ë„ŒìŠ¤ë¥¼ í¬ê´„í•œ í‘œì¤€í™”ëœ í”„ë ˆì„ì›Œí¬ì™€ ì•„í‚¤í…ì²˜ íŒ¨í„´ì´ ì£¼ìš” ê¸°ì—…ì—ì„œ ì ê·¹ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤[1][5].</li>
</ul>
<p>ì¶œì²˜
[1] AI ì•„í‚¤í…ì²˜ ë””ìì¸ - Azure Architecture Center https://learn.microsoft.com/ko-kr/azure/architecture/ai-ml/
[2] AI Architecture 1í¸ â€“ ì„¸ìƒì€ ê°œì¸í™” ì¶”ì²œ ì‹œëŒ€ https://tech.osci.kr/ai-architecture/
[3] AI ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„í‚¤í…ì²˜ ì´í•´ https://www.f5.com/ko_kr/company/blog/understanding-ai-application-architecture
[4] AI ëª¨ë¸ ê°œë°œì˜ ê¸°ë³¸ ê°œë…ê³¼ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê°œìš” https://triangular.tistory.com/entry/AI-%EB%AA%A8%EB%8D%B8-%EA%B0%9C%EB%B0%9C%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%A0%84%EC%B2%B4-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B0%9C%EC%9A%94
[5] [Architecture] Generative AI ê¸°ì—… ì•„í‚¤í…ì²˜ ì„¤ê³„ - 42JerryKim https://42jerrykim.github.io/post/2024-08-27-gen-ai-architecture/
[6] AI ì¸í”„ë¼ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ íŠ¹ì§•ê³¼ ìµœì‹  ë™í–¥ - Goover https://seo.goover.ai/report/202505/go-public-report-ko-68e5a512-bf15-4472-a343-4f44e85d9b9f-0-0.html
[7] 2.3 AI ë°˜ë„ì²´ ì•„í‚¤í…ì²˜ ì„¤ê³„ https://wikidocs.net/280862
[8] AI ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì´ì •ë¦¬, 6ë‹¨ê³„ë¡œ ì´ë ‡ê²Œ ì§„í–‰ë©ë‹ˆë‹¤. https://aiheroes.ai/community/192
[9] ì£¼ìš” AI, ML ë° DL ì‚¬ìš© ì‚¬ë¡€ ë° ì•„í‚¤í…ì²˜ https://docs.netapp.com/ko-kr/netapp-solutions/data-analytics/apache-spark-major-ai-ml-and-dl-use-cases-and-architectures.html
[10] 2025ë…„, AI ëŒ€í™ìˆ˜ ì‹œëŒ€: AI ëª¨ë¸ ë° ê°œë°œì‚¬ ì§‘ì¤‘ ë¶„ì„ - ì˜¬ë¦¬ì‚¬ì´íŠ¸ https://ollysite.com/board/read.php?M2_IDX=37272&amp;PAGE=1&amp;B_IDX=149404</p>
<hr />
<h2 id="2">2. ì£¼ìš” ì•„í‚¤í…ì²˜ ê°œë…<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="21-residual-block-skip-connection">2.1 Residual Block &amp; Skip Connection<a class="headerlink" href="#21-residual-block-skip-connection" title="Permanent link">&para;</a></h3>
<p><strong>Residual Block</strong>ê³¼ <strong>Skip Connection</strong>ì€ ë”¥ëŸ¬ë‹, íŠ¹íˆ ResNet(Residual Network)ì—ì„œ ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“  í•µì‹¬ êµ¬ì¡°ì…ë‹ˆë‹¤.</p>
<hr />
<p><strong>Residual Blockì´ë€?</strong></p>
<ul>
<li>Residual Blockì€ ì…ë ¥ê°’ $$ x $$ë¥¼ ì—¬ëŸ¬ ì¸µ(ì˜ˆ: Convolution, BatchNorm, Activation ë“±)ì„ ê±°ì¹œ ê²°ê³¼ $$ F(x) $$ì™€ ë”í•´ì£¼ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.</li>
<li>ìˆ˜ì‹ìœ¼ë¡œëŠ” $$ y = F(x) + x $$ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ $$ F(x) $$ëŠ” ë¸”ë¡ ë‚´ì—ì„œ í•™ìŠµë˜ëŠ” ë³€í™˜ í•¨ìˆ˜ì…ë‹ˆë‹¤[3][5][7].</li>
<li>ì´ êµ¬ì¡°ì˜ í•µì‹¬ì€, ì…ë ¥ê°’ $$ x $$ë¥¼ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë¸”ë¡ì— ë”í•´ì¤Œìœ¼ë¡œì¨, ë„¤íŠ¸ì›Œí¬ê°€ í•™ìŠµí•´ì•¼ í•  ì •ë³´ë¥¼ "ì”ì°¨(residual)"ë¡œ ì œí•œí•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì¦‰, ìƒˆë¡œìš´ ì •ë³´ë¥¼ í•™ìŠµí•˜ëŠ” ëŒ€ì‹  ê¸°ì¡´ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì¶”ê°€ì ì¸ ê²ƒë§Œ í•™ìŠµí•©ë‹ˆë‹¤[3][5][7].</li>
</ul>
<hr />
<p><strong>Skip Connection(ìŠ¤í‚µ ì—°ê²°)ì´ë€?</strong></p>
<ul>
<li>Skip Connectionì€ í•œ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ ê±´ë„ˆë›°ì–´ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ì— ì§ì ‘ ë”í•˜ëŠ” ì—°ê²° ë°©ì‹ì…ë‹ˆë‹¤[1][2][6].</li>
<li>ì´ ë°©ì‹ì€ ì‹ ê²½ë§ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë°œìƒí•˜ëŠ” vanishing gradient(ê¸°ìš¸ê¸° ì†Œì‹¤) ë¬¸ì œë¥¼ ì™„í™”í•˜ê³ , ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë§Œë“­ë‹ˆë‹¤[1][2][4][6].</li>
<li>Skip Connectionì´ ì ìš©ëœ ë¸”ë¡ì„ Residual Blockì´ë¼ê³  ë¶€ë¥´ë©°, ì´ êµ¬ì¡° ë•ë¶„ì— ê° ë ˆì´ì–´ê°€ í•™ìŠµí•´ì•¼ í•  ì •ë³´ëŸ‰ì´ ì¤„ì–´ë“¤ê³ , ê¸°ì¡´ ì •ë³´ë¥¼ ìƒì§€ ì•Šìœ¼ë©´ì„œ ìƒˆë¡œìš´ ì •ë³´ë§Œ ì¶”ê°€ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1][3][5][7].</li>
</ul>
<hr />
<p><strong>ì™œ Residual Blockê³¼ Skip Connectionì´ ì¤‘ìš”í•œê°€?</strong></p>
<ul>
<li>ê¸°ì¡´ì˜ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ëŠ” ë ˆì´ì–´ë¥¼ ë§ì´ ìŒ“ìœ¼ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì£¼ë¡œ gradient vanishing/exploding í˜„ìƒ ë•Œë¬¸ì…ë‹ˆë‹¤[1][2][4][5].</li>
<li>Residual Blockê³¼ Skip Connectionì„ ë„ì…í•˜ë©´, ì…ë ¥ê°’ì´ ì§ì ‘ ì¶œë ¥ë‹¨ê¹Œì§€ ì „ë‹¬ë  ìˆ˜ ìˆì–´, ì—­ì „íŒŒ ì‹œì—ë„ gradientê°€ ì›í™œí•˜ê²Œ íë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤[6].</li>
<li>ì´ë¡œ ì¸í•´ í›¨ì”¬ ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬(ì˜ˆ: 100ì¸µ ì´ìƒ)ë„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆê³ , ì‹¤ì œë¡œ ResNetì€ 150ì¸µì´ ë„˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤[1][4][5].</li>
</ul>
<hr />
<p><strong>ìš”ì•½</strong></p>
<ul>
<li><strong>Residual Block</strong>: ì…ë ¥ê°’ì„ ì—¬ëŸ¬ ì¸µì„ ê±°ì¹œ ê²°ê³¼ì™€ ë”í•˜ëŠ” êµ¬ì¡°. ìˆ˜ì‹: $$ y = F(x) + x $$[3][5][7].</li>
<li><strong>Skip Connection</strong>: ì…ë ¥ê°’ì„ ì—¬ëŸ¬ ì¸µì„ ê±´ë„ˆë›°ì–´ ë‹¤ìŒ ë ˆì´ì–´ì— ì§ì ‘ ë”í•˜ëŠ” ì—°ê²° ë°©ì‹[1][2][6].</li>
<li><strong>ì£¼ìš” íš¨ê³¼</strong>: gradient vanishing ë¬¸ì œ ì™„í™”, ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ ê°€ëŠ¥, ê¸°ì¡´ ì •ë³´ ë³´ì¡´ ë° ì¶”ê°€ ì •ë³´ íš¨ìœ¨ì  í•™ìŠµ[1][2][4][6].</li>
</ul>
<hr />
<blockquote>
<p>"Residual blockì˜ í•µì‹¬ì€ layerê°„ì˜ ì—°ê²°ì„ ê±´ë„ˆë›°ì–´ì„œ ì—°ì‚°í•œë‹¤ëŠ” Skip Connectionì…ë‹ˆë‹¤."<br />
â€” Andrew Ng êµìˆ˜ CNN ê°•ì˜ ìš”ì•½[5]</p>
</blockquote>
<p>ì¶œì²˜
[1] Residual Network, Residual Block ê°œë…ì •ë¦¬ - ì¹˜í‚¨ê³ ì–‘ì´ì§±ì•„ ê³µë¶€ì¼ì§€ https://chickencat-jjanga.tistory.com/141
[2] [ë”¥ëŸ¬ë‹]Skip-Connectionì´ë€? - Meaningful AI https://meaningful96.github.io/deeplearning/skipconnection/
[3] (7) ResNet (Residual Connection) - IT Repository - í‹°ìŠ¤í† ë¦¬ https://itrepo.tistory.com/36
[4] [ë”¥ëŸ¬ë‹] ResNet (Residual block and Skip connection) - velog https://velog.io/@zzwon1212/%EB%94%A5%EB%9F%AC%EB%8B%9D-ResNet-Residual-block-and-Skip-connection
[5] Residual Block ê°œë… ë° ëª©ì  ì •ë¦¬ (feat.ResNet) https://psygo22.tistory.com/entry/Residual-Block-%EA%B0%9C%EB%85%90-%EB%B0%8F-%EB%AA%A9%EC%A0%81-%EC%A0%95%EB%A6%AC-featResNet%F0%9F%98%8E
[6] Skip connection ì •ë¦¬ - Shinuk - í‹°ìŠ¤í† ë¦¬ https://lswook.tistory.com/105
[7] Residual Network(ResNet) ì•„ì´ë””ì–´: skip connect https://bommbom.tistory.com/entry/Residual-NetworkResNet-%EC%95%84%EC%9D%B4%EB%94%94%EC%96%B4-skip-connect
[8] Residual Block ê°„ë‹¨ ì˜ˆì‹œ - velog https://velog.io/@1-june/Residual-Block-%EA%B0%84%EB%8B%A8-%EC%98%88%EC%8B%9C
[9] Residual connectionì€ ì™œ íš¨ê³¼ì ì¼ê¹Œ? - channel AI - í‹°ìŠ¤í† ë¦¬ https://channelai.tistory.com/2</p>
<h3 id="22-transformer">2.2 Transformer ê¸°ë³¸ êµ¬ì¡°<a class="headerlink" href="#22-transformer" title="Permanent link">&para;</a></h3>
<p>TransformerëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ, í¬ê²Œ <strong>ì¸ì½”ë”(Encoder)</strong>ì™€ <strong>ë””ì½”ë”(Decoder)</strong> ë‘ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ëœ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤(Seq2Seq) êµ¬ì¡°ë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤[1][2][7].</p>
<h4 id="_1">ì£¼ìš” êµ¬ì„± ìš”ì†Œ<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ì¸ì½”ë”(Encoder)</strong></li>
<li>ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ì„œ íŠ¹ì§•(feature)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.</li>
<li>ì—¬ëŸ¬ ê°œì˜ ë™ì¼í•œ ì¸ì½”ë” ë ˆì´ì–´ê°€ ìŒ“ì—¬ ìˆìŠµë‹ˆë‹¤.</li>
<li>
<p>ê° ì¸ì½”ë” ë ˆì´ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„œë¸Œ ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:</p>
<ul>
<li><strong>Multi-Head Self-Attention</strong>: ì…ë ¥ ì‹œí€€ìŠ¤ ë‚´ ê° ë‹¨ì–´ê°€ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì™€ì˜ ê´€ê³„(ìœ ì‚¬ë„)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.</li>
<li><strong>Feed-Forward Neural Network</strong>: ê° ìœ„ì¹˜ë³„ë¡œ ë™ì¼í•˜ê²Œ ì ìš©ë˜ëŠ” ì™„ì „ ì—°ê²° ì‹ ê²½ë§ì…ë‹ˆë‹¤.</li>
<li><strong>Add &amp; Layer Normalization</strong>: ê° ì„œë¸Œ ë ˆì´ì–´ì˜ ì…ë ¥ì„ ì¶œë ¥ì— ë”í•˜ëŠ” ì”ì°¨ ì—°ê²°(Residual Connection)ê³¼ ì •ê·œí™”(Layer Normalization)ì„ ì ìš©í•©ë‹ˆë‹¤[1][2][3][4][8].</li>
</ul>
</li>
<li>
<p><strong>ë””ì½”ë”(Decoder)</strong></p>
</li>
<li>ì¸ì½”ë”ì˜ ì¶œë ¥(íŠ¹ì§•)ì„ ë°›ì•„ì„œ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</li>
<li>ì—¬ëŸ¬ ê°œì˜ ë™ì¼í•œ ë””ì½”ë” ë ˆì´ì–´ê°€ ìŒ“ì—¬ ìˆìŠµë‹ˆë‹¤.</li>
<li>
<p>ê° ë””ì½”ë” ë ˆì´ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„œë¸Œ ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:</p>
<ul>
<li><strong>Masked Multi-Head Self-Attention</strong>: ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ìœ„ì¹˜ê°€ ë¯¸ë˜ ì •ë³´ë¥¼ ë³´ì§€ ëª»í•˜ë„ë¡ ë§ˆìŠ¤í‚¹ì„ ì ìš©í•œ ìê¸°-ì–´í…ì…˜ì…ë‹ˆë‹¤.</li>
<li><strong>Encoder-Decoder Attention</strong>: ë””ì½”ë”ì˜ ê° ìœ„ì¹˜ê°€ ì¸ì½”ë”ì˜ ì¶œë ¥ ì „ì²´ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì–´í…ì…˜ì…ë‹ˆë‹¤.</li>
<li><strong>Feed-Forward Neural Network</strong></li>
<li><strong>Add &amp; Layer Normalization</strong>[1][2][4].</li>
</ul>
</li>
<li>
<p><strong>Positional Encoding</strong></p>
</li>
<li>TransformerëŠ” ì…ë ¥ ìˆœì„œë¥¼ ì¸ì‹í•˜ì§€ ëª»í•˜ë¯€ë¡œ, ê° ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì„ë² ë”©ì— ë”í•´ì¤ë‹ˆë‹¤.</li>
<li>ì´ë¥¼ í†µí•´ ë‹¨ì–´ì˜ ìˆœì„œ(ìœ„ì¹˜) ì •ë³´ë¥¼ ëª¨ë¸ì— ì œê³µí•©ë‹ˆë‹¤[2][6].</li>
</ul>
<h4 id="_2">í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ì–´í…ì…˜(Attention)</strong></li>
<li>ì…ë ¥ ì‹œí€€ìŠ¤ ë‚´ ê° ìš”ì†Œê°€ ë‹¤ë¥¸ ëª¨ë“  ìš”ì†Œì™€ì˜ ì—°ê´€ì„±ì„ í•™ìŠµí•©ë‹ˆë‹¤.</li>
<li>Query, Key, Valueì˜ ê°œë…ì„ ì‚¬ìš©í•˜ë©°, Scaled Dot-Product Attention ë°©ì‹ì´ ëŒ€í‘œì ì…ë‹ˆë‹¤[1].</li>
<li>
<p><strong>Multi-Head Attention</strong>: ì—¬ëŸ¬ ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ë³‘ë ¬ë¡œ ì‚¬ìš©í•´ ë‹¤ì–‘í•œ ê´€ê³„ë¥¼ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤[1][2].</p>
</li>
<li>
<p><strong>Feed-Forward Network</strong></p>
</li>
<li>
<p>ê° ìœ„ì¹˜ë³„ë¡œ ë™ì¼í•˜ê²Œ ì ìš©ë˜ëŠ” ë‘ ê°œì˜ Dense(ì™„ì „ ì—°ê²°) ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤[2][4].</p>
</li>
<li>
<p><strong>ì”ì°¨ ì—°ê²°(Residual Connection) &amp; ì¸µ ì •ê·œí™”(Layer Normalization)</strong></p>
</li>
<li>ê° ì„œë¸Œ ë ˆì´ì–´ì˜ ì…ë ¥ì„ ì¶œë ¥ì— ë”í•´ì£¼ê³ , ì •ê·œí™”ë¥¼ í†µí•´ í•™ìŠµì„ ì•ˆì •í™”í•©ë‹ˆë‹¤[2][3][4].</li>
</ul>
<h4 id="_3">ì „ì²´ êµ¬ì¡° ìš”ì•½<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>êµ¬ì„± ìš”ì†Œ</th>
<th style="text-align: center;">Encoderì— í¬í•¨</th>
<th style="text-align: center;">Decoderì— í¬í•¨</th>
<th>ì„¤ëª…</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multi-Head Self-Attention</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">O</td>
<td>ì…ë ¥(ë˜ëŠ” ì¶œë ¥) ì‹œí€€ìŠ¤ ë‚´ ë‹¨ì–´ ê°„ ê´€ê³„ í•™ìŠµ</td>
</tr>
<tr>
<td>Masked Self-Attention</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">O</td>
<td>ë¯¸ë˜ ë‹¨ì–´ ì •ë³´ ì°¨ë‹¨(ë””ì½”ë”ì—ì„œë§Œ ì‚¬ìš©)</td>
</tr>
<tr>
<td>Encoder-Decoder Attention</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">O</td>
<td>ë””ì½”ë”ê°€ ì¸ì½”ë” ì¶œë ¥ ì „ì²´ë¥¼ ì°¸ê³ </td>
</tr>
<tr>
<td>Feed-Forward Network</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">O</td>
<td>ìœ„ì¹˜ë³„ ì™„ì „ ì—°ê²° ì‹ ê²½ë§</td>
</tr>
<tr>
<td>Add &amp; Layer Norm</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">O</td>
<td>ì”ì°¨ ì—°ê²° ë° ì •ê·œí™”</td>
</tr>
<tr>
<td>Positional Encoding</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">O</td>
<td>ë‹¨ì–´ ìœ„ì¹˜ ì •ë³´ ë¶€ì—¬</td>
</tr>
</tbody>
</table>
<h4 id="_4">ì°¸ê³ <a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<ul>
<li>íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë” ë¸”ë¡ì„ ì—¬ëŸ¬ ì¸µ(stack)ìœ¼ë¡œ ìŒ“ì•„ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤(ë…¼ë¬¸ì—ì„œëŠ” ê°ê° 6ê°œ ì¸µ)[4][5].</li>
<li>ëŒ€í‘œì ì¸ ì‘ìš© ëª¨ë¸ë¡œ ì¸ì½”ë”ë§Œ ì‚¬ìš©í•˜ëŠ” <strong>BERT</strong>, ë””ì½”ë”ë§Œ ì‚¬ìš©í•˜ëŠ” <strong>GPT</strong> ë“±ì´ ìˆìŠµë‹ˆë‹¤[2].</li>
</ul>
<p>ì´ì™€ ê°™ì´ TransformerëŠ” ì–´í…ì…˜ ê¸°ë°˜ì˜ ë³‘ë ¬ ì—°ì‚° êµ¬ì¡°ì™€ ë‹¤ì–‘í•œ ì„œë¸Œ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´, ê¸°ì¡´ RNN/LSTM ê¸°ë°˜ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤[1][2][4].</p>
<p>ì¶œì²˜
[1] Transformerì˜ ì´ë¡  ë° êµ¬ì„±ìš”ì†Œ(Attention is all you need) - velog https://velog.io/@gpdus41/Transformer-%EC%9D%B4%EB%A1%A0-%EB%B0%8F-%EA%B5%AC%EC%84%B1Attention-is-all-you-need
[2] íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ê¸°ë³¸ ê°œë…ê³¼ ì£¼ìš” êµ¬ì„± ìš”ì†Œ ì •ë¦¬ - velog https://velog.io/@jayginwoolee/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8-%EB%AA%A8%EB%8D%B8-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%A3%BC%EC%9A%94-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C-%EC%A0%95%EB%A6%AC
[3] Transformer ì´ë¡  ë° êµ¬ì„±ìš”ì†Œ : ë„¤ì´ë²„ ë¸”ë¡œê·¸ https://blog.naver.com/hwankko27/222561357578
[4] 16-01 íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) - ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ https://wikidocs.net/31379
[5] NLPì˜ í•µì‹¬, íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ë³µìŠµ! - Hello, didi universe https://didi-universe.tistory.com/entry/NLP%EC%9D%98-%ED%95%B5%EC%8B%AC-%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8Transformer-%EB%B3%B5%EC%8A%B5
[6] Transformer - ì¸ì½”ë¤, ìƒë¬¼ì •ë³´ ì „ë¬¸ìœ„í‚¤ https://incodom.kr/Transformer
[7] &lt;ì§€ì‹ ì‚¬ì „&gt; íŠ¸ëœìŠ¤í¬ë¨¸(Transformer)ê°€ ë­”ë°? AI í˜ëª…ì˜ í•µì‹¬ ëª¨ë¸ ... https://blog.kakaocloud.com/91
[8] Transformers - ratsgo's NLPBOOK https://ratsgo.github.io/nlpbook/docs/language_model/transformers/
[9] [NLP] Transformer ì•Œì•„ë³´ê¸° - (1) Encoder - ìˆ˜ë¡œê·¸ - í‹°ìŠ¤í† ë¦¬ https://cocosy.tistory.com/71
[10] ë³€ì••ê¸° ë€ ë¬´ì—‡ì´ë©° êµ¬ì„± ìš”ì†ŒëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ? - ì§€ì‹ https://ko.hydgetpower.com/info/what-is-electrical-transformer-and-what-are-it-75569321.html</p>
<h4 id="transformer">Transformer<a class="headerlink" href="#transformer" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Transformer</strong>: Attentionì„ í¬í•¨í•œ Encoder Blockê³¼ Decoder Blockìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ ëª¨ë¸<br />
<a href="https://codingopera.tistory.com/43?category=1094804">ìƒì„¸ ì„¤ëª… ë³´ê¸°</a>  </li>
</ul>
<p><img width="992" height="554" alt="image-11" src="https://github.com/user-attachments/assets/f096c4ca-8463-43dc-87e6-b18d3c193f41" /></p>
<h4 id="attention">Attention êµ¬ì¡°<a class="headerlink" href="#attention" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><strong>Encoder Self-Attention</strong>: ë¬¸ë§¥ìƒ ì¤‘ìš”í•œ ë‹¨ì–´ì— 'ì£¼ëª©'í•˜ì—¬ í•´ë‹¹ ë‹¨ì–´ì˜ ì»¨í…ìŠ¤íŠ¸í™”ëœ í‘œí˜„ ìƒì„±<br />
<img width="581" height="244" alt="Sef-attentsion drawio" src="https://github.com/user-attachments/assets/d746a620-d005-40c6-8c77-8868e0a78016" /></p>
</li>
<li>
<p><strong>Decoder Self-Attention</strong>: ì´ë¯¸ ì¶œë ¥ëœ ì •ë³´ë§Œ í™œìš©í•˜ì—¬ ì¶œë ¥ ë‹¨ì–´ ê°„ì˜ ê´€ë ¨ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìˆœì°¨ì„± ê°•í™”)<br />
<img width="581" height="244" alt="Sef-attentsion-%ED%8E%98%EC%9D%B4%EC%A7%80-2 drawio" src="https://github.com/user-attachments/assets/1f3bfd6a-5559-4ad8-bf37-5e9f42e769ed" /></p>
</li>
<li>
<p><strong>Encoder-Decoder Attention</strong>: ìƒì„± ëŒ€ìƒ ë‹¨ì–´ì™€ ì›ë³¸ ë¬¸ì¥ ë‹¨ì–´ ê°„ì˜ ê´€ë ¨ë„ì— ì£¼ëª©, ë¬¸ë§¥ ê³ ë ¤í•˜ì—¬ ì •í™•ì„± ê°•í™”<br />
<img width="321" height="121" alt="encoder-decoder-attentsion drawio" src="https://github.com/user-attachments/assets/192a9c1d-f889-4b0c-be64-0712b7f19a89" /></p>
</li>
<li>
<p><strong>Positional Encoding</strong>: ë‹¨ì–´ ìˆœì„œ ì •ë³´ë¥¼ ëª¨ë¸ì— ì œê³µ</p>
</li>
</ul>
<hr />
<h4 id="transformer-family-model">Transformer Family Model<a class="headerlink" href="#transformer-family-model" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>ëª¨ë¸</th>
<th>êµ¬ì¡°</th>
<th>íŠ¹ì§•</th>
<th>ìš©ë„</th>
<th>ê´€ë ¨ Family</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GPT</strong></td>
<td>Decoder</td>
<td>- ìƒì„± ëŠ¥ë ¥ + ë©€í‹°ëª¨ë‹¬<br>- ìœ ì°½í•œ ëŒ€í™”, ê°ì • ì´í•´</td>
<td>ëŒ€í™”, ì°½ì‘, ë¶„ì„</td>
<td>GPT-1, 2, 3: ë‹¨ë°©í–¥ ë¬¸ë§¥ ì²˜ë¦¬<br>GPT-3.5, 4<br>GPT-4o: ë©€í‹°ëª¨ë‹¬, ì‹¤ì‹œê°„ ëŒ€í™”</td>
</tr>
<tr>
<td><strong>Claud4</strong></td>
<td>Decoder</td>
<td>- ìƒì„± ëŠ¥ë ¥ + ë©€í‹°ëª¨ë‹¬<br>- í˜‘ë ¥í˜• ì—ì´ì „íŠ¸</td>
<td>ì¥ë¬¸ ì²˜ë¦¬, ë”°ëœ»í•œ ì–´ì¡°</td>
<td></td>
</tr>
<tr>
<td><strong>LLaMA</strong></td>
<td>Decoder</td>
<td>- ìƒì„± ëŠ¥ë ¥</td>
<td>í•™ìˆ  ì—°êµ¬ìš© ì˜¤í”ˆì†ŒìŠ¤</td>
<td></td>
</tr>
<tr>
<td><strong>Gemini</strong></td>
<td>Decoder</td>
<td>- ìƒì„± ëŠ¥ë ¥ + ë©€í‹°ëª¨ë‹¬<br>- ë¶„ì„, ë²ˆì—­, ì½”ë“œ</td>
<td>ì²´ê³„ì  ì¶”ë¡ , ë‹¤êµ­ì–´</td>
<td></td>
</tr>
<tr>
<td><strong>BERT</strong></td>
<td>Encoder</td>
<td>- ì–‘ë°©í–¥ ë¬¸ë§¥ ì´í•´</td>
<td>ë¬¸ì¥ ì´í•´, ë¶„ë¥˜</td>
<td>RoBERTa, ALBERT, DistilBERT, BioBERT, SciBERT, TinyBERT, ELECTRA, DeBERTa</td>
</tr>
<tr>
<td><strong>T5 (Text-to-Text Transfer Transformer)</strong></td>
<td>Decoder+Encoder</td>
<td>- Text2Text êµ¬ì¡°</td>
<td>ìš”ì•½, ë²ˆì—­, QA</td>
<td>mT5, ByT5, UL2</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="bert-family">BERT Family<a class="headerlink" href="#bert-family" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>ëª¨ë¸</th>
<th>íŠ¹ì§•</th>
<th>ì£¼ìš” ìš©ë„</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BERT</strong></td>
<td>MLM + NSP</td>
<td>ë¬¸ì¥ ë¶„ë¥˜, QA, NER</td>
</tr>
<tr>
<td><strong>RoBERTa</strong></td>
<td>MLM</td>
<td>ë¬¸ì¥ ë¶„ë¥˜, QA</td>
</tr>
<tr>
<td><strong>SpanBERT</strong></td>
<td>Span ë§ˆìŠ¤í‚¹ + ì˜ˆì¸¡</td>
<td>ë¬¸ì¥ êµ¬ì¡° ì´í•´ â†’ ê´€ê³„ ì¶”ì¶œ, ë¬¸ì¥ ë¶„í• </td>
</tr>
<tr>
<td><strong>DeBERTa</strong></td>
<td>MLM + ìœ„ì¹˜/ì˜ë¯¸ ë¶„ë¦¬, Relative Positional Encoding</td>
<td>í‘œí˜„ë ¥ ê°•í™”</td>
</tr>
<tr>
<td><strong>ELECTRA</strong></td>
<td>RTD (Replaced Token Detection)</td>
<td>ë¶„ë¥˜, QA</td>
</tr>
<tr>
<td><strong>ALBERT</strong></td>
<td>MLM + SOP</td>
<td>ê²½ëŸ‰í™”, ë©”ëª¨ë¦¬ ì ˆì•½ (ëª¨ë°”ì¼ NLP)</td>
</tr>
<tr>
<td><strong>DistilBERT</strong></td>
<td>Distillation</td>
<td>ì„±ëŠ¥ 97% ìœ ì§€ì˜ ê²½ëŸ‰ ëª¨ë¸</td>
</tr>
<tr>
<td><strong>TinyBERT</strong></td>
<td>Distillation + Layer ì¶•ì†Œ</td>
<td>ì—£ì§€/IoT ë””ë°”ì´ìŠ¤ ìš©</td>
</tr>
<tr>
<td><strong>BioBERT</strong></td>
<td>ì˜ë£Œ ë¶„ì•¼ MLM</td>
<td>ì˜ë£Œ QA, ë…¼ë¬¸ ë¶„ì„</td>
</tr>
<tr>
<td><strong>SciBERT</strong></td>
<td>ê³¼í•™ ë¶„ì•¼ MLM</td>
<td>ì—°êµ¬ ë¬¸ì„œ ë¶„ì„</td>
</tr>
</tbody>
</table>
<p><strong>ì°¸ê³  ìš©ì–´</strong>
- <strong>MLM (Masked Language Modeling)</strong>: ë¬¸ì¥ ë‚´ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•˜ê³  ë³µì›
- <strong>NSP (Next Sentence Prediction)</strong>: ë‘ ë¬¸ì¥ì´ ì—°ê²°ë˜ëŠ”ì§€ ì˜ˆì¸¡
- <strong>SOP (Sentence Order Prediction)</strong>: ë‘ ë¬¸ì¥ì˜ ìˆœì„œê°€ ì˜¬ë°”ë¥¸ì§€ ì˜ˆì¸¡
- <strong>RTD (Replaced Token Detection)</strong>: ì˜ëª»ëœ ë‹¨ì–´ íŒë³„</p>
<blockquote>
<p>ìµœê·¼ LLMì˜ ìƒì„± ê¸°ëŠ¥ ìš”ê±´ ê°•í™”ë¡œ ì¸í•´, BERT ê³„ì—´ì€ LLMì—ì„œ ì œì™¸ë˜ëŠ” ì¶”ì„¸</p>
</blockquote>
<h3 id="23-cnn">2.3 CNNê³¼ ë³€í˜• êµ¬ì¡°<a class="headerlink" href="#23-cnn" title="Permanent link">&para;</a></h3>
<p><img width="850" height="285" alt="image-10" src="https://github.com/user-attachments/assets/80e0813a-b38e-4303-8469-8703455a6b7e" /></p>
<ul>
<li><strong>Convolutional Layer</strong>: í•„í„°/ì»¤ë„ë¡œ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ Feature Map ìƒì„±  </li>
<li><strong>Stride</strong>: í•„í„°/ì»¤ë„ ì´ë™ ê±°ë¦¬  </li>
<li><strong>Padding</strong>: ê°€ì¥ìë¦¬ì— ì±„ì›Œì§€ëŠ” ê°’</li>
<li><strong>Pooling Layer</strong>: Feature Mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ê³  ì£¼ìš” íŠ¹ì§•ì„ ê°•ì¡°  </li>
<li>Max Pooling, Average Pooling</li>
<li>
<p><strong>Fully Connected Layer / Dense Layer</strong>: Feature Map ê¸°ë°˜ì˜ ë¶„ë¥˜ ì‘ì—… ìˆ˜í–‰</p>
</li>
<li>
<p>ë³€í˜• ë° ì‘ìš©</p>
</li>
</ul>
<h3 id="24">2.4 ìˆœí™˜ ì‹ ê²½ë§ ê³„ì—´<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<p><img width="850" height="383" alt="Computation-wise-comparison-of-RNN-LSTM-and-GRU-nodes" src="https://github.com/user-attachments/assets/4beb8259-48c9-483e-b343-7da228db549b" /></p>
<h4 id="rnn-lstm-gru">RNN / LSTM / GRU<a class="headerlink" href="#rnn-lstm-gru" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>RNN</strong>(Recurrent Neural Network)ì€ ì…ë ¥ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ì´ì „ ë‹¨ê³„ì˜ ì •ë³´ë¥¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•˜ëŠ” êµ¬ì¡°ë¡œ ì‹œê³„ì—´ ë° ìˆœì°¨ ë°ì´í„°(í…ìŠ¤íŠ¸, ìŒì„±, ì„¼ì„œ ë“±)ì— ì í•©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê¸´ ì‹œí€€ìŠ¤ì—ì„œ ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œê°€ ë°œìƒí•˜ë©°, ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµì´ ì–´ë µë‹¤ëŠ” í•œê³„ë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ì§§ì€ ì‹œí€€ìŠ¤ ì²˜ë¦¬ì—ëŠ” ì„±ëŠ¥ì´ ì¢‹ìœ¼ë‚˜, ì¥ê¸° ê¸°ì–µì´ í•„ìš”í•œ ë¬¸ë§¥ì—ì„œëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>LSTM</strong>(Long Short-Term Memory)ì€ RNNì˜ ì¥ê¸° ì˜ì¡´ì„± í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ 'ê²Œì´íŠ¸'ë¼ëŠ” êµ¬ì¡°ê°€ ì¶”ê°€ëœ ëª¨ë¸ì…ë‹ˆë‹¤(ì…ë ¥ ê²Œì´íŠ¸, ë§ê° ê²Œì´íŠ¸, ì¶œë ¥ ê²Œì´íŠ¸). ì´ë¡œ ì¸í•´ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì˜¤ë˜ ê¸°ì–µí•  ìˆ˜ ìˆê³ , ê¸´ ë¬¸ì¥ì´ë‚˜ ì¥ê¸°ì ì¸ íŒ¨í„´ì´ ì¤‘ìš”í•œ ìì—°ì–´ ì²˜ë¦¬, ì–¸ì–´ ë²ˆì—­, ìŒì„± ì¸ì‹ ë“±ì— ë§ì´ í™œìš©ë©ë‹ˆë‹¤. ë‹¨ì ì€ êµ¬ì¡°ê°€ ë³µì¡í•´ íŒŒë¼ë¯¸í„°ê°€ ë§ê³ , ê³„ì‚°/ë©”ëª¨ë¦¬ ë¹„ìš©ì´ í½ë‹ˆë‹¤.</li>
<li><strong>GRU</strong>(Gated Recurrent Unit)ëŠ” LSTMì˜ ì¥ì ì„ ìœ ì§€í•˜ë©´ì„œ êµ¬ì¡°ë¥¼ ê°„ì†Œí™”í•œ ëª¨ë¸ì…ë‹ˆë‹¤(ì—…ë°ì´íŠ¸ ê²Œì´íŠ¸, ë¦¬ì…‹ ê²Œì´íŠ¸). ë©”ëª¨ë¦¬/íŒŒë¼ë¯¸í„°ê°€ ì ê³  í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ì§€ë§Œ, ëŒ€ê·œëª¨ ì¥ê¸° ì˜ì¡´ì„± ì²˜ë¦¬ì—ì„œëŠ” LSTMì— ë¹„í•´ íš¨ê³¼ê°€ ë‹¤ì†Œ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ì²˜ë¦¬, ëª¨ë°”ì¼ í™˜ê²½, ìƒëŒ€ì ìœ¼ë¡œ ì§§ì€ ì‹œí€€ìŠ¤ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.</li>
</ul>
<table>
<thead>
<tr>
<th>ë¹„êµ í•­ëª©</th>
<th>RNN</th>
<th>LSTM</th>
<th>GRU</th>
</tr>
</thead>
<tbody>
<tr>
<td>êµ¬ì¡° ë³µì¡ë„</td>
<td>ë‹¨ìˆœ</td>
<td>ë³µì¡(3ê°œì˜ ê²Œì´íŠ¸)</td>
<td>ìƒëŒ€ì  ë‹¨ìˆœ(2ê°œì˜ ê²Œì´íŠ¸)</td>
</tr>
<tr>
<td>ì¥ê¸° ê¸°ì–µ</td>
<td>ì•½í•¨(ê¸°ìš¸ê¸° ì†Œì‹¤)</td>
<td>ê°•í•¨(ì¥ê¸° ì •ë³´ ìœ ì§€)</td>
<td>ë³´í†µ(ì§§ì€ ì‹œí€€ìŠ¤ì— íš¨ìœ¨ì )</td>
</tr>
<tr>
<td>ê³„ì‚°/ë©”ëª¨ë¦¬ ë¹„ìš©</td>
<td>ë‚®ìŒ</td>
<td>ë†’ìŒ</td>
<td>ì¤‘ê°„</td>
</tr>
<tr>
<td>í•™ìŠµ/ì¶”ë¡  ì†ë„</td>
<td>ë¹ ë¦„</td>
<td>ëŠë¦¼</td>
<td>ë¹ ë¦„</td>
</tr>
<tr>
<td>ëŒ€í‘œ ì ìš© ë¶„ì•¼</td>
<td>ê°„ë‹¨ ì‹œê³„ì—´</td>
<td>ë³µì¡âˆ™ì¥ê¸° ì˜ì¡´ NLP, ìŒì„± ë“±</td>
<td>ëª¨ë°”ì¼, ì‹¤ì‹œê°„, ì§§ì€ ë°ì´í„°</td>
</tr>
<tr>
<td>ëŒ€í‘œì  í•œê³„</td>
<td>ê¸´ ì‹œí€€ìŠ¤ ë¯¸ì§€ì›</td>
<td>ê³„ì‚°ëŸ‰, ë©”ëª¨ë¦¬ ì†Œëª¨</td>
<td>ì¥ê¸° ì˜ì¡´ì„± ë‹¤ì†Œ ì•½í•¨</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>ì ìš© ì‚¬ë¡€</strong>:  </li>
<li>RNN: ê°„ë‹¨í•œ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„, ë‹¨ê¸° ì˜ˆì¸¡</li>
<li>LSTM: ë²ˆì—­ ëª¨ë¸, ì±—ë´‡, ê¸´ ëŒ€í™” ë¬¸ë§¥ ì²˜ë¦¬, ìŒì„± ì¸ì‹</li>
<li>GRU: ì‹¤ì‹œê°„ ë²ˆì—­, IoT ë°ì´í„°, ëª¨ë°”ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡[2][4][5][6]</li>
</ul>
<h3 id="25">2.5 ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°<a class="headerlink" href="#25" title="Permanent link">&para;</a></h3>
<h4 id="3d-cnn-convlstm">3D CNN, ConvLSTM<a class="headerlink" href="#3d-cnn-convlstm" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>3D CNN</strong>(3-Dimensional Convolutional Neural Network)ì€ ë°ì´í„° í˜•íƒœê°€ ì‹œê°„/ê³µê°„ì ìœ¼ë¡œ í™•ì¥ëœ ê²½ìš°(ì˜ˆ: ë™ì˜ìƒ, ì˜ë£Œ ì˜ìƒ ë“± 3D ë°ì´í„°)ì— ì ìš©ë©ë‹ˆë‹¤. 2D CNNì—ì„œ ê³µê°„ì  íŒ¨í„´ë§Œ ì¶”ì¶œí•˜ëŠ” ë°˜ë©´, 3D CNNì€ ì‹œê°„ì¶•ê¹Œì§€ í•¨ê»˜ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°í•´ ì‹œê³µê°„ ì •ë³´(ë™ì˜ìƒì˜ ì›€ì§ì„, ë‡Œ MRIì˜ ì‹œê³„ì—´ ë³€í™” ë“±)ë¥¼ ëª¨ë‘ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨ì ì€ ê³„ì‚° ë¹„ìš©ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ë‹¤ëŠ” ê²ƒ.</li>
<li><strong>ConvLSTM</strong>ì€ LSTMê³¼ CNNì˜ ê²°í•© êµ¬ì¡°ë¡œ, ì‹œê³µê°„ ë°ì´í„°(ë™ì˜ìƒ, ì‹œê³„ì—´ ì˜ìƒ ë“±) ë‚´ì˜ ì‹œê°„ì âˆ™ê³µê°„ì  íŒ¨í„´ì„ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤. ì…€ì˜ ê²Œì´íŠ¸ ì—°ì‚°ì—ì„œ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì„ ì ìš©í•´ ì‹œê°ì  êµ¬ì¡° ìœ ì§€ì™€ ì¥ê¸°/ì§§ì€ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ëª¨ë‘ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì˜ìƒ ì˜ˆì¸¡, ê¸°ìƒ ë°ì´í„°(ê°•ìˆ˜ ì˜ˆì¸¡ ë“±)ì™€ ê°™ì€ ê³ ì°¨ì› ì‹œê³„ì—´ ì˜ìƒì— ì£¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.</li>
<li><strong>ì¥ì </strong>  </li>
<li>3D CNN: ì‹œê³µê°„ íŒ¨í„´ì˜ ë™ì‹œ ë¶„ì„, ë³µì¡í•œ ì›€ì§ì„ ì¸ì‹  </li>
<li>ConvLSTM: ë³µì¡í•œ ì‹œê³„ì—´âˆ™ê³µê°„ íŒ¨í„´ ë™ì‹œ ì²˜ë¦¬, ì˜ìƒ ì˜ˆì¸¡ ê°•í™”</li>
<li><strong>ë‹¨ì </strong>  </li>
<li>3D CNN: ë†’ì€ ë©”ëª¨ë¦¬/ì—°ì‚° ë¹„ìš©, ì˜¤ë²„í”¼íŒ… ë“± ìœ„í—˜</li>
<li>
<p>ConvLSTM: íŒŒë¼ë¯¸í„°ê°€ ë§ì•„ ìµœì í™”ê°€ ì–´ë µê³ , ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ í•™ìŠµ ì‹œê°„ ì¦ê°€</p>
</li>
<li>
<p><strong>ëŒ€í‘œ ì ìš© ì‚¬ë¡€</strong>:  </p>
</li>
<li>3D CNN: ë™ì˜ìƒ ë¶„ë¥˜, í–‰ë™ ì¸ì‹, MRI ë“± 3D ì˜ë£Œ ì˜ìƒ ë¶„ì„</li>
<li>ConvLSTM: ê¸°ìƒ ì˜ˆì¸¡(ê°•ìˆ˜ëŸ‰, ë°”ëŒ), ì‹œê³„ì—´ ì˜ìƒ ì´ìƒì˜ ì˜ˆì¸¡, íŠ¸ë˜í”½ íë¦„ ì˜ˆì¸¡, ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„</li>
</ul>
<hr />
<p>ì´ì²˜ëŸ¼ RNN ê³„ì—´ê³¼ ì‹œê³µê°„ ì²˜ë¦¬ êµ¬ì¡°ëŠ” ë°ì´í„° íŠ¹ì„±ê³¼ í™œìš© ëª©ì ì— ë”°ë¼ ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•¨ìœ¼ë¡œì¨ ìµœì ì˜ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] [Deep Learning] RNN, LSTM, GRU ì°¨ì´ì  (ìˆœí™˜ ì‹ ê²½ë§ ëª¨ë¸ë“¤) https://huidea.tistory.com/237
[2] [7í¸] RNN í•œê³„ ê·¹ë³µ: LSTMê³¼ GRUì˜ êµ¬ì¡°ì™€ ìƒì„¸ ë¹„êµ ë° ìµœê·¼ ì—°êµ¬ ... https://newitlec.com/entry/7%ED%8E%B8-RNN%EC%9D%98-%EA%B8%B0%EC%9A%B8%EA%B8%B0-%EC%86%8C%EC%8B%A4-%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0-LSTM%EA%B3%BC-GRU%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EC%9D%91%EC%9A%A9
[3] [DL] ìˆœí™˜ ì‹ ê²½ë§ - RNN, LSTM, GRU íŒŒí—¤ì¹˜ê¸° - ì²œë°©ì§€ì¶• Tech ì¼ê¸°ì¥ https://heeya-stupidbutstudying.tistory.com/entry/DL-%EC%88%9C%ED%99%98-%EC%8B%A0%EA%B2%BD%EB%A7%9D-RNN-LSTM-GRU-%ED%8C%8C%ED%97%A4%EC%B9%98%EA%B8%B0
[4] ì¥ë‹¨ê¸° ê¸°ì–µ ë„¤íŠ¸ì›Œí¬(LSTM) ë° GRU ê°œë… ì™„ë²½ ì •ë¦¬ - learningflix https://learningflix.tistory.com/141
[5] GRU(Gated Recurrent Unit): ë” ê°€ë²¼ìš´ êµ¬ì¡°ë¡œ LSTMì„ ëŒ€ì²´í•  ìˆ˜ ... http://woka.kr/blog/deep%20learning%20%EA%B8%B0%EC%B4%88/2025/03/17/GRU.html
[6] RNN, LSTM, GRU, Transformer model - co-yong ë‹˜ì˜ ë¸”ë¡œê·¸ https://co-yong.tistory.com/entry/RNN
[7] ìˆœí™˜ ì‹ ê²½ë§(RNN) ë° ê·¸ ë³€í˜•(ì˜ˆ: LSTM, GRU) - velog https://velog.io/@imu1119/%EC%88%9C%ED%99%98-%EC%8B%A0%EA%B2%BD%EB%A7%9DRNN-%EB%B0%8F-%EA%B7%B8-%EB%B3%80%ED%98%95%EC%98%88-LSTM-GRU
[8] [NLP] RNN, LSTM, GRUë¥¼ ë¹„êµí•´ë³´ì - ì½”ë”© ë§¤ê±°ì§„ - í‹°ìŠ¤í† ë¦¬ https://hyunsooworld.tistory.com/entry/NLP-%EA%B3%B5%EB%B6%80-RNN-LSTM-GRU%EB%A5%BC-%EB%B9%84%EA%B5%90%ED%95%B4%EB%B3%B4%EC%9E%90
[9] [RNN/LSTM/GRU] Recurrent Neural Network ìˆœí™˜ì‹ ê²½ë§ https://di-bigdata-study.tistory.com/23</p>
<hr />
<h2 id="3">3. ìë™í™”ëœ ì•„í‚¤í…ì²˜ íƒìƒ‰<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<h3 id="31-nas-neural-architecture-search">3.1 NAS (Neural Architecture Search)<a class="headerlink" href="#31-nas-neural-architecture-search" title="Permanent link">&para;</a></h3>
<h4 id="nas">NASë€ ë¬´ì—‡ì¸ê°€?<a class="headerlink" href="#nas" title="Permanent link">&para;</a></h4>
<p><strong>NAS(Neural Architecture Search)</strong>ëŠ” ì¸ê³µì§€ëŠ¥(AI)ê³¼ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ êµ¬ì¡°(ì•„í‚¤í…ì²˜)ë¥¼ ìë™ìœ¼ë¡œ ì„¤ê³„í•´ì£¼ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì¦‰, ì‚¬ëŒì´ ì§ì ‘ ì‹ ê²½ë§ì˜ ì¸µ, ì—°ê²° ë°©ì‹, ì—°ì‚°ì ë“±ì„ ì„¤ê³„í•˜ì§€ ì•Šê³ , AIê°€ ìŠ¤ìŠ¤ë¡œ ìµœì ì˜ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤[1][4][5].</p>
<hr />
<h4 id="nas_1">NASì˜ í•µì‹¬ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬<a class="headerlink" href="#nas_1" title="Permanent link">&para;</a></h4>
<p><strong>1. íƒìƒ‰ ê³µê°„(Search Space) ì •ì˜</strong>
- NASëŠ” ë¨¼ì € ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì‹ ê²½ë§ êµ¬ì„± ìš”ì†Œ(ì˜ˆ: í•©ì„±ê³± ì¸µ, í’€ë§ ì¸µ, í™œì„±í™” í•¨ìˆ˜ ë“±)ì™€ ì´ë“¤ì˜ ì¡°í•© ë°©ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.
- ì´ ê³µê°„ì´ ë„“ì„ìˆ˜ë¡ ë” ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1][4][5].</p>
<p><strong>2. íƒìƒ‰ ì „ëµ(Search Strategy)</strong>
- ì •ì˜ëœ íƒìƒ‰ ê³µê°„ì—ì„œ ìµœì ì˜ êµ¬ì¡°ë¥¼ ì°¾ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜(ê°•í™”í•™ìŠµ, ì§„í™” ì•Œê³ ë¦¬ì¦˜, ë¬´ì‘ìœ„ íƒìƒ‰ ë“±)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´, ê°•í™”í•™ìŠµì„ ì‚¬ìš©í•˜ë©´ AIê°€ ì—¬ëŸ¬ êµ¬ì¡°ë¥¼ ì‹œë„í•´ë³´ê³ , ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” êµ¬ì¡°ì— ë” ì§‘ì¤‘í•˜ê²Œ ë©ë‹ˆë‹¤[1][4][5].</p>
<p><strong>3. ì„±ëŠ¥ ì¶”ì •(Performance Estimation)</strong>
- í›„ë³´ êµ¬ì¡°ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ëª¨ë“  êµ¬ì¡°ë¥¼ ì™„ì „íˆ í•™ìŠµì‹œí‚¤ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ, ë¶€ë¶„ í•™ìŠµì´ë‚˜ íŒŒë¼ë¯¸í„° ê³µìœ  ë“±ìœ¼ë¡œ í‰ê°€ ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤[1][4][5].</p>
<h4 id="nas_2">NASì˜ ì¥ì <a class="headerlink" href="#nas_2" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ìë™í™”</strong>: ì „ë¬¸ê°€ê°€ ì•„ë‹ˆì–´ë„ ê³ ì„±ëŠ¥ AI ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>íš¨ìœ¨ì„±</strong>: ì¸ê°„ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ìˆ˜ë§ì€ êµ¬ì¡°ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>í˜ì‹ ì„±</strong>: ì¸ê°„ì´ ìƒê°í•˜ì§€ ëª»í•œ ìƒˆë¡œìš´ êµ¬ì¡°ë¥¼ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>ë³µì¡ì„± ê´€ë¦¬</strong>: ëŒ€ê·œëª¨ ì‹ ê²½ë§ êµ¬ì¡°ë„ íš¨ê³¼ì ìœ¼ë¡œ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>ë‹¤ì¤‘ ëª©í‘œ ìµœì í™”</strong>: ì •í™•ë„, ì†ë„, ë©”ëª¨ë¦¬ ë“± ì—¬ëŸ¬ ëª©í‘œë¥¼ ë™ì‹œì— ê³ ë ¤í•´ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1][4][5].</li>
</ul>
<h4 id="nas_3">NASì˜ ë„ì „ê³¼ì œ<a class="headerlink" href="#nas_3" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ë†’ì€ ê³„ì‚° ë¹„ìš©</strong>: íƒìƒ‰ ê³¼ì •ì—ì„œ ë§‰ëŒ€í•œ ì—°ì‚° ìì›ì´ í•„ìš”í•©ë‹ˆë‹¤.</li>
<li><strong>íƒìƒ‰ ê³µê°„ ì„¤ê³„</strong>: ë„ˆë¬´ ë„“ê±°ë‚˜ ì¢ìœ¼ë©´ íš¨ìœ¨ì ì¸ íƒìƒ‰ì´ ì–´ë µìŠµë‹ˆë‹¤.</li>
<li><strong>ì„¤ëª… ê°€ëŠ¥ì„±</strong>: ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ êµ¬ì¡°ì˜ ì›ë¦¬ë‚˜ ë™ì‘ì„ í•´ì„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.</li>
<li><strong>ê³µì •ì„± ë° í¸í–¥</strong>: ë°ì´í„° í¸í–¥ì´ ê²°ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1].</li>
</ul>
<hr />
<h4 id="nas-automl">NASì™€ AutoMLì˜ ì°¨ì´<a class="headerlink" href="#nas-automl" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>êµ¬ë¶„</th>
<th>NAS</th>
<th>AutoML</th>
</tr>
</thead>
<tbody>
<tr>
<td>ëª©ì </td>
<td>ì‹ ê²½ë§ êµ¬ì¡°(ì•„í‚¤í…ì²˜) ìë™ íƒìƒ‰</td>
<td>ì „ì²´ ML íŒŒì´í”„ë¼ì¸(ì „ì²˜ë¦¬, ëª¨ë¸ì„ íƒ ë“±) ìë™í™”</td>
</tr>
<tr>
<td>ë²”ìœ„</td>
<td>ëª¨ë¸ êµ¬ì¡° ìì²´ì— ì§‘ì¤‘</td>
<td>ë°ì´í„° ì „ì²˜ë¦¬, íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë“± í¬í•¨</td>
</tr>
<tr>
<td>í™œìš©</td>
<td>ì£¼ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„¤ê³„ì— ì‚¬ìš©</td>
<td>ë¨¸ì‹ ëŸ¬ë‹ ì „ë°˜ì— ì ìš© ê°€ëŠ¥</td>
</tr>
</tbody>
</table>
<p>[4]</p>
<hr />
<h4 id="nas_4">NASì˜ ë¯¸ë˜ì™€ í™œìš©<a class="headerlink" href="#nas_4" title="Permanent link">&para;</a></h4>
<ul>
<li>NASëŠ” AI ëª¨ë¸ ê°œë°œì˜ í‘œì¤€ì´ ë˜ì–´ê°€ê³  ìˆìœ¼ë©°, ëˆ„êµ¬ë‚˜ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ë©´ ìµœì ì˜ AI ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” AutoML í”Œë«í¼ì˜ í•µì‹¬ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.</li>
<li>ì˜ë£Œ, ììœ¨ì£¼í–‰, ì—ë„ˆì§€ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ NASì˜ í™œìš©ì´ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤[1].</li>
</ul>
<hr />
<h4 id="_5">ìš”ì•½<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<ul>
<li>NASëŠ” AIê°€ AI ëª¨ë¸ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ì„¤ê³„í•˜ëŠ” í˜ì‹ ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤.</li>
<li>íƒìƒ‰ ê³µê°„, íƒìƒ‰ ì „ëµ, ì„±ëŠ¥ ì¶”ì •ì˜ 3ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤.</li>
<li>ìë™í™”, íš¨ìœ¨ì„±, í˜ì‹ ì„± ë“± ë‹¤ì–‘í•œ ì¥ì ì´ ìˆì§€ë§Œ, ê³„ì‚° ë¹„ìš© ë“± í•´ê²°í•´ì•¼ í•  ê³¼ì œë„ ì¡´ì¬í•©ë‹ˆë‹¤.</li>
<li>ì•ìœ¼ë¡œ AI ì„¤ê³„ì˜ ë¯¼ì£¼í™”ì™€ ì ‘ê·¼ì„± í™•ëŒ€ì— ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤[1][4][5].</li>
</ul>
<p>ì¶œì²˜
[1] &lt;ì§€ì‹ ì‚¬ì „&gt; Neural Architecture Search(NAS)ë€? AIê°€ AIë¥¼ ì„¤ê³„í•˜ëŠ” ... https://blog.kakaocloud.com/121
[2] [MAT 3í¸] NAS(Network architecture search)ë€ ë¬´ì—‡ì¼ê¹Œ? - ë°ì´ì½˜ https://dacon.io/codeshare/4879
[3] ë‰´ëŸ´ ì•„í‚¤í…ì²˜ ì„œì¹˜(NAS)ì˜ íš¨ìœ¨ì ì¸ êµ¬í˜„ ë°©ë²•: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ì„¤ê³„ ... https://www.jaenung.net/tree/20954
[4] ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ ê²€ìƒ‰(NAS) ì„¤ëª… - Ultralytics https://www.ultralytics.com/ko/glossary/neural-architecture-search-nas
[5] [AI] ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ì„¤ê³„ ìë™í™”ë¥¼ ìœ„í•œ NAS https://easyjwork.tistory.com/63
[6] "AIÂ·ë”¥ëŸ¬ë‹ìœ¼ë¡œ NASì— ì €ì¥ëœ ì‚¬ì§„ ìë™ ë¶„ë¥˜" - ì§€ë””ë„·ì½”ë¦¬ì•„ https://zdnet.co.kr/view/?no=20200305164334
[7] Neural Architecture Search (NAS) - Framework - doingAI - í‹°ìŠ¤í† ë¦¬ https://doing-ai.tistory.com/entry/Neural-Architecture-Search-NAS-Framework
[8] [NeurIPS 2021] Neural Architecture Search Review : ë„¤ì´ë²„ ë¸”ë¡œê·¸ https://post.naver.com/viewer/postView.naver?volumeNo=33500636&amp;memberNo=52249799
[9] QNAP, AI ê¸°ë°˜ RAG ê²€ìƒ‰ìœ¼ë¡œ Qsirchì— í˜ì„ ì‹¤ì–´ NASë¥¼ ìŠ¤ë§ˆíŠ¸ ì§€ì‹ ... https://www.qnap.com/ko-kr/news/2025/qnap-ai-%EA%B8%B0%EB%B0%98-rag-%EA%B2%80%EC%83%89%EC%9C%BC%EB%A1%9C-qsirch%EC%97%90-%ED%9E%98%EC%9D%84-%EC%8B%A4%EC%96%B4-nas%EB%A5%BC-%EC%8A%A4%EB%A7%88%ED%8A%B8-%EC%A7%80%EC%8B%9D-%ED%97%88%EB%B8%8C%EB%A1%9C
[10] LLM íƒ‘ì¬ 'AI NAS'...ëŒ€ìš©ëŸ‰ ì½˜í…ì¸ ì— ìµœì í™”ëœ ì§€ëŠ¥í˜• ë„¤íŠ¸ì›Œí¬ ì—°ê²° ... https://www.gttkorea.com/news/articleView.html?idxno=18240</p>
<h3 id="32-darts-differentiable-architecture-search">3.2 DARTS (Differentiable Architecture Search)<a class="headerlink" href="#32-darts-differentiable-architecture-search" title="Permanent link">&para;</a></h3>
<p><strong>DARTS</strong>ëŠ” Neural Architecture Search(NAS) ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ë°©ë²•ë¡ ìœ¼ë¡œ, ê¸°ì¡´ì˜ ê°•í™”í•™ìŠµì´ë‚˜ ì§„í™”ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ NASê°€ ê°€ì§„ ë¹„íš¨ìœ¨ì„±ê³¼ ë†’ì€ ê³„ì‚° ë¹„ìš© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ë¯¸ë¶„ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ íƒìƒ‰ ê¸°ë²•ì…ë‹ˆë‹¤.</p>
<hr />
<p><strong>í•µì‹¬ ì•„ì´ë””ì–´</strong></p>
<ul>
<li>ê¸°ì¡´ NASëŠ” ì´ì‚°ì (discrete)ì¸ íƒìƒ‰ ê³µê°„ì—ì„œ í›„ë³´ ì•„í‚¤í…ì²˜ë¥¼ í•˜ë‚˜ì”© ìƒ˜í”Œë§í•˜ê³  í‰ê°€í•˜ëŠ” ë°©ì‹ì´ì—ˆìœ¼ë‚˜, DARTSëŠ” íƒìƒ‰ ê³µê°„ì„ ì—°ì†ì ìœ¼ë¡œ(relaxation) í™•ì¥í•˜ì—¬ ë¯¸ë¶„ì´ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤[1][2][3][7].</li>
<li>ì´ë¡œ ì¸í•´ ì•„í‚¤í…ì²˜ íƒìƒ‰ì„ gradient descent(ê²½ì‚¬í•˜ê°•ë²•)ë¡œ ìµœì í™”í•  ìˆ˜ ìˆì–´, íƒìƒ‰ ì†ë„ê°€ ëŒ€í­ í–¥ìƒë˜ê³  ê³„ì‚° ìì›ì´ í¬ê²Œ ì ˆì•½ë©ë‹ˆë‹¤[1][2][5][7].</li>
</ul>
<hr />
<p><strong>DARTSì˜ êµ¬ì¡°ì™€ íƒìƒ‰ ë°©ì‹</strong></p>
<ul>
<li><strong>Cell-based êµ¬ì¡°</strong>: ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ cell(ëª¨ë“ˆ)ë¡œ ë‚˜ëˆ„ê³ , ê° cell ë‚´ë¶€ì˜ êµ¬ì¡°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤. ì´ cellì„ ë°˜ë³µì ìœ¼ë¡œ ìŒ“ì•„ ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“­ë‹ˆë‹¤[2][4][7].</li>
<li><strong>DAG(Directed Acyclic Graph)</strong>: ê° cellì€ ì—¬ëŸ¬ ë…¸ë“œ(ë°ì´í„°ì˜ í‘œí˜„)ì™€ ì—£ì§€(ì—°ì‚°ì)ë¡œ êµ¬ì„±ëœ DAG í˜•íƒœë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ê° ì—£ì§€ì—ëŠ” ì—¬ëŸ¬ í›„ë³´ ì—°ì‚°(ì˜ˆ: convolution, pooling, none ë“±)ì´ í• ë‹¹ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤[2][7].</li>
<li><strong>Mixed Operation</strong>: ê° ì—£ì§€ì— ëŒ€í•´ ì—¬ëŸ¬ ì—°ì‚°ì˜ ê°€ì¤‘í•©(mixed operation)ì„ ì •ì˜í•˜ê³ , ì´ ê°€ì¤‘ì¹˜(architecture parameter, Î±)ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ê°€ì¤‘ì¹˜ëŠ” softmaxë¡œ í™•ë¥ í™”ë˜ì–´ ê° ì—°ì‚°ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤[2][5][7].</li>
<li><strong>Bi-level Optimization</strong>: ì•„í‚¤í…ì²˜ íŒŒë¼ë¯¸í„°(Î±)ëŠ” validation lossë¥¼, ë„¤íŠ¸ì›Œí¬ íŒŒë¼ë¯¸í„°(w)ëŠ” training lossë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ë²ˆê°ˆì•„ê°€ë©° ìµœì í™”í•©ë‹ˆë‹¤[2][5].</li>
<li><strong>ìµœì¢… ì•„í‚¤í…ì²˜ ë„ì¶œ</strong>: íƒìƒ‰ì´ ëë‚˜ë©´ ê° ì—£ì§€ë§ˆë‹¤ ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ì—°ì‚°ì„ ì„ íƒí•´(discretization) ìµœì¢… ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ë¥¼ í™•ì •í•©ë‹ˆë‹¤[2][4][7].</li>
</ul>
<hr />
<p><strong>ì¥ì  ë° ì„±ëŠ¥</strong></p>
<ul>
<li>ê¸°ì¡´ NAS ëŒ€ë¹„ ìˆ˜ì‹­ ë°° ë¹ ë¥¸ íƒìƒ‰ ì†ë„ì™€ ë‚®ì€ ì—°ì‚° ë¹„ìš©[1][5].</li>
<li>ê°•í™”í•™ìŠµ, ì§„í™”ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ë°©ë²•ê³¼ ìœ ì‚¬í•˜ê±°ë‚˜ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì´ë¯¸ì§€ ë¶„ë¥˜(CIFAR-10, ImageNet)ì™€ ì–¸ì–´ ëª¨ë¸ë§(PTB, WikiText-2) ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì…ì¦[1][2][5].</li>
<li>ë‹¨ì¼ GPU í™˜ê²½ì—ì„œë„ ì‹¤ìš©ì ìœ¼ë¡œ ì ìš© ê°€ëŠ¥í•˜ë©°, ENAS ë“± ë‹¤ë¥¸ One-Shot NAS ê¸°ë²•ë³´ë‹¤ë„ íš¨ìœ¨ì ì„[5][6].</li>
</ul>
<hr />
<p><strong>í•œê³„ ë° ê°œì„ ì </strong></p>
<ul>
<li>íƒìƒ‰ ê³¼ì •ì—ì„œ ëª¨ë“  í›„ë³´ ì—°ì‚°ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ë¯€ë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì•„, ëŒ€ê·œëª¨ íƒìƒ‰ ê³µê°„ì—ì„œëŠ” ë©”ëª¨ë¦¬ ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ[6].</li>
<li>Continuous encodingê³¼ discrete architecture ê°„ì˜ ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„±ì´ ì¡´ì¬í•¨. ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•œ softmax temperature annealing ë“± ë‹¤ì–‘í•œ í›„ì† ì—°êµ¬ê°€ ì§„í–‰ ì¤‘ì„[5].</li>
<li>ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ë¬¸ì œë¥¼ ê°œì„ í•˜ëŠ” Zero-One-Shot NAS ë“± ë‹¤ì–‘í•œ íŒŒìƒ ì—°êµ¬ê°€ í™œë°œíˆ ì´ë£¨ì–´ì§€ê³  ìˆìŒ[6].</li>
</ul>
<hr />
<h4 id="_6">ìš”ì•½<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<ul>
<li>DARTSëŠ” NASì˜ íƒìƒ‰ ê³µê°„ì„ ì—°ì†ì ìœ¼ë¡œ relaxí•˜ì—¬ gradient ê¸°ë°˜ ìµœì í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œ ë¯¸ë¶„ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ íƒìƒ‰ ê¸°ë²•ì…ë‹ˆë‹¤.</li>
<li>Cell-based êµ¬ì¡°, mixed operation, bi-level optimizationì´ í•µì‹¬ì´ë©°, ê¸°ì¡´ NAS ëŒ€ë¹„ ë¹ ë¥´ê³  íš¨ìœ¨ì ì…ë‹ˆë‹¤.</li>
<li>ë†’ì€ ë©”ëª¨ë¦¬ ìš”êµ¬ ë“± í•œê³„ë„ ìˆìœ¼ë‚˜, ë‹¤ì–‘í•œ íŒŒìƒ ì—°êµ¬ë¥¼ í†µí•´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤.</li>
</ul>
<hr />
<h2 id="4-llm">4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•„í‚¤í…ì²˜<a class="headerlink" href="#4-llm" title="Permanent link">&para;</a></h2>
<h4 id="1_1">1. êµ¬ì¡°ì™€ ì•„í‚¤í…ì²˜<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Transformer ê¸°ë°˜</strong><br />
  LLMì€ Transformer ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, íŠ¹íˆ <em>decoder-only</em> êµ¬ì¡°ê°€ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.</li>
<li><strong>Autoregressive ë°©ì‹</strong><br />
  ì´ì „ê¹Œì§€ ìƒì„±ëœ í† í°ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í† í°ì„ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©° í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</li>
<li>** Self attention**
  ê°™ì€ ë¬¸ì¥ ë‚´ì—ì„œ ë‹¨ì–´ë“¤ ê°„ì˜ ì˜ë¯¸ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ëŠ” ê²ƒ (ì°¸ê³ : https://cn-c.tistory.com/68)</li>
</ul>
<h4 id="2_1">2. í•™ìŠµ ë°©ì‹<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ì‚¬ì „í•™ìŠµ(Pre-training)</strong><br />
  ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµì„ ì§„í–‰í•˜ì—¬ ì–¸ì–´ì˜ íŒ¨í„´ê³¼ ì§€ì‹ì„ ê´‘ë²”ìœ„í•˜ê²Œ ìŠµë“í•©ë‹ˆë‹¤.</li>
<li><strong>Zero-shot &amp; Few-shot í•™ìŠµ</strong><br />
  ë³„ë„ì˜ íŒŒì¸íŠœë‹(fine-tuning) ì—†ì´ë„, ë˜ëŠ” ëª‡ ê°œì˜ ì˜ˆì‹œë§Œìœ¼ë¡œ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br />
  ì´ëŠ” LLMì´ ì¼ë°˜ì ì¸ ì–¸ì–´ì  ë§¥ë½ê³¼ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‚´ì¬í™”í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</li>
</ul>
<h4 id="3_1">3. íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŠœë‹<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>LoRA(Low-Rank Adaptation)</strong><br />
  ì „ì²´ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šê³ , ì €ì°¨ì› í–‰ë ¬ì„ ì¶”ê°€ë¡œ í•™ìŠµí•˜ì—¬ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±ì„ ë†’ì´ê³ , ë©”ëª¨ë¦¬ì™€ ì—°ì‚° ìì›ì„ ì ˆì•½í•˜ë©´ì„œë„ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.</li>
</ul>
<h4 id="4-tokenization">4. í† í°í™”(Tokenization)<a class="headerlink" href="#4-tokenization" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ì„œë¸Œì›Œë“œ ê¸°ë°˜ í† í°í™”</strong><br />
  BPE(Byte-Pair Encoding), WordPiece ë“± í†µê³„ì  ë³‘í•© ë°©ì‹ì„ í™œìš©í•˜ì—¬ ì–´íœ˜ ì§‘í•©ì„ êµ¬ì„±í•©ë‹ˆë‹¤.</li>
<li><strong>OOV(Out-of-Vocabulary) ëŒ€ì‘</strong><br />
  ìƒˆë¡œìš´ ë‹¨ì–´ì—ë„ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•  ìˆ˜ ìˆì–´ ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ë„ë©”ì¸ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.</li>
</ul>
<h4 id="_7">ìš©ì–´ ìš”ì•½<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>ìš©ì–´</th>
<th>ì„¤ëª…</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transformer</td>
<td>ëŒ€ê·œëª¨ ë³‘ë ¬ ì—°ì‚°ê³¼ ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµì´ ê°€ëŠ¥í•œ ì‹ ê²½ë§ êµ¬ì¡°</td>
</tr>
<tr>
<td>Decoder-only</td>
<td>ì…ë ¥ ì‹œí€€ìŠ¤ë§Œ ë°›ì•„ ìƒì„±í˜• ì‘ì—…ì— íŠ¹í™”ëœ êµ¬ì¡°</td>
</tr>
<tr>
<td>Autoregressive</td>
<td>ì´ì „ í† í° ê¸°ë°˜ ìˆœì°¨ì  ì˜ˆì¸¡ ë°©ì‹</td>
</tr>
<tr>
<td>Zero-shot/Few-shot</td>
<td>ë³„ë„ íŒŒì¸íŠœë‹ ì—†ì´, í˜¹ì€ ì†Œìˆ˜ ì˜ˆì‹œë§Œìœ¼ë¡œ ì‘ì—… ìˆ˜í–‰</td>
</tr>
<tr>
<td>LoRA</td>
<td>ì €ì°¨ì› í–‰ë ¬ ì¶”ê°€ë¡œ íš¨ìœ¨ì  íŒŒë¼ë¯¸í„° íŠœë‹</td>
</tr>
<tr>
<td>BPE/WordPiece</td>
<td>ë¹ˆë²ˆí•œ ë¬¸ì/ë¶€ë¶„ë‹¨ì–´ ë³‘í•©ìœ¼ë¡œ ì–´íœ˜ êµ¬ì„±</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="5">5. íŒŒì¸íŠœë‹ ì „ëµ<a class="headerlink" href="#5" title="Permanent link">&para;</a></h2>
<h3 id="51-lora-low-rank-adaptation">5.1 LoRA (Low-Rank Adaptation)<a class="headerlink" href="#51-lora-low-rank-adaptation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>1. LoRAë€?</strong>
LoRA(Low-Rank Adaptation)ëŠ” Huggingfaceì—ì„œ ì œì•ˆí•œ Parameter-Efficient Fine-Tuning(PEFT) ë°©ì‹ ì¤‘ í•˜ë‚˜ë¡œ, ëŒ€ê·œëª¨ ì‚¬ì „í•™ìŠµ ì–¸ì–´ëª¨ë¸(LLM)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •(fine-tuning) í•˜ê¸° ìœ„í•œ ê¸°ë²•ì…ë‹ˆë‹¤. Pythonì—ì„œëŠ” <a href="https://github.com/huggingface/peft">peft</a> ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì†ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</li>
<li>
<p><strong>2. ê°œìš” ë° êµ¬ì¡°</strong>
ê¸°ì¡´ì˜ full fine-tuningì€ ëª¨ë¸ì˜ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ë©´ì„œ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ê²½ìš° ì—°ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ì´ í¬ë©°, ë³µìˆ˜ ì‘ì—…ì— ë§ì¶° ê°ê° ëª¨ë¸ì„ ìƒˆë¡œ í•™ìŠµí•´ì•¼ í•˜ëŠ” ë¹„ìš©ì´ í½ë‹ˆë‹¤.</p>
</li>
</ul>
<p>LoRAëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤:</p>
<ul>
<li>ê¸°ì¡´ LLMì˜ ì„ í˜• ê³„ì¸µ(Linear layer)ì€ ë™ê²°(freeze)</li>
<li>í•´ë‹¹ ìœ„ì¹˜ì— ì €ë­í¬ í–‰ë ¬ ë‘ ê°œ (A, B layer) ë¥¼ ì¶”ê°€ ì‚½ì…</li>
<li>í•™ìŠµ ì‹œì—ëŠ” Aì™€ B í–‰ë ¬ë§Œ í•™ìŠµ (ì¦‰, Î”W â‰ˆ AÂ·B í˜•íƒœë¡œ weight ë³€í™” í•™ìŠµ)</li>
</ul>
<p>ì´ë¡œ ì¸í•´ ì „ì²´ íŒŒë¼ë¯¸í„° ëŒ€ë¹„ 1~2% ìˆ˜ì¤€ë§Œ í•™ìŠµë˜ë©°, ê¸°ì¡´ weightëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.</p>
<ul>
<li><strong>3. ì¥ì </strong></li>
<li>âœ… íš¨ìœ¨ì„±: ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ì—°ì‚°ëŸ‰ ì ˆê°</li>
<li>âœ… í™•ì¥ì„±: í•˜ë‚˜ì˜ ë² ì´ìŠ¤ ëª¨ë¸ì— ì—¬ëŸ¬ LoRA adapterë¥¼ ë¶™ì—¬ ë‹¤ì¤‘ ì‘ì—… ì§€ì› ê°€ëŠ¥</li>
<li>âœ… ê²½ëŸ‰í™”ëœ íŒŒì¸íŠœë‹: ì ì€ ìì›ìœ¼ë¡œ ë¹ ë¥´ê²Œ task-specific ëª¨ë¸ ê°œë°œ ê°€ëŠ¥</li>
<li>âœ… ì„±ëŠ¥ ìœ ì§€ ë˜ëŠ” í–¥ìƒ: RoBERTa, DeBERTa, GPT-2/3 ë“±ì— ì ìš© ì‹œ full fine-tuning ìˆ˜ì¤€ì˜ ì„±ëŠ¥ í™•ë³´</li>
</ul>
<h3 id="52-instruction-tuning">5.2 Instruction Tuning<a class="headerlink" href="#52-instruction-tuning" title="Permanent link">&para;</a></h3>
<p><strong>Instruction Tuning</strong>ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë‹¤ì–‘í•œ ëª…ë ¹(Instruction)ì— ì˜ ë°˜ì‘í•˜ë„ë¡ ë§Œë“œëŠ” íŠ¹ìˆ˜í•œ íŒŒì¸íŠœë‹(fine-tuning) ê¸°ë²•ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì‚¬ì „í•™ìŠµ(pre-training) ëª¨ë¸ì´ ë‹¨ìˆœíˆ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì— ìµœì í™”ë˜ì–´ ìˆë‹¤ë©´, Instruction Tuningì„ ê±°ì¹œ ëª¨ë¸ì€ ì‚¬ìš©ìì˜ ëª…í™•í•œ ì§€ì‹œ(ì˜ˆ: â€œìš”ì•½í•´ì¤˜â€, â€œë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì¤˜â€)ë¥¼ ë” ì˜ ì´í•´í•˜ê³ , ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤[1][2][3].</p>
<h4 id="1_2">1. ê°œë… ë° ëª©ì <a class="headerlink" href="#1_2" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Instruction Tuning</strong>ì€ (Instruction, Input, Output) í˜•íƒœì˜ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ LLMì„ ì¶”ê°€ í•™ìŠµì‹œí‚¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.</li>
<li><em>Instruction</em>: ì‚¬ëŒì´ ìì—°ì–´ë¡œ ì‘ì„±í•œ ëª…ë ¹(ì˜ˆ: â€œì´ ê¸€ì„ ìš”ì•½í•˜ë¼â€)</li>
<li><em>Input</em>: ëª…ë ¹ì˜ ëŒ€ìƒì´ ë˜ëŠ” ì…ë ¥ ë°ì´í„°(ì˜ˆ: ìš”ì•½í•  ë³¸ë¬¸)</li>
<li><em>Output</em>: ëª…ë ¹ê³¼ ì…ë ¥ì— ëŒ€í•œ ë°”ëŒì§í•œ ê²°ê³¼(ì˜ˆ: ìš”ì•½ë¬¸)</li>
<li>ëª©ì ì€ ëª¨ë¸ì´ ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•´ â€œì„¤ëª…ë§Œ ë³´ê³ â€ ì ì ˆí•œ í–‰ë™ì„ í•˜ë„ë¡ ë§Œë“œëŠ” ë° ìˆìŠµë‹ˆë‹¤[1][2].</li>
</ul>
<h4 id="2_2">2. ê¸°ì¡´ íŒŒì¸íŠœë‹ê³¼ì˜ ì°¨ì´ì <a class="headerlink" href="#2_2" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>êµ¬ë¶„</th>
<th>ì¼ë°˜ íŒŒì¸íŠœë‹(SFT)</th>
<th>Instruction Tuning</th>
</tr>
</thead>
<tbody>
<tr>
<td>ë°ì´í„°</td>
<td>ì…ë ¥-ì¶œë ¥ ìŒ</td>
<td>ëª…ë ¹-ì…ë ¥-ì¶œë ¥ ìŒ</td>
</tr>
<tr>
<td>ëª©í‘œ</td>
<td>íŠ¹ì • ì‘ì—… ì„±ëŠ¥ í–¥ìƒ</td>
<td>ë‹¤ì–‘í•œ ëª…ë ¹ì— ëŒ€í•œ ë²”ìš©ì„± í–¥ìƒ</td>
</tr>
<tr>
<td>ì˜ˆì‹œ</td>
<td>ë²ˆì—­, ê°ì •ë¶„ì„ ë“± ë‹¨ì¼ ì‘ì—…</td>
<td>ìš”ì•½, ë²ˆì—­, QA ë“± ë‹¤ì¤‘ ì‘ì—…</td>
</tr>
<tr>
<td>ì¼ë°˜í™” ëŠ¥ë ¥</td>
<td>ì œí•œì </td>
<td>ë†’ìŒ (zero/few-shot ê°€ëŠ¥)</td>
</tr>
</tbody>
</table>
<p>Instruction Tuningì€ ë‹¤ì–‘í•œ ëª…ë ¹ì„ í•™ìŠµí•¨ìœ¼ë¡œì¨, ìƒˆë¡œìš´ ì‘ì—…ì— ëŒ€í•œ ì¼ë°˜í™”(zero-shot/few-shot ì„±ëŠ¥)ë¥¼ í¬ê²Œ ë†’ì…ë‹ˆë‹¤[3][4][5].</p>
<h4 id="3_2">3. ë°ì´í„°ì…‹ êµ¬ì„±ê³¼ í•™ìŠµ ë°©ì‹<a class="headerlink" href="#3_2" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Instruction Dataset</strong>: ë‹¤ì–‘í•œ ëª…ë ¹ê³¼ ê·¸ì— ëŒ€í•œ ì…ë ¥/ì¶œë ¥ ì˜ˆì‹œë¡œ êµ¬ì„±</li>
<li>ìˆ˜ì‘ì—… ë˜ëŠ” LLMì„ í™œìš©í•´ ìƒì„±</li>
<li>FLAN, Alpaca, Self-Instruct ë“± ëŒ€í‘œì  ê³µê°œ ë°ì´í„°ì…‹ ì¡´ì¬[2][6]</li>
<li><strong>í•™ìŠµ ë°©ì‹</strong>: ì§€ë„í•™ìŠµ(Supervised Learning)ìœ¼ë¡œ, ì£¼ì–´ì§„ ëª…ë ¹ê³¼ ì…ë ¥ì— ëŒ€í•´ ì •ë‹µ ì¶œë ¥ì„ ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ì„ ë¯¸ì„¸ì¡°ì •</li>
</ul>
<h4 id="4">4. íš¨ê³¼ì™€ íŠ¹ì§•<a class="headerlink" href="#4" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ëª…ë ¹ ì´í•´ ë° ìˆ˜í–‰ ëŠ¥ë ¥ ê°•í™”</strong>: ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì— ë” ì •í™•í•˜ê²Œ ë°˜ì‘</li>
<li><strong>ë³µì¡í•œ ìš”ì²­ ì²˜ë¦¬</strong>: ë‹¤ë‹¨ê³„ ì§€ì‹œ, íŠ¹ì • í˜•ì‹/í†¤ ìœ ì§€ ë“± ë³µí•©ì  ìš”êµ¬ì— ëŒ€ì‘[3]</li>
<li><strong>ë²”ìš©ì„±</strong>: ìƒˆë¡œìš´ ì‘ì—…ì´ë‚˜ ë„ë©”ì¸ì— ë¹ ë¥´ê²Œ ì ì‘(zero-shot/few-shot)</li>
<li><strong>ì¼ê´€ì„± ë° ì‹ ë¢°ì„± í–¥ìƒ</strong>: ìœ ì‚¬í•œ ìš”ì²­ì— ëŒ€í•´ ì¼ê´€ëœ ê²°ê³¼ ì œê³µ</li>
</ul>
<h4 id="5_1">5. ì‹¤ì œ ì ìš© ì˜ˆì‹œ<a class="headerlink" href="#5_1" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ëŒ€í™”í˜• AI</strong>: ì‚¬ìš©ìì˜ ì§ˆë¬¸, ìš”ì•½ ìš”ì²­, ë²ˆì—­, ë‹¨ê³„ë³„ ì„¤ëª… ë“± ë‹¤ì–‘í•œ ëª…ë ¹ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘</li>
<li><strong>íŠ¹ì • ë„ë©”ì¸ íŠ¹í™”</strong>: ë²•ë¥ , ì˜ë£Œ, ì˜ì—… ë“± íŠ¹ì • ë¶„ì•¼ì˜ ëª…ë ¹-ì‘ë‹µ ìŒìœ¼ë¡œ íŠœë‹ ì‹œ í•´ë‹¹ ë¶„ì•¼ì— íŠ¹í™”ëœ AI ë¹„ì„œ êµ¬í˜„[7]</li>
</ul>
<h4 id="6">6. í•œê³„ì™€ ê³¼ì œ<a class="headerlink" href="#6" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ê³ í’ˆì§ˆ Instruction ë°ì´í„°ì…‹ êµ¬ì¶•ì˜ ì–´ë ¤ì›€</strong>: ë‹¤ì–‘í•œ ì‘ì—…ê³¼ ëª…ë ¹ì„ í¬ê´„í•˜ëŠ” ë°ì´í„°ì…‹ì´ í•„ìš”[2]</li>
<li><strong>í‘œë©´ì  íŒ¨í„´ í•™ìŠµì˜ í•œê³„</strong>: ëª…ë ¹ì˜ ì˜ë¯¸ë¥¼ ê¹Šì´ ì´í•´í•˜ê¸°ë³´ë‹¤ëŠ” í˜•ì‹ì  íŒ¨í„´ì— ì¹˜ì¤‘í•  ìˆ˜ ìˆìŒ</li>
<li><strong>ë„ë©”ì¸ í¸í–¥</strong>: í•™ìŠµ ë°ì´í„°ì— ì—†ëŠ” ìƒˆë¡œìš´ ëª…ë ¹ì—ëŠ” ì—¬ì „íˆ ì•½ì ì„ ë³´ì¼ ìˆ˜ ìˆìŒ</li>
</ul>
<h4 id="_8">ìš”ì•½<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<p>Instruction Tuningì€ LLMì´ ë‹¤ì–‘í•œ ìì—°ì–´ ëª…ë ¹ì„ ì´í•´í•˜ê³  ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” í•µì‹¬ ê¸°ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë²”ìš©ì ì´ê³  ìœ ì—°í•œ AI ì‹œìŠ¤í…œì„ êµ¬í˜„í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì œë¡œ ë§ì€ ìµœì‹  LLM(ChatGPT, Llama-2-Chat ë“±)ì´ ì´ ê³¼ì •ì„ ê±°ì³ ì¶œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤[1][2][3].</p>
<p>ì¶œì²˜
[1] What Is Instruction Tuning? | IBM https://www.ibm.com/think/topics/instruction-tuning
[2] Instruction Tuning for Large Language Models: A Survey - arXiv https://arxiv.org/html/2308.10792v5
[3] Base LLM vs. instruction-tuned LLM - Toloka https://toloka.ai/blog/base-llm-vs-instruction-tuned-llm/
[4] Instruction Tuning: What is fine-tuning? https://datascientest.com/en/instruction-tuning-what-is-fine-tuning
[5] Difference between Fine-Tuning, Supervised ... https://www.geeksforgeeks.org/difference-between-fine-tuning-supervised-fine-tuning-sft-and-instruction-fine-tuning/
[6] How to Fine-Tune an LLM Part 1: Preparing a Dataset for Instruction ... https://wandb.ai/capecape/alpaca_ft/reports/How-to-Fine-Tune-an-LLM-Part-1-Preparing-a-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2
[7] 10 Examples of Instruction Tuning of LLMs - Incubity by Ambilio https://incubity.ambilio.com/10-examples-of-instruction-tuning-of-llms/
[8] [LLM study] 5. Instruction Tuning - velog https://velog.io/@zvezda/LLM-study-5
[9] Instruction tuning : LLMì´ ì‚¬ëŒ ë§ì„ ì•Œì•„ ë“£ëŠ” ë°©ë²• https://devocean.sk.com/blog/techBoardDetail.do?ID=165806&amp;boardType=techBlog
[10] ì–¼ë ëš±ë•… LLMì„ ë§Œë“¤ì–´ë³´ì [3/3] - zzaebok https://zzaebok.github.io/machine_learning/nlp/llm-finetune/
[11] Fine-tuning large language models (LLMs) in 2025 - SuperAnnotate https://www.superannotate.com/blog/llm-fine-tuning
[12] Difference between Instruction Tuning vs Non ... https://stackoverflow.com/questions/76451205/difference-between-instruction-tuning-vs-non-instruction-tuning-large-language-m
[13] Instruction Tuning with LLM - Kaggle https://www.kaggle.com/code/lonnieqin/instruction-tuning-with-llm
[14] Instruction Tuningì´ë€? - velog https://velog.io/@nellcome/Instruction-Tuning%EC%9D%B4%EB%9E%80
[15] What is the difference between pre-training, fine-tuning ... https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/
[16] Supervised fine-tuning (SFT), instruction fine-tuning and ... https://community.deeplearning.ai/t/supervised-fine-tuning-sft-instruction-fine-tuning-and-full-fine-tuning/527651</p>
<h3 id="53-supervised-fine-tuning-vs-instruction-tuning">5.3 Supervised Fine-Tuning vs Instruction Tuning<a class="headerlink" href="#53-supervised-fine-tuning-vs-instruction-tuning" title="Permanent link">&para;</a></h3>
<h4 id="_9">ë°ì´í„° êµ¬ì¡° ì°¨ì´<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Supervised Fine-Tuning(SFT)</strong>  </li>
<li>ë°ì´í„°ëŠ” <em>ì…ë ¥(input)</em>ê³¼ ê·¸ì— ëŒ€ì‘ë˜ëŠ” <em>ì •ë‹µ(output)</em> ìŒì˜ í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.  </li>
<li>ì˜ˆì‹œ: í…ìŠ¤íŠ¸ ë¶„ë¥˜ë¼ë©´ [ì…ë ¥ ë¬¸ì¥, ë¶„ë¥˜ ë¼ë²¨], ë²ˆì—­ì—ì„œëŠ” [ì›ë¬¸, ë²ˆì—­ë¬¸]ì²˜ëŸ¼ ê°ê° íŠ¹ì • íƒœìŠ¤í¬ì— ì •ë‹µì„ ì§ì ‘ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.  </li>
<li>ê° ìƒ˜í”Œì€ ëª…í™•í•œ íƒœìŠ¤í¬ì™€ ëª©í‘œê°€ ìˆìœ¼ë©° task-specific datasetì„ ì‚¬ìš©í•©ë‹ˆë‹¤[2][3][7].</li>
<li><strong>Instruction Tuning</strong></li>
<li>ë°ì´í„°ëŠ” <em>Instruction(ì§€ì‹œë¬¸)</em>, <em>ì…ë ¥(input)</em>, <em>ì¶œë ¥(output)</em> ì‚¼ì¤‘ êµ¬ì¡° ë˜ëŠ” [instruction, input, output]ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.  </li>
<li>ì—¬ê¸°ì„œ instructionì€ ëª¨ë¸ì´ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€ ìì—°ì–´ ì•ˆë‚´(ì˜ˆ: â€œë‹¤ìŒ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ì‹œì˜¤â€)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.  </li>
<li>ë°ì´í„°ì…‹ì€ ë‹¤ì–‘í•œ í–‰ë™ ì˜ˆì‹œì™€ ì´ì— ëŒ€í•œ ì§€ì‹œë¬¸-ì¶œë ¥ ìŒì„ ë‹´ê³  ìˆì–´ì„œ ì—¬ëŸ¬ íƒœìŠ¤í¬ë¥¼ í¬ê´„í•  ìˆ˜ ìˆëŠ” í˜•íƒœì…ë‹ˆë‹¤[3][5][6][7].</li>
</ul>
<h4 id="_10">ëª©í‘œ ì°¨ì´<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Supervised Fine-Tuning(SFT)</strong>  </li>
<li>í•œ ê°€ì§€ ëª…í™•í•œ íƒœìŠ¤í¬ì—ì„œ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê²ƒ(ì˜ˆ: íŠ¹ì • ë„ë©”ì¸ì˜ ë¬¸ì„œ ë¶„ë¥˜, ì •ë³´ ì¶”ì¶œ ë“±)ì´ ëª©í‘œì…ë‹ˆë‹¤.  </li>
<li>ëª¨ë¸ì€ ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ì •ë‹µì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.  </li>
<li>
<p>ì¼ë°˜ì ìœ¼ë¡œ single-task ë°©ì‹ì´ë©°, ë„ë©”ì¸ íŠ¹í™” ëŠ¥ë ¥ í–¥ìƒì— ì§‘ì¤‘í•©ë‹ˆë‹¤[2][7].</p>
</li>
<li>
<p><strong>Instruction Tuning</strong></p>
</li>
<li>ëª¨ë¸ì´ â€œì§€ì‹œë¬¸â€ì„ ì´í•´í•˜ê³ , ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì™€ ìš”ì²­ì— ë§ê²Œ ë³´ë‹¤ ìœ ì—°í•˜ê²Œ í–‰ë™í•  ìˆ˜ ìˆë„ë¡ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.  </li>
<li>í•œ ê°€ì§€ íƒœìŠ¤í¬ê°€ ì•„ë‹ˆë¼ â€œí”„ë¡¬í”„íŠ¸(ìš”ì²­)â€ì— ë”°ë¼ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µí•˜ëŠ” ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤.  </li>
<li>multitaskÂ·ë‹¤ëª©ì  ëŒ€ì‘ê³¼ ì¼ë°˜í™”(Generalization) ëŠ¥ë ¥, ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ ìš”ì²­ í•´ì„ ëŠ¥ë ¥ ê°œì„ ì´ í•µì‹¬ì…ë‹ˆë‹¤[2][3][5][6].</li>
</ul>
<p>ìš”ì•½í•˜ë©´, SFTëŠ” â€œì •í™•í•œ ì •ë‹µì„ ë§ì¶”ëŠ”â€ ë‹¨ì¼ íƒœìŠ¤í¬ ì¤‘ì‹¬ì´ê³ , Instruction Tuningì€ â€œëª…ì‹œì  ì§€ì‹œë¥¼ ë”°ë¼ í­ë„“ì€ íƒœìŠ¤í¬ì— ëŒ€ì‘í•˜ëŠ”â€ ë©€í‹°íƒœìŠ¤í¬ ë° í”„ë¡¬í”„íŠ¸ ì¤‘ì‹¬ êµ¬ì¡°ì™€ ëª©ì ì„ ê°€ì§„ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] Supervised fine-tuning (SFT), instruction fine-tuning and full fine-tuning https://community.deeplearning.ai/t/supervised-fine-tuning-sft-instruction-fine-tuning-and-full-fine-tuning/527651
[2] Difference between Fine-Tuning, Supervised fine-tuning (SFT) and ... https://www.geeksforgeeks.org/artificial-intelligence/difference-between-fine-tuning-supervised-fine-tuning-sft-and-instruction-fine-tuning/
[3] Instruction Tuning Vol. 1 - by Sebastian Ruder - NLP News https://newsletter.ruder.io/p/instruction-tuning-vol-1
[4] Difference between Instruction Tuning vs Non ... - Stack Overflow https://stackoverflow.com/questions/76451205/difference-between-instruction-tuning-vs-non-instruction-tuning-large-language-m
[5] Instruction Tuning: What is fine-tuning? - DataScientest https://datascientest.com/en/instruction-tuning-what-is-fine-tuning
[6] What Is Instruction Tuning? | IBM https://www.ibm.com/think/topics/instruction-tuning
[7] What is supervised fine-tuning in LLMs? Unveiling the process https://nebius.com/blog/posts/fine-tuning/supervised-fine-tuning
[8] What is the difference between pre-training, fine-tuning, and instruct ... https://www.reddit.com/r/learnmachinelearning/comments/19f04y3/what_is_the_difference_between_pretraining/</p>
<hr />
<h2 id="6-self-supervised-learning">6. ìê¸°ì§€ë„ í•™ìŠµ(Self-Supervised Learning) êµ¬ì¡°<a class="headerlink" href="#6-self-supervised-learning" title="Permanent link">&para;</a></h2>
<ul>
<li>labelì—†ëŠ” unsupervised learningì— ì†í•˜ì—¬, ìŠ¤ìŠ¤ë¡œ taskë¥¼ ë§Œë“¤ì–´ì„œ ëª¨ë¸ì„ í•™ìŠµí•¨.</li>
<li>ëª©ì </li>
<li>unlabelled datasetìœ¼ë¡œ ë¶€í„° ì¢‹ì€ representationì„ ì–»ê³ ì í•˜ëŠ” í•™ìŠµ ë°©ì‹, representation learingì˜ ì¼ì¢…</li>
<li>
<p>label(y)ì—†ì´ input(x)ë‚´ì—ì„œ targetìœ¼ë¡œ ì“°ì¼ë§Œí•œ ê²ƒì„ selfë¡œ taskë¥¼ ì •í•´ì„œ ëª¨ë¸ í•™ìŠµ</p>
</li>
<li>
<p>SimCLR
https://kyujinpy.tistory.com/39</p>
</li>
</ul>
<h3 id="simclr"><strong>SimCLR</strong><a class="headerlink" href="#simclr" title="Permanent link">&para;</a></h3>
<p>A Simple Framework for Contrastive Learning of Visual Representations</p>
<ul>
<li>ì´ë¯¸ì§€ ë¶„ë¥˜</li>
<li>í•µì‹¬ ì•„ì´ë””ì–´ : ìœ ì‚¬í•œ ì´ë¯¸ì§€ì™€ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ìƒì„± í›„, ìœ ì‚¬í•œ ì´ë¯¸ì§€ëŠ” feature spaceì— ê°€ê¹ë„ë¡, ë‹¤ë¥¸ ì´ë¯¸ì§€ëŠ” ë©€ë„ë¡ í•™ìŠµ</li>
<li>loss function
<img alt="image.png" src="attachment:692747ca-88a3-4d55-8e29-1e777abdd761:image.png" /><ul>
<li>ë¶„ì: positive sample(ìœ ì‚¬í•œìƒ˜í”Œ)ê°„ì˜ ìœ ì‚¬ë„</li>
<li>ë¶„ëª¨: negative sample(ë‹¤ë¥¸ìƒ˜í”Œ)ê°„ì˜ ìœ ì‚¬ë„ </li>
</ul>
</li>
</ul>
<hr />
<h3 id="byol"><strong>BYOL</strong><a class="headerlink" href="#byol" title="Permanent link">&para;</a></h3>
<p>Bootstrap your own latent: A new approach to self-supervised Learning</p>
<ul>
<li>ì´ë¯¸ì§€ ë¶„ë¥˜</li>
<li>í•µì‹¬ ì•„ì´ë””ì–´: negative sampleì—†ì´, positivie sampleë§Œ í™œìš©í•˜ì—¬ ì§€ë„í•™ìŠµê³¼ ë¹„êµê°€ëŠ¥í•œ ì„±ëŠ¥ ë³´ì„</li>
<li>BYOLì€ ê°™ì€ ì´ë¯¸ì§€ë¥¼ ë‹¤ë¥´ê²Œ ë³€í˜•í•œ ë‘ ê°œë¥¼ ë³´ê³ ,  â€œì´ ë‘˜ì´ ê°™ë‹¤ê³  ìƒê°í•˜ê²Œâ€ ëª¨ë¸ì„ í›ˆë ¨</li>
<li>online, target networkë¡œ êµ¬ì„±</li>
<li>online network: representationì„ êµ¬ì„±/ í•™ìŠµì˜ ì£¼ì²´</li>
<li>target network: í•™ìŠµì˜ ê¸°ì¤€ ì œê³µ.
<img alt="image.png" src="attachment:6825192d-8ae5-4f5a-97ba-0629a0a1edc6:image.png" /></li>
<li>ì˜¨ë¼ì¸ ë„¤íŠ¸ì›Œí¬ê°€ ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•´ ì—…ë°ì´íŠ¸</li>
<li>íƒ€ì¼“ ë„¤íŠ¸ì›Œí¬ëŠ” ì˜¨ë¼ì¸ ë„¤íŠ¸ì›Œí¬ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•œ exponential moving average(EMA) ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸</li>
<li>ë…¼ë¬¸ë¦¬ë·° ë§í¬ : https://kyujinpy.tistory.com/44</li>
</ul>
<hr />
<h3 id="jigsaw-puzzle"><strong>jigsaw puzzle</strong><a class="headerlink" href="#jigsaw-puzzle" title="Permanent link">&para;</a></h3>
<ul>
<li>í•µì‹¬ì•„ì´ë””ì–´ : ë ˆì´ë¸” ì—†ì´ë„Â ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì€ í¼ì¦ì„ ë§ì¶”ëŠ” ê³¼ì œë¥¼ í†µí•´, ëª¨ë¸ì´Â ì´ë¯¸ì§€ì˜ ê³µê°„ êµ¬ì¡°ì™€ ì˜ë¯¸ì  íŠ¹ì§•ì„ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ë°©ì‹</li>
</ul>
<hr />
<h3 id="maemasked-auto-encoder"><strong>MAE(masked auto encoder)</strong><a class="headerlink" href="#maemasked-auto-encoder" title="Permanent link">&para;</a></h3>
<ul>
<li>ì…ë ¥ ì´ë¯¸ì§€ì— ëœë¤ íŒ¨ì¹˜ ë§ˆìŠ¤í‚¹â†’ í”½ì…€ ê³µê°„ì—ì„œ ëˆ„ë½ëœ íŒ¨ì¹˜ ì¬êµ¬ì„±</li>
<li>MAEëŠ” ë¹„ëŒ€ì¹­ ì¸ì½”ë”-ë””ì½”ë” í˜•ì‹<ul>
<li>ì¸ì½”ë”ëŠ” (ë§ˆìŠ¤í¬ í† í° ì—†ì´) ë³´ì´ëŠ” íŒ¨ì¹˜ì˜ ë¶€ë¶„ì§‘í•©ì—ì„œë§Œ ì‘ë™í•˜ë©°</li>
<li>ë””ì½”ë”ëŠ” ê°€ë³ê³  ë§ˆìŠ¤í¬ í† í°ê³¼ í•¨ê»˜ latent í‘œí˜„ì—ì„œ ì…ë ¥ì„ ì¬êµ¬ì„±</li>
</ul>
</li>
<li>ë…¼ë¬¸ ë¦¬ë·° ë§í¬ : <a href="https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/mae/">Masked Autoencoders Are Scalable Vision Learners (MAE)</a></li>
</ul>
<h3 id="rotnet"><strong>RotNet</strong><a class="headerlink" href="#rotnet" title="Permanent link">&para;</a></h3>
<ul>
<li>ì´ë¯¸ì§€ íšŒì „ëŸ‰ì„ ë§ì¶”ëŠ” ëª¨ë¸ í•™ìŠµ</li>
<li><img alt="image.png" src="attachment:56c7bfec-147a-4caf-a48c-afd8589da538:image.png" /></li>
</ul>
<hr />
<h2 id="7-unsupervised-learning">7. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) êµ¬ì¡°<a class="headerlink" href="#7-unsupervised-learning" title="Permanent link">&para;</a></h2>
<h3 id="unsupervised-learning">ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) ê°œë…<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ë¹„ì§€ë„ í•™ìŠµ</strong>ì€ ì •ë‹µ(ë¼ë²¨)ì´ ì—†ëŠ” ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì´ë‚˜ êµ¬ì¡°ë¥¼ ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì…ë‹ˆë‹¤. ì¦‰, ì…ë ¥ ë°ì´í„°ë§Œ ì£¼ì–´ì§€ê³ , ë°ì´í„° ë‚´ì˜ ìˆ¨ê²¨ì§„ ê´€ê³„ë‚˜ ê·¸ë£¹, íŠ¹ì§•ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤[1][2][3].</li>
<li>ì§€ë„í•™ìŠµ(Supervised Learning)ê³¼ ë‹¬ë¦¬, ëª©í‘œê°’(ì •ë‹µ)ì´ ì£¼ì–´ì§€ì§€ ì•Šìœ¼ë¯€ë¡œ ë°ì´í„°ì˜ ë¶„í¬, ìœ ì‚¬ì„±, íŠ¹ì§• ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.</li>
<li>ì£¼ìš” í™œìš© ë¶„ì•¼ë¡œëŠ” ë°ì´í„°ì˜ <strong>êµ°ì§‘í™”(Clustering)</strong>, <strong>ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)</strong>, <strong>ì´ìƒì¹˜ íƒì§€(Anomaly Detection)</strong> ë“±ì´ ìˆìŠµë‹ˆë‹¤[2][4].</li>
</ul>
<h3 id="_11">ë¹„ì§€ë„ í•™ìŠµì˜ ëŒ€í‘œì  ì˜ˆì‹œ<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ì•Œê³ ë¦¬ì¦˜/ë¶„ì•¼</th>
<th>ì„¤ëª… ë° í™œìš© ì˜ˆì‹œ</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clustering(êµ°ì§‘í™”)</td>
<td>- ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ìŒ<br>- ì˜ˆ: ê³ ê°ì„ êµ¬ë§¤ íŒ¨í„´ì— ë”°ë¼ ê·¸ë£¹í™”, MBTI ìœ í˜• ë¶„ë¥˜, ì´ë¯¸ì§€ ë‚´ ìœ ì‚¬í•œ ì–¼êµ´ ê·¸ë£¹í™”[2][5]</td>
</tr>
<tr>
<td>Dimensionality Reduction(ì°¨ì› ì¶•ì†Œ)</td>
<td>- ë°ì´í„°ì˜ ì°¨ì›ì„ ì¤„ì—¬ì„œ ë³¸ì§ˆì ì¸ íŠ¹ì§•ë§Œ ì¶”ì¶œ<br>- ì˜ˆ: PCA(ì£¼ì„±ë¶„ ë¶„ì„)ë¡œ ë°ì´í„° ì‹œê°í™”, ë…¸ì´ì¦ˆ ì œê±°, í…ìŠ¤íŠ¸ ì£¼ì œ ì¶”ì¶œ[2][6]</td>
</tr>
<tr>
<td>Anomaly Detection(ì´ìƒì¹˜ íƒì§€)</td>
<td>- ì •ìƒ íŒ¨í„´ì—ì„œ ë²—ì–´ë‚œ ë°ì´í„° íƒì§€<br>- ì˜ˆ: ê¸ˆìœµ ê±°ë˜ì—ì„œ ì´ìƒ ê±°ë˜ íƒì§€, ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆì—ì„œ ë¹„ì •ìƒ íŠ¸ë˜í”½ íƒì§€[2]</td>
</tr>
<tr>
<td>Generative Models(ìƒì„± ëª¨ë¸)</td>
<td>- ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±<br>- ì˜ˆ: GANì„ í™œìš©í•œ ê°€ì§œ ì´ë¯¸ì§€ ìƒì„±, VAEë¥¼ í†µí•œ ë°ì´í„° ìƒ˜í”Œë§[4]</td>
</tr>
<tr>
<td>Self-supervised Learning(ìê¸° ì§€ë„ í•™ìŠµ)</td>
<td>- ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•˜ì—¬ ìœ ì˜ë¯¸í•œ í‘œí˜„ í•™ìŠµ<br>- ì˜ˆ: ë¬¸ì¥ ë‚´ ë‹¨ì–´ ì˜ˆì¸¡, ì´ë¯¸ì§€ì˜ ì¼ë¶€ ë³µì›[4]</td>
</tr>
</tbody>
</table>
<h3 id="_12">ì‹¤ì œ í™œìš© ì‚¬ë¡€<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ê³ ê° ì„¸ê·¸ë¨¼í…Œì´ì…˜</strong>: ë§ˆì¼€íŒ…ì—ì„œ ê³ ê° ë°ì´í„°ë¥¼ êµ°ì§‘í™”í•˜ì—¬ ë§ì¶¤í˜• ì „ëµ ìˆ˜ë¦½[2].</li>
<li><strong>ì´ë¯¸ì§€ ì••ì¶• ë° ì‹œê°í™”</strong>: ê³ ì°¨ì› ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PCA ë“±ìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ í›„ ì‹œê°í™”[2][4].</li>
<li><strong>ì¶”ì²œ ì‹œìŠ¤í…œ</strong>: ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ë¥¼ ë¶„ì„í•´ ìœ ì‚¬í•œ ì‚¬ìš©ì ê·¸ë£¹ì„ ì°¾ì•„ ì½˜í…ì¸  ì¶”ì²œ[2].</li>
<li><strong>ì´ìƒ íƒì§€</strong>: ì‹ ìš©ì¹´ë“œ ê±°ë˜, ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ë“±ì—ì„œ ì •ìƒ íŒ¨í„´ê³¼ ë‹¤ë¥¸ ì´ìƒì¹˜ íƒì§€[2].</li>
</ul>
<h3 id="_13">ë¹„ì§€ë„ í•™ìŠµì˜ íŠ¹ì§•<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ë¼ë²¨ ì—†ì´ ë°ì´í„°ì˜ êµ¬ì¡°, íŒ¨í„´, ìœ ì‚¬ì„± ë“±ì„ ìŠ¤ìŠ¤ë¡œ íŒŒì•…</strong>í•©ë‹ˆë‹¤.</li>
<li><strong>í‰ê°€ê°€ ì–´ë µê³  ê²°ê³¼ í•´ì„ì´ ì‰½ì§€ ì•Šë‹¤ëŠ” í•œê³„</strong>ê°€ ìˆì§€ë§Œ, ë°ì´í„° íƒìƒ‰ ë° ì „ì²˜ë¦¬, ìƒˆë¡œìš´ íŒ¨í„´ ë°œê²¬ ë“±ì— ë§¤ìš° ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤[2][6].</li>
</ul>
<p>ë¹„ì§€ë„ í•™ìŠµì€ ë°ì´í„° ë‚´ì¬ì  êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³ , ë¼ë²¨ì´ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ë¡ ì…ë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] ë¹„ì§€ë„í•™ìŠµ(Unsupervised Learning)ì— ëŒ€í•˜ì—¬ - velog https://velog.io/@deep_lini/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5Unsupervised-Learning%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC
[2] Unsupervised Learning (ë¹„ì§€ë„ í•™ìŠµ) ì´ë€? - Data Science Diary https://datasciencediary.tistory.com/entry/Unsupervised-Learning-%EB%B9%84%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5-%EC%9D%B4%EB%9E%80
[3] unsupervised learning (ë¹„ì§€ë„ í•™ìŠµ) - ìœ„í‚¤ë…ìŠ¤ https://wikidocs.net/120198
[4] ì •ë¦¬ : Deep Unsupervised Learning - Research Blog https://animilux.github.io/study/2021/01/29/unsupervised_learning.html
[5] [ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ] ë¹„ì§€ë„í•™ìŠµ(Unsupervised-learning) - êµ°ì§‘í™” ... https://ai-creator.tistory.com/591
[6] Unsupervised Learningì‚¬ë¡€, data preprocessing - Dev https://dev-jm.tistory.com/31
[7] ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) ì´í•´ë¥¼ ë•ëŠ” ì‹¬í”Œ ê°€ì´ë“œ - Appier https://www.appier.com/ko-kr/blog/a-simple-guide-to-unsupervised-learning
[8] [ë¨¸ì‹ ëŸ¬ë‹ ìˆœí•œë§›] ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)ì´ë€? : K ... https://box-world.tistory.com/30
[9] Supervised Learningê³¼ Unsupervised Learning ì°¨ì´ - ìœ ë‹ˆì˜ ê³µë¶€ https://process-mining.tistory.com/98
[10] ì•¤ë“œë¥˜ ì‘ì˜ ë¨¸ì‹ ëŸ¬ë‹ (1-4) : ë¹„ì§€ë„ í•™ìŠµ https://brunch.co.kr/@linecard/440
[11] [ê¸°ê³„í•™ìŠµ] Supervised Learning &amp; Unsupervised Learning https://velog.io/@tjswodud/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-Supervised-Learning-Unsupervised-Learning
[12] ë¨¸ì‹ ëŸ¬ë‹ ê°œìš”, ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) https://sandol20.tistory.com/147
[13] [ë¨¸ì‹ ëŸ¬ë‹ ìˆœí•œë§›] ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)ì´ë€? : ìµœì í™” ... https://box-world.tistory.com/31
[14] ì§€ë„ í•™ìŠµ vs ë¹„ì§€ë„ í•™ìŠµ (Supervised learning ... - CAI - í‹°ìŠ¤í† ë¦¬ https://kjh-ai-blog.tistory.com/12
[15] 09ì¥. ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) https://wikidocs.net/145557</p>
<hr />
<h2 id="8">8. ì˜ìƒ ì²˜ë¦¬ìš© ì•„í‚¤í…ì²˜<a class="headerlink" href="#8" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>ëª¨ë¸ ì•„í‚¤í…ì²˜</th>
<th>ì²˜ë¦¬ êµ¬ì¡° ìš”ì•½</th>
<th>ì‹œê°„ ì •ë³´ ì²˜ë¦¬</th>
<th>í™œìš© ì˜ˆì‹œ</th>
<th>ì¥ë‹¨ì  ìš”ì•½</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CNN</strong></td>
<td>ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬</td>
<td>âŒ ì—†ìŒ</td>
<td>ê°ì²´ ê²€ì¶œ, ì–¼êµ´ ì¸ì‹</td>
<td>âœ… ë¹ ë¥´ê³  ë‹¨ìˆœ<br>âŒ ì‹œê°„ ì •ë³´ ë°˜ì˜ ë¶ˆê°€</td>
</tr>
<tr>
<td><strong>3D CNN / C3D</strong></td>
<td>3D ì»¤ë„ë¡œ ì§§ì€ í”„ë ˆì„ ì‹œí€€ìŠ¤ ì²˜ë¦¬</td>
<td>âœ… ì§§ì€ ì‹œí€€ìŠ¤</td>
<td>ë™ì‘ ì¸ì‹, ìŠ¤í¬ì¸  ì˜ìƒ ë¶„ì„</td>
<td>âœ… ì‹œê°„+ê³µê°„ í†µí•©<br>âŒ ê³ ì •ëœ ê¸¸ì´ í•„ìš”</td>
</tr>
<tr>
<td><strong>ConvLSTM</strong></td>
<td>CNN â†’ LSTM ê²°í•© êµ¬ì¡°ë¡œ ì‹œê³µê°„ ì •ë³´ ë¶„ë¦¬ ì²˜ë¦¬</td>
<td>âœ… ì¥ê¸° ì‹œí€€ìŠ¤</td>
<td>ì´ìƒ í–‰ë™ íƒì§€, ì˜ë£Œ ì˜ìƒ</td>
<td>âœ… ì—°ì†ì„± í‘œí˜„ ê°€ëŠ¥<br>âŒ í•™ìŠµ ì†ë„ ëŠë¦¼</td>
</tr>
<tr>
<td><strong>Two-Stream CNN</strong></td>
<td>RGB ì´ë¯¸ì§€ + Optical Flow 2ê²½ë¡œ ì²˜ë¦¬</td>
<td>âœ… ì›€ì§ì„ ì¶”ì¶œ</td>
<td>ì•¡ì…˜ ì¸ì‹, ë³´ì•ˆ ì˜ìƒ ë¶„ì„</td>
<td>âœ… ì›€ì§ì„ ë¯¼ê°<br>âŒ Preprocessing ì‹œê°„ ìš”êµ¬</td>
</tr>
<tr>
<td><strong>I3D</strong></td>
<td>ê¸°ì¡´ 2D CNNì„ 3Dë¡œ í™•ì¥í•˜ì—¬ ì˜ìƒ í´ë¦½ ì²˜ë¦¬</td>
<td>âœ… ì§§ì€ ì‹œí€€ìŠ¤</td>
<td>ë¹„ë””ì˜¤ ë¶„ë¥˜, Kinetics ì˜ìƒ ë¶„ì„</td>
<td>âœ… ì‚¬ì „í•™ìŠµ ì‚¬ìš© ê°€ëŠ¥<br>âŒ ê³ ì‚¬ì–‘ ìì› í•„ìš”</td>
</tr>
<tr>
<td><strong>Video Transformer (TimeSformer ë“±)</strong></td>
<td>Transformerë¥¼ ì‹œê³µê°„ ì…ë ¥ì— ì ìš©</td>
<td>âœ… ê¸´ ì‹œí€€ìŠ¤</td>
<td>ê¸´ ì˜ìƒ ë¶„ì„, ì´ë²¤íŠ¸ ê°ì§€</td>
<td>âœ… ê¸€ë¡œë²Œ í‘œí˜„ë ¥ ë›°ì–´ë‚¨<br>âŒ ê³„ì‚°ëŸ‰ ë§¤ìš° í¼</td>
</tr>
<tr>
<td><strong>SlowFast Network</strong></td>
<td>ë¹ ë¥¸ ë³€í™”/ëŠë¦° ë³€í™” 2ê°œì˜ ì‹œí€€ìŠ¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬</td>
<td>âœ… ì´ì¤‘ ì‹œí€€ìŠ¤</td>
<td>í–‰ë™ ë¶„ì„, ììœ¨ì£¼í–‰</td>
<td>âœ… ë‹¤ì–‘í•œ ì†ë„ ê°ì§€<br>âŒ êµ¬í˜„ ë³µì¡</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="1-cnn-convolutional-neural-network">1ï¸âƒ£ CNN (Convolutional Neural Network)<a class="headerlink" href="#1-cnn-convolutional-neural-network" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>ê³ ì „ì ì¸ ì´ë¯¸ì§€ ì¸ì‹ì—ì„œ ì‚¬ìš©ë˜ëŠ” êµ¬ì¡°.</li>
<li>ì»¨ë³¼ë£¨ì…˜ í•„í„°ë¥¼ í†µí•´ ê³µê°„ì ì¸ íŠ¹ì§•(ê²½ê³„, ëª¨ì–‘, ìƒ‰ìƒ ë“±)ì„ ì¶”ì¶œ.</li>
<li>ì‹œê°„ ê°œë…ì€ ì „í˜€ ê³ ë ¤ë˜ì§€ ì•ŠìŒ.</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ë‹¨ì¼ í”„ë ˆì„ ê¸°ë°˜ CCTV ì´ë²¤íŠ¸ íƒì§€, ì–¼êµ´ ê°ì§€, ë²ˆí˜¸íŒ ì¸ì‹ ë“±.</li>
<li><strong>í•œê³„:</strong>  </li>
<li>ì›€ì§ì„ ê¸°ë°˜ ì´ë²¤íŠ¸(ì˜ˆ: ì‹¸ì›€, ë„˜ì–´ì§ ë“±)ì˜ ê°ì§€ ë¶ˆê°€ëŠ¥.</li>
<li>ì‹œê°„ì— ë”°ë¥¸ ë³€í™” í•™ìŠµ ë¶ˆê°€.</li>
</ul>
<hr />
<h3 id="2-3d-cnn-c3d-convolutional-3d-networks">2ï¸âƒ£ 3D CNN / C3D (Convolutional 3D Networks)<a class="headerlink" href="#2-3d-cnn-c3d-convolutional-3d-networks" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>ì…ë ¥ ì˜ìƒì´ 3ì°¨ì› í…ì„œ (í”„ë ˆì„ ìˆ˜, ë†’ì´, ë„ˆë¹„)ë¡œ êµ¬ì„±ë˜ë©°, ì»¤ë„ë„ 3Dë¡œ í™•ì¥ë¨.</li>
<li>í”„ë ˆì„ ê°„ ì›€ì§ì„ ë° ê³µê°„ íŒ¨í„´ì„ ë™ì‹œì— í•™ìŠµ.</li>
<li><strong>ëŒ€í‘œ ëª¨ë¸:</strong>  </li>
<li>C3D (Facebook, 2015)</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ìŠ¤í¬ì¸  í–‰ë™ ë¶„ì„, ë‹¨ê¸° ë™ì‘ ì¸ì‹ (ì˜ˆ: ì† í”ë“¤ê¸°, ë°•ìˆ˜ ë“±).</li>
<li><strong>í•œê³„:</strong>  </li>
<li>ê³ ì •ëœ í”„ë ˆì„ ìˆ˜(ì˜ˆ: 16)ë¡œ ì…ë ¥ì„ êµ¬ì„±í•´ì•¼ í•¨.</li>
<li>ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ í”„ë ˆì„ ìˆ˜ê°€ ê°€ë³€ì ì¸ ê²½ìš° ì²˜ë¦¬ ì–´ë µë‹¤.</li>
</ul>
<hr />
<h3 id="3-convlstm-convolutional-long-short-term-memory">3ï¸âƒ£ ConvLSTM (Convolutional Long Short-Term Memory)<a class="headerlink" href="#3-convlstm-convolutional-long-short-term-memory" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>CNNìœ¼ë¡œ ê° í”„ë ˆì„ì˜ ê³µê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ LSTMì— ìˆœì°¨ì ìœ¼ë¡œ ì…ë ¥í•´ ì‹œê°„ íë¦„ì„ í•™ìŠµ.</li>
<li>ì‹œê°„ê³¼ ê³µê°„ ì •ë³´ë¥¼ <strong>ë¶„ë¦¬í•˜ì—¬ ë‹¨ê³„ì ìœ¼ë¡œ</strong> ì²˜ë¦¬í•¨.</li>
<li><strong>ëŒ€í‘œ ë…¼ë¬¸:</strong>  </li>
<li>Shi et al., â€œConvolutional LSTM Network for Precipitation Nowcastingâ€, NIPS 2015</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ì´ìƒ í–‰ë™ ê°ì§€, ì˜ë£Œ ì˜ìƒ ì‹œí€€ìŠ¤ ë¶„ì„, ë“œë¡ /ìœ„ì„±ì˜ìƒ ì˜ˆì¸¡.</li>
<li><strong>ì¥ì :</strong>  </li>
<li>ê¸´ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ìœ ì—°í•˜ê²Œ ëŒ€ì‘ ê°€ëŠ¥.</li>
<li>CNNì„ í†µí•´ ì˜ìƒ ì²˜ë¦¬ì— ìµœì í™”ëœ êµ¬ì¡°.</li>
<li><strong>ë‹¨ì :</strong>  </li>
<li>í•™ìŠµ ì‹œê°„ ê¸¸ê³ , ì—°ì‚°ëŸ‰ì´ ë§ìŒ.</li>
<li>ê³ í•´ìƒë„ ì˜ìƒì—ì„œëŠ” GPU ë©”ëª¨ë¦¬ ë¶€ë‹´.</li>
</ul>
<hr />
<h3 id="4-two-stream-cnn">4ï¸âƒ£ Two-Stream CNN<a class="headerlink" href="#4-two-stream-cnn" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>í•˜ë‚˜ì˜ ë„¤íŠ¸ì›Œí¬ëŠ” RGB í”„ë ˆì„ì„ ì…ë ¥ë°›ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” Optical Flow (ì›€ì§ì„ ë²¡í„°)ë¥¼ ì…ë ¥ë°›ìŒ.</li>
<li>ë‘ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ì˜ˆì¸¡.</li>
<li><strong>ëŒ€í‘œ ë…¼ë¬¸:</strong>  </li>
<li>Simonyan &amp; Zisserman, â€œTwo-Stream Convolutional Networks for Action Recognitionâ€, NIPS 2014</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ìŠ¤í¬ì¸  ì˜ìƒ ë¶„ì„, ë™ì‘ ë¶„ë¥˜.</li>
<li><strong>ì¥ì :</strong>  </li>
<li>ì›€ì§ì„ê³¼ ëª¨ì–‘ ì •ë³´ë¥¼ ë¶„ë¦¬ í•™ìŠµ ê°€ëŠ¥.</li>
<li><strong>ë‹¨ì :</strong>  </li>
<li>Optical Flow ì‚¬ì „ ê³„ì‚° í•„ìš” â†’ ëŠë¦¼.</li>
<li>ì‹¤ì‹œê°„ ë¶„ì„ì—ëŠ” ë¶€ì í•©.</li>
</ul>
<hr />
<h3 id="5-i3d-inflated-3d-convnet">5ï¸âƒ£ I3D (Inflated 3D ConvNet)<a class="headerlink" href="#5-i3d-inflated-3d-convnet" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>ê¸°ì¡´ 2D CNN (ex: Inception-V1)ì„ 3D ì»¤ë„ë¡œ "Inflate"í•˜ì—¬ ì‹œê³µê°„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ í™•ì¥.</li>
<li>ì‚¬ì „ í•™ìŠµëœ 2D ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ 3D ëª¨ë¸ë¡œ ì´ì „í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì .</li>
<li><strong>ëŒ€í‘œ ë…¼ë¬¸:</strong>  </li>
<li>Carreira &amp; Zisserman, â€œQuo Vadis, Action Recognition?â€, CVPR 2017</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>Kinetics dataset ê¸°ë°˜ ë™ì‘ ì¸ì‹.</li>
<li><strong>ì¥ì :</strong>  </li>
<li>ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ í™œìš© ê°€ëŠ¥.</li>
<li>ì •í™•ë„ ë†’ìŒ.</li>
<li><strong>ë‹¨ì :</strong>  </li>
<li>ì—°ì‚° ìì› ë§ì´ í•„ìš” (GPU, ë©”ëª¨ë¦¬).</li>
<li>í•™ìŠµ ì†ë„ ëŠë¦¼.</li>
</ul>
<hr />
<h3 id="6-video-transformer-timesformer-vivit">6ï¸âƒ£ Video Transformer (TimeSformer, ViViT ë“±)<a class="headerlink" href="#6-video-transformer-timesformer-vivit" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>Vision Transformerì˜ êµ¬ì¡°ë¥¼ ì˜ìƒì— í™•ì¥.</li>
<li>í”„ë ˆì„ì˜ ê³µê°„/ì‹œê°„ ê´€ê³„ë¥¼ self-attentionìœ¼ë¡œ ëª¨ë¸ë§í•¨.</li>
<li>ì‹œê°„ ìœ„ì¹˜ì™€ ê³µê°„ ìœ„ì¹˜ ì •ë³´ë¥¼ positional embeddingìœ¼ë¡œ ë¶€ì—¬.</li>
<li><strong>ëŒ€í‘œ ë…¼ë¬¸:</strong>  </li>
<li>TimeSformer (Bertasius et al., CVPR 2021), ViViT (Arnab et al., 2021)</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ê¸´ ì˜ìƒ ì† ì´ë²¤íŠ¸ íƒì§€, ê´‘ê³  ê²€ì—´, ì˜í™” ì¥ë©´ ë¶„ë¥˜ ë“±.</li>
<li><strong>ì¥ì :</strong>  </li>
<li>ë©€ë¦¬ ë–¨ì–´ì§„ í”„ë ˆì„ ê°„ ê´€ê³„ê¹Œì§€ í•™ìŠµ ê°€ëŠ¥.</li>
<li>ìŠ¤ì¼€ì¼ì´ í° ëª¨ë¸ì—ë„ ìœ ì—°í•˜ê²Œ ëŒ€ì‘.</li>
<li><strong>ë‹¨ì :</strong>  </li>
<li>ë§¤ìš° ë†’ì€ ì—°ì‚° ìš”êµ¬ (GPU í´ëŸ¬ìŠ¤í„° í•„ìš”).</li>
<li>ì‘ì€ ë°ì´í„°ì…‹ì—ëŠ” ê³¼ì í•© ìœ„í—˜ ìˆìŒ.</li>
</ul>
<hr />
<h3 id="7-slowfast-networks">7ï¸âƒ£ SlowFast Networks<a class="headerlink" href="#7-slowfast-networks" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ì„¤ëª…:</strong>  </li>
<li>ì„œë¡œ ë‹¤ë¥¸ í”„ë ˆì„ ì†ë„ì˜ ë‘ ê°€ì§€ ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš©.</li>
<li>ëŠë¦° ìŠ¤íŠ¸ë¦¼ì€ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€, ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¼ì€ ì„¸ë°€í•œ ì›€ì§ì„ í¬ì°©.</li>
<li><strong>ëŒ€í‘œ ë…¼ë¬¸:</strong>  </li>
<li>Feichtenhofer et al., â€œSlowFast Networks for Video Recognitionâ€, ICCV 2019</li>
<li><strong>í™œìš© ì˜ˆ:</strong>  </li>
<li>ììœ¨ì£¼í–‰ ì˜ìƒ, ê°ì‹œ ì‹œìŠ¤í…œ, ìŠ¤í¬ì¸  ì˜ìƒ ì¸ì‹ ë“±.</li>
<li><strong>ì¥ì :</strong>  </li>
<li>ë‹¤ì–‘í•œ ì†ë„ì˜ ì›€ì§ì„ í‘œí˜„ì— ê°•í•¨.</li>
<li><strong>ë‹¨ì :</strong>  </li>
<li>êµ¬í˜„ ë³µì¡, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ.</li>
</ul>
<hr />
<h3 id="_14">ğŸ§­ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ëª¨ë¸ ìš”ì•½<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤</th>
<th>ì¶”ì²œ ëª¨ë¸</th>
<th>ì´ìœ </th>
</tr>
</thead>
<tbody>
<tr>
<td>ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ (ì •ì§€ ì´ë¯¸ì§€)</td>
<td>CNN</td>
<td>ê°„ë‹¨í•˜ê³  ë¹ ë¥´ë©° ì˜ ì•Œë ¤ì ¸ ìˆìŒ</td>
</tr>
<tr>
<td>ì§§ì€ ë™ì‘ ë¶„ì„ (ì˜ˆ: ì†ì§“, ì í”„)</td>
<td>3D CNN, C3D, I3D</td>
<td>í”„ë ˆì„ ê°„ ê³µê°„+ì‹œê°„ íŒ¨í„´ì„ í†µí•© ì²˜ë¦¬ ê°€ëŠ¥</td>
</tr>
<tr>
<td>ì´ìƒ í–‰ë™ ê°ì§€ (ì‹œê°„ ì—°ì†ì„± ì¤‘ìš”)</td>
<td>âœ… ConvLSTM</td>
<td>í”„ë ˆì„ ê°„ì˜ ì‹œí€€ìŠ¤ë¥¼ ê³ ë ¤í•œ ì‹œê³µê°„ ë¶„ì„ì— ìµœì </td>
</tr>
<tr>
<td>ë¹ ë¥¸ ì›€ì§ì„ ë¶„ì„ (ì˜ˆ: ê²©íˆ¬, ì¶”ë½)</td>
<td>Two-Stream, SlowFast</td>
<td>ì›€ì§ì„ ì •ë³´ ëª…ì‹œì  í™œìš©, ì†ë„ êµ¬ê°„ ë¶„ë¦¬ ê°€ëŠ¥</td>
</tr>
<tr>
<td>ê¸´ ì˜ìƒ ë¶„ì„ (ì˜ˆ: ì˜í™”, ìŠ¤í¬ì¸ )</td>
<td>Video Transformer</td>
<td>ì „ì²´ ë§¥ë½ ì´í•´ ë° ì¥ê±°ë¦¬ ì˜ì¡´ ê´€ê³„ í‘œí˜„ ê°€ëŠ¥</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="_15">ğŸ”— ì°¸ê³  ë¬¸í—Œ<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h3>
<ul>
<li>Shi et al. (2015), <a href="https://arxiv.org/abs/1506.04214">ConvLSTM</a></li>
<li>Carreira &amp; Zisserman (2017), <a href="https://arxiv.org/abs/1705.07750">I3D</a></li>
<li>Bertasius et al. (2021), <a href="https://arxiv.org/abs/2102.05095">TimeSformer</a></li>
<li>Feichtenhofer et al. (2019), <a href="https://arxiv.org/abs/1812.03982">SlowFast</a></li>
<li>Simonyan &amp; Zisserman (2014), <a href="https://arxiv.org/abs/1412.0767">Two-Stream CNN</a></li>
</ul>
<hr />
<h2 id="9">9. ì•™ìƒë¸” êµ¬ì¡°<a class="headerlink" href="#9" title="Permanent link">&para;</a></h2>
<p>ì•™ìƒë¸” í•™ìŠµ(Ensemble Learning)ì€ ì—¬ëŸ¬ ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì¡°í•©í•´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ í–¥ìƒëœ ì •í™•ë„ì™€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ëŠ” "ì§‘ë‹¨ ì§€ì„±" ì›ë¦¬ë¥¼ ì ìš©í•´ í¸í–¥(Bias)ê³¼ ë¶„ì‚°(Variance)ì„ ë™ì‹œì— ìµœì í™”í•©ë‹ˆë‹¤[1][2][3]. ì£¼ìš” ê¸°ë²•ì¸ ë°°ê¹…(Bagging), ë¶€ìŠ¤íŒ…(Boosting), ìŠ¤íƒœí‚¹(Stacking)ì˜ ì‘ë™ ì›ë¦¬ì™€ ì°¨ì´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<p><a href="https://brunch.co.kr/@chris-song/98">ì°¸ê³  ë¸”ë¡œê·¸</a></p>
<h3 id="1-bagging">1. ë°°ê¹…(Bagging): ë¶„ì‚° ê°ì†Œ ì¤‘ì‹¬<a class="headerlink" href="#1-bagging" title="Permanent link">&para;</a></h3>
<blockquote>
<p><strong>Bootstrap Aggregating</strong>ì˜ ì•½ìë¡œ, ê³ ë¶„ì‚° ëª¨ë¸ì˜ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤[4][5][6].</p>
</blockquote>
<ul>
<li><strong>ì‘ë™ ë°©ì‹</strong>:<br />
  í›ˆë ¨ ë°ì´í„°ë¥¼ ì¤‘ë³µ í—ˆìš© ë¬´ì‘ìœ„ ìƒ˜í”Œë§(ë¶€íŠ¸ìŠ¤íŠ¸ë©)ìœ¼ë¡œ ì—¬ëŸ¬ ë¶€ë¶„ì§‘í•© ìƒì„± â†’ ê° ë¶€ë¶„ì§‘í•©ìœ¼ë¡œ ë…ë¦½ì ì¸ ëª¨ë¸(ì£¼ë¡œ ê²°ì • íŠ¸ë¦¬) í›ˆë ¨ â†’ í‰ê· (íšŒê·€) ë˜ëŠ” ë‹¤ìˆ˜ê²°(ë¶„ë¥˜)ë¡œ ì˜ˆì¸¡ í†µí•©[4][5].</li>
<li><strong>í•µì‹¬ íš¨ê³¼</strong>:<br />
  ëª¨ë¸ì˜ <strong>ë¶„ì‚°ì„ ê°ì†Œ</strong>ì‹œì¼œ ì•ˆì •ì„± í–¥ìƒ. íŠ¹íˆ ë…¸ì´ì¦ˆê°€ ë§ì€ ë°ì´í„°ì—ì„œ íš¨ê³¼ì [5][6].</li>
<li><strong>ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜</strong>:<br />
  Random Forest (ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê¸°ë°˜ ë°°ê¹…ì˜ í™•ì¥)[4][6].</li>
</ul>
<h3 id="2-boosting">2. ë¶€ìŠ¤íŒ…(Boosting): í¸í–¥ ê°ì†Œ ì¤‘ì‹¬<a class="headerlink" href="#2-boosting" title="Permanent link">&para;</a></h3>
<blockquote>
<p>ìˆœì°¨ì  í•™ìŠµìœ¼ë¡œ ì•½í•œ í•™ìŠµê¸°(Weak Learner)ë¥¼ ê°•í•œ ëª¨ë¸ë¡œ ë°œì „ì‹œí‚µë‹ˆë‹¤[7][8].</p>
</blockquote>
<ul>
<li><strong>ì‘ë™ ë°©ì‹</strong>:<br />
  ì´ˆê¸° ëª¨ë¸ì´ ì˜ëª» ì˜ˆì¸¡í•œ ìƒ˜í”Œì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ â†’ ìƒˆë¡œìš´ ëª¨ë¸ì´ ì˜¤ë¥˜ ë³´ì •ì— ì§‘ì¤‘í•´ ìˆœì°¨ì  í›ˆë ¨ â†’ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡ í†µí•©(ì˜ˆ: AdaBoost)[7][8].</li>
<li><strong>í•µì‹¬ íš¨ê³¼</strong>:<br />
  ëª¨ë¸ì˜ <strong>í¸í–¥ì„ ê°ì†Œ</strong>ì‹œì¼œ ì •í™•ë„ í–¥ìƒ. ê³ í¸í–¥ ëª¨ë¸(ì˜ˆ: ì–•ì€ ê²°ì • íŠ¸ë¦¬)ì— íš¨ê³¼ì [7][8].</li>
<li><strong>ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜</strong>:<br />
  AdaBoost, Gradient Boosting, XGBoost[8][6].</li>
</ul>
<h3 id="3-stacking">3. ìŠ¤íƒœí‚¹(Stacking): ë¹„ì„ í˜• ì¡°í•©<a class="headerlink" href="#3-stacking" title="Permanent link">&para;</a></h3>
<blockquote>
<p>ë©”íƒ€-ëª¨ë¸(Meta-Model)ì´ ê¸°ë³¸ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìµœì í™”í•´ í†µí•©í•©ë‹ˆë‹¤[9][10].</p>
</blockquote>
<ul>
<li><strong>ì‘ë™ ë‹¨ê³„</strong>:  </li>
<li>ë‹¤ì–‘í•œ ê¸°ë³¸ ëª¨ë¸(Base Model: RF, SVM ë“±) í›ˆë ¨  </li>
<li>ê¸°ë³¸ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ê°’ì„ ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ë¡œ ë³€í™˜  </li>
<li>ë©”íƒ€-ëª¨ë¸(Logistic Regression, NN ë“±)ì´ ì´ ê°’ì„ í•™ìŠµí•´ ìµœì¢… ì˜ˆì¸¡ ìƒì„±[9][10].</li>
<li><strong>í•µì‹¬ íš¨ê³¼</strong>:<br />
  ê¸°ë³¸ ëª¨ë¸ì˜ í•œê³„ë¥¼ ë„˜ì–´ <strong>ë³µì¡í•œ íŒ¨í„´ í¬ì°©</strong> ê°€ëŠ¥. ì´ì§ˆì  ëª¨ë¸ ì¡°í•©ì— ì í•©[10][6].</li>
<li><strong>ì¥ì </strong>:<br />
  ë¹„ì„ í˜• ê´€ê³„ í•™ìŠµ ê°€ëŠ¥ì„±ìœ¼ë¡œ ë‹¨ìˆœ í‰ê· /íˆ¬í‘œë³´ë‹¤ í‘œí˜„ë ¥ ìš°ìˆ˜[9][10].</li>
</ul>
<h3 id="_16">ë¹„êµ í‘œ: ì•™ìƒë¸” ê¸°ë²• íŠ¹ì„±<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>íŠ¹ì„±</th>
<th>ë°°ê¹…(Bagging)</th>
<th>ë¶€ìŠ¤íŒ…(Boosting)</th>
<th>ìŠ¤íƒœí‚¹(Stacking)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ëª©ì </strong></td>
<td>ë¶„ì‚° ê°ì†Œ</td>
<td>í¸í–¥ ê°ì†Œ</td>
<td>ì˜ˆì¸¡ ì •í™•ë„ ê·¹ëŒ€í™”</td>
</tr>
<tr>
<td><strong>í•™ìŠµ ë°©ì‹</strong></td>
<td>ë³‘ë ¬ ë…ë¦½ í•™ìŠµ</td>
<td>ìˆœì°¨ì  ì˜¤ë¥˜ ë³´ì •</td>
<td>ë©”íƒ€-ëª¨ë¸ í†µí•©</td>
</tr>
<tr>
<td><strong>ëª¨ë¸ ê´€ê³„</strong></td>
<td>ë™ì§ˆì  ëª¨ë¸</td>
<td>ë™ì§ˆì  ëª¨ë¸</td>
<td>ì´ì§ˆì  ëª¨ë¸ ê°€ëŠ¥</td>
</tr>
<tr>
<td><strong>ê³¼ì í•©</strong></td>
<td>ëœ ì·¨ì•½</td>
<td>ì·¨ì•½ (ì¡°ê¸° ì¢…ë£Œ í•„ìˆ˜)</td>
<td>ë°ì´í„° ì–‘ì— ì˜í–¥</td>
</tr>
<tr>
<td><strong>ëŒ€í‘œ ì‚¬ë¡€</strong></td>
<td>Random Forest</td>
<td>AdaBoost, XGBoost</td>
<td>ë¸”ë Œë”©(Blending)</td>
</tr>
</tbody>
</table>
<h3 id="_17">ìš”ì•½<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ë°°ê¹…</strong>: ë¬´ì‘ìœ„ ìƒ˜í”Œë§ìœ¼ë¡œ ëª¨ë¸ ë‹¤ì–‘ì„± í™•ë³´ â†’ <strong>ë¶„ì‚° ê°ì†Œ</strong>  </li>
<li><strong>ë¶€ìŠ¤íŒ…</strong>: ì˜¤ë¥˜ ì¤‘ì‹¬ ìˆœì°¨ í•™ìŠµ â†’ <strong>í¸í–¥ ê°ì†Œ</strong>  </li>
<li><strong>ìŠ¤íƒœí‚¹</strong>: ë©”íƒ€ ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ë¹„ì„ í˜• í†µí•© â†’ <strong>í‘œí˜„ë ¥ ê·¹ëŒ€í™”</strong>  </li>
</ul>
<p>ì•™ìƒë¸” ê¸°ë²• ì„ íƒì€ ë¬¸ì œ íŠ¹ì„±ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤: ê³ ë¶„ì‚° ë¬¸ì œì—ëŠ” ë°°ê¹…, ê³ í¸í–¥ ë¬¸ì œì—ëŠ” ë¶€ìŠ¤íŒ…, ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ì—ëŠ” ìŠ¤íƒœí‚¹ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤[5][8][10].</p>
<p>ì¶œì²˜
[1] What is ensemble learning? - IBM https://www.ibm.com/think/topics/ensemble-learning
[2] Ensemble learning - Wikipedia https://en.wikipedia.org/wiki/Ensemble_learning
[3] Ensemble Learning: A Combined Prediction Model Guide - viso.ai https://viso.ai/deep-learning/ensemble-learning/
[4] What Is Bagging? | IBM https://www.ibm.com/think/topics/bagging
[5] Introduction to Bagging and Ensemble Methods | Paperspace Blog https://blog.paperspace.com/bagging-ensemble-methods/
[6] Bagging in Machine Learning: Step to Perform and Its Advantages https://www.simplilearn.com/tutorials/machine-learning-tutorial/bagging-in-machine-learning
[7] BOOSTING: Ensemble Learning Method in Machine Learning https://www.youtube.com/watch?v=ikaeV2XA9Kk
[8] What Is Boosting? | IBM https://www.ibm.com/think/topics/boosting
[9] Mastering Complexity: The Comprehensive Guide to Stacking Ensemble Models https://ai.plainenglish.io/mastering-complexity-the-comprehensive-guide-to-stacking-ensemble-models-7c0ef4876eda?gi=6acbc9390e87
[10] Unleashing the Full Potential of Ensemble Stacking in Machine Learning and Deep Learning - 33rd Square https://www.33rdsquare.com/ensemble-stacking-for-machine-learning-and-deep-learning/
[11] A Comprehensive Guide to Ensemble Learning: What Exactly Do ... https://neptune.ai/blog/ensemble-learning-guide
[12] A Data Scientistâ€™s Guide to Ensemble Learning: Techniques, Benefits, and Code https://pub.towardsai.net/a-data-scientists-guide-to-ensemble-learning-techniques-benefits-and-code-2f1d82654fb9?gi=fb251f17d1ea
[13] What is Ensemble Learning? https://www.dremio.com/wiki/ensemble-learning/
[14] A Guide to Bagging in Machine Learning - DataCamp https://www.datacamp.com/tutorial/what-bagging-in-machine-learning-a-guide-with-examples
[15] Ensemble learning: Bagging and Boosting | Towards Data Science https://towardsdatascience.com/ensemble-learning-bagging-and-boosting-23f9336d3cb0/
[16] Ensemble Learning: Bagging, Boosting &amp; Stacking - Kaggle https://www.kaggle.com/code/satishgunjal/ensemble-learning-bagging-boosting-stacking
[17] Ensemble Learning - an overview | ScienceDirect Topics https://www.sciencedirect.com/topics/computer-science/ensemble-learning
[18] 8 Key Advantages of Ensemble Learning in Machine Intelligence https://www.numberanalytics.com/blog/8-key-advantages-ensemble-learning-machine-intelligence
[19] What is Ensemble Learning? https://www.lyzr.ai/glossaries/ensemble-learning/
[20] The Essential Guide to Ensemble Learning https://www.v7labs.com/blog/ensemble-learning-guide</p>
<hr />
<h2 id="10">10. ëª¨ë¸ ì„±ëŠ¥ ë° ê³¼ì í•©/ê³¼ì†Œì í•©<a class="headerlink" href="#10" title="Permanent link">&para;</a></h2>
<ul>
<li>Overfitting &amp; Underfitting ì •ì˜ ë° ì›ì¸
<img alt="" src="https://aiml.com/wp-content/uploads/2023/02/overfitting_underfitting.png" /></li>
</ul>
<table>
<thead>
<tr>
<th>êµ¬ë¶„</th>
<th>ì •ì˜</th>
<th>ì£¼ìš” ì›ì¸</th>
<th>í•´ê²° ë°©ë²• ë° ì„¤ëª…</th>
</tr>
</thead>
<tbody>
<tr>
<td>Overfitting</td>
<td>ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì— ê³¼ë„í•˜ê²Œ ì í•©í•˜ì—¬, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¼ë°˜í™”ë˜ì§€ ëª»í•¨</td>
<td>- ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•¨<br>- í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•¨<br>- ë…¸ì´ì¦ˆì— ë¯¼ê°í•˜ê²Œ í•™ìŠµí•¨</td>
<td>- <strong>ë°ì´í„° ì–‘ ì¦ê°€</strong>: ë” ë§ì€ í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ë°ì´í„° ì¦ê°•(Data Augmentation)ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´<br>- <strong>ì •ê·œí™”(Regularization)</strong>: L1, L2 ê·œì œë¥¼ í†µí•´ ê³¼ë„í•œ ê°€ì¤‘ì¹˜ë¥¼ ì–µì œ<br>- <strong>Dropout</strong>: í•™ìŠµ ì¤‘ ì¼ë¶€ ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ êº¼ì„œ ê³¼ì í•©ì„ ë°©ì§€<br>- <strong>ëª¨ë¸ ë‹¨ìˆœí™”</strong>: íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ì€ ê°„ë‹¨í•œ ëª¨ë¸ ì‚¬ìš©<br>- <strong>ì¡°ê¸° ì¢…ë£Œ(Early Stopping)</strong>: ê²€ì¦ ì†ì‹¤ì´ ì¦ê°€í•˜ê¸° ì‹œì‘í•˜ë©´ í•™ìŠµì„ ì¤‘ë‹¨í•˜ì—¬ ê³¼ë„í•œ í•™ìŠµ ë°©ì§€</td>
</tr>
<tr>
<td>Underfitting</td>
<td>ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì˜ íŒ¨í„´ì¡°ì°¨ ì œëŒ€ë¡œ í•™ìŠµí•˜ì§€ ëª»í•¨</td>
<td>- ëª¨ë¸ì´ ì§€ë‚˜ì¹˜ê²Œ ë‹¨ìˆœí•¨<br>- í•™ìŠµ ì‹œê°„ì´ ë¶€ì¡±í•¨<br>- ì¤‘ìš”í•œ feature ëˆ„ë½</td>
<td>- <strong>ë” ë³µì¡í•œ ëª¨ë¸ ì‚¬ìš©</strong>: ì¸µ ìˆ˜ë‚˜ ë‰´ëŸ° ìˆ˜ë¥¼ ëŠ˜ë¦° ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ ì „í™˜<br>- <strong>í•™ìŠµ ì‹œê°„ ì¦ê°€</strong>: epoch ìˆ˜ë¥¼ ëŠ˜ë ¤ ì¶©ë¶„íˆ í•™ìŠµ<br>- <strong>feature ì—”ì§€ë‹ˆì–´ë§</strong>: ì¤‘ìš”í•œ ì…ë ¥ íŠ¹ì„± ì¶”ê°€ ë° ì „ì²˜ë¦¬ ê°œì„ <br>- <strong>í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</strong>: í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸° ë“± ì¡°ì ˆë¡œ í•™ìŠµ ì„±ëŠ¥ ê°œì„ </td>
</tr>
</tbody>
</table>
<hr />
<h2 id="11">11. ë©”ëª¨ë¦¬ ë° íš¨ìœ¨ì„± ê³ ë ¤<a class="headerlink" href="#11" title="Permanent link">&para;</a></h2>
<h3 id="oom-out-of-memory">OOM (Out-Of-Memory)<a class="headerlink" href="#oom-out-of-memory" title="Permanent link">&para;</a></h3>
<h4 id="oomout-of-memory">OOM(Out Of Memory)ë€?<a class="headerlink" href="#oomout-of-memory" title="Permanent link">&para;</a></h4>
<p>OOM(Out Of Memory, ë©”ëª¨ë¦¬ ë¶€ì¡±)ì€ ì»´í“¨í„°ë‚˜ GPUê°€ ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë©”ëª¨ë¦¬ë¥¼ ëª¨ë‘ ì†Œì§„í•´ ë” ì´ìƒ ë©”ëª¨ë¦¬ë¥¼ í• ë‹¹í•  ìˆ˜ ì—†ì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì…ë‹ˆë‹¤. ì´ ì˜¤ë¥˜ëŠ” ë¬¼ë¦¬ì  RAMì´ë‚˜ ê°€ìƒ ë©”ëª¨ë¦¬(ë””ìŠ¤í¬ë¥¼ í™œìš©í•´ í™•ì¥ëœ ë©”ëª¨ë¦¬)ê°€ ëª¨ë‘ ë¶€ì¡±í•  ë•Œ ë‚˜íƒ€ë‚˜ë©°, í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ê±°ë‚˜ ì‹œìŠ¤í…œì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤[1][2][3]. ë”¥ëŸ¬ë‹ì—ì„œëŠ” íŠ¹íˆ ëŒ€ìš©ëŸ‰ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ë•Œ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤.</p>
<h4 id="cuda-oomout-of-memory">CUDA OOM(Out Of Memory) ì™„í™” ë°©ë²•<a class="headerlink" href="#cuda-oomout-of-memory" title="Permanent link">&para;</a></h4>
<p>ë”¥ëŸ¬ë‹ì—ì„œ GPUë¥¼ ì‚¬ìš©í•  ë•Œ ë°œìƒí•˜ëŠ” CUDA OOM ì˜¤ë¥˜ëŠ” GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•´ í…ì„œë‚˜ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ í• ë‹¹í•˜ì§€ ëª»í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•œ ì£¼ìš” ë°©ë²•ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<h5 id="1-batch-size">1. <strong>ë°°ì¹˜ í¬ê¸°(batch size) ì¤„ì´ê¸°</strong><a class="headerlink" href="#1-batch-size" title="Permanent link">&para;</a></h5>
<ul>
<li>í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë°ì´í„° ì–‘ì„ ì¤„ì´ë©´ í•„ìš”í•œ GPU ë©”ëª¨ë¦¬ë„ ì¤„ì–´ë“­ë‹ˆë‹¤. ê°€ì¥ ê¸°ë³¸ì ì´ê³  íš¨ê³¼ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤[4][5][6][7].</li>
</ul>
<h5 id="2_3">2. <strong>ëª¨ë¸ í¬ê¸° ì¶•ì†Œ</strong><a class="headerlink" href="#2_3" title="Permanent link">&para;</a></h5>
<ul>
<li>ë ˆì´ì–´ ìˆ˜ë‚˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì—¬ ëª¨ë¸ ìì²´ê°€ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ë¥¼ ì¤„ì…ë‹ˆë‹¤[4][5].</li>
</ul>
<h5 id="3-mixed-precision-training">3. <strong>í˜¼í•© ì •ë°€ë„ í•™ìŠµ(Mixed Precision Training)</strong><a class="headerlink" href="#3-mixed-precision-training" title="Permanent link">&para;</a></h5>
<ul>
<li>float32 ëŒ€ì‹  float16 ë“± ë” ì‘ì€ ë°ì´í„° íƒ€ì…ì„ ì‚¬ìš©í•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. PyTorchì˜ <code>torch.cuda.amp</code> ë“±ì„ í™œìš©í•©ë‹ˆë‹¤[4][5].</li>
</ul>
<h5 id="4_1">4. <strong>ë¶ˆí•„ìš”í•œ ë³€ìˆ˜/í…ì„œ ì‚­ì œ</strong><a class="headerlink" href="#4_1" title="Permanent link">&para;</a></h5>
<ul>
<li>ì‚¬ìš©ì´ ëë‚œ ë³€ìˆ˜ë‚˜ í…ì„œëŠ” <code>del</code> ëª…ë ¹ì–´ë¡œ ì‚­ì œí•˜ê³ , í•„ìš” ì—†ëŠ” í…ì„œëŠ” GPUê°€ ì•„ë‹Œ CPUì— ì˜¬ë ¤ ë©”ëª¨ë¦¬ ì ìœ ë¥¼ ì¤„ì…ë‹ˆë‹¤[4][8][7].</li>
</ul>
<h5 id="5_2">5. <strong>ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°</strong><a class="headerlink" href="#5_2" title="Permanent link">&para;</a></h5>
<ul>
<li>PyTorchì˜ <code>torch.cuda.empty_cache()</code>ë¥¼ ì‚¬ìš©í•´ ìºì‹œëœ ë¯¸ì‚¬ìš© ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ í…ì„œì˜ ë©”ëª¨ë¦¬ëŠ” í•´ì œë˜ì§€ ì•Šìœ¼ë¯€ë¡œ íš¨ê³¼ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤[9][8][7].</li>
</ul>
<h5 id="6-torchno_grad-modeleval">6. <strong>torch.no_grad() ë° model.eval() ì‚¬ìš©</strong><a class="headerlink" href="#6-torchno_grad-modeleval" title="Permanent link">&para;</a></h5>
<ul>
<li>ì¶”ë¡ (inference) ì‹œì—ëŠ” <code>torch.no_grad()</code>ë¡œ ë¶ˆí•„ìš”í•œ ê·¸ë˜ë””ì–¸íŠ¸ ì €ì¥ì„ ë°©ì§€í•˜ê³ , <code>model.eval()</code>ë¡œ í•™ìŠµì—ë§Œ í•„ìš”í•œ ë ˆì´ì–´ë¥¼ ë¹„í™œì„±í™”í•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì…ë‹ˆë‹¤[6][7].</li>
</ul>
<h5 id="7">7. <strong>ì…ë ¥ ë°ì´í„° í¬ê¸°/í•´ìƒë„ ì¤„ì´ê¸°</strong><a class="headerlink" href="#7" title="Permanent link">&para;</a></h5>
<ul>
<li>ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ ë“± ì…ë ¥ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê°ì†Œí•©ë‹ˆë‹¤[5].</li>
</ul>
<h5 id="8-dataloader">8. <strong>ë°ì´í„° ë¶„í•  ë° DataLoader í™œìš©</strong><a class="headerlink" href="#8-dataloader" title="Permanent link">&para;</a></h5>
<ul>
<li>ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì˜¬ë¦¬ì§€ ì•Šê³ , DataLoader ë“±ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤[4].</li>
</ul>
<h5 id="9_1">9. <strong>ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€</strong><a class="headerlink" href="#9_1" title="Permanent link">&para;</a></h5>
<ul>
<li>ì‚¬ìš©ì´ ëë‚œ ë©”ëª¨ë¦¬ë¥¼ ì¦‰ì‹œ í•´ì œí•˜ê³ , ë¶ˆí•„ìš”í•œ ë°ì´í„°ê°€ ê³„ì† ìŒ“ì´ì§€ ì•Šë„ë¡ ì£¼ì˜í•©ë‹ˆë‹¤[3][10].</li>
</ul>
<h5 id="10-gpu">10. <strong>ë” í° GPUë¡œ ì—…ê·¸ë ˆì´ë“œ</strong><a class="headerlink" href="#10-gpu" title="Permanent link">&para;</a></h5>
<ul>
<li>ìœ„ì˜ ë°©ë²•ìœ¼ë¡œë„ í•´ê²°ì´ ì•ˆ ë˜ë©´, ë©”ëª¨ë¦¬ ìš©ëŸ‰ì´ ë” í° GPUë¡œ êµì²´í•˜ëŠ” ê²ƒì´ ê·¼ë³¸ì ì¸ í•´ê²°ì±…ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤[5][6].</li>
</ul>
<h5 id="gpu">ì°¸ê³ : GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸<a class="headerlink" href="#gpu" title="Permanent link">&para;</a></h5>
<ul>
<li><code>nvidia-smi</code> ë˜ëŠ” <code>GPUtil</code>ì„ ì‚¬ìš©í•´ í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[8][7].</li>
</ul>
<h4 id="_18">ìš”ì•½<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h4>
<p>OOM(Out Of Memory)ì€ ì‹œìŠ¤í…œì´ë‚˜ GPUì˜ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ë•Œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì…ë‹ˆë‹¤. CUDA OOMì„ ì™„í™”í•˜ë ¤ë©´ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°, ëª¨ë¸ ì¶•ì†Œ, í˜¼í•© ì •ë°€ë„ í•™ìŠµ, ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì‚­ì œ, ìºì‹œ ë¹„ìš°ê¸°, ë°ì´í„° í¬ê¸° ì¶•ì†Œ, DataLoader í™œìš© ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ë„ í•´ê²°ì´ ì•ˆ ëœë‹¤ë©´ ë” í° GPUë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤[4][5][6][8][7].</p>
<p>ì¶œì²˜
[1] What Does "Out of Memory" (OOM) Mean? - phoenixNAP https://phoenixnap.com/glossary/out-of-memory
[2] Out of memory - Wikipedia https://en.wikipedia.org/wiki/Out_of_memory
[3] What is OOM? A Guide to Out of Memory Issues - Last9 https://last9.io/blog/what-is-oom/
[4] PyTorch CUDA OutOfMemoryError í•´ê²° https://velog.io/@hly1013/PyTorch-CUDA-OutOfMemoryError-%ED%95%B4%EA%B2%B0
[5] CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±" ì˜¤ë¥˜ê°€ ë°œìƒ - post - í‹°ìŠ¤í† ë¦¬ https://post.tistory.com/entry/CUDA-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EB%B6%80%EC%A1%B1-%EC%98%A4%EB%A5%98%EA%B0%80-%EB%B0%9C%EC%83%9D
[6] [pytorch, ë”¥ëŸ¬ë‹] CUDA out of memory ì—ëŸ¬ í•´ê²°ë°©ë²•(ì´ë¯¸ì§€ ... https://mopipe.tistory.com/192
[7] 10. GPU OOM(Out Of Memory) í•´ê²°ë°©ë²• - ì½”ë”©ì†Œë¹„ - í‹°ìŠ¤í† ë¦¬ https://sobeee.tistory.com/251
[8] Week_3 Pytorch - Out of Memory, OOM í•´ê²° https://memesoo99.tistory.com/53
[9] PyTorchì™€ CUDAë¥¼ ì´ìš©í•œ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ë§ˆìŠ¤í„°í•˜ê¸° https://intelloper.tistory.com/entry/PyTorch-CUDA-GPU-memory-management
[10] Out-of-Memory Error (CUDA Out of Memory): What It Is and How to Fix It https://hatchjs.com/outofmemoryerror-cuda-out-of-memory/
[11] How to Fix CUDA Out of Memory Errors in PyTorch https://hatchjs.com/cuda-out-of-memory-pytorch/
[12] Out-of-Memory (OOM) or Excessive Memory Usage https://www.osc.edu/documentation/knowledge_base/out_of_memory_oom_or_excessive_memory_usage
[13] Out of Memory Killer - Red Hat Learning Community https://learn.redhat.com/t5/Platform-Linux/Out-of-Memory-Killer/td-p/48828
[14] CUDA OOM í•´ê²° ì‚¬ë¡€ ê³µìœ  - PyTorch all_gather_object ì˜ ë¹„ë°€ https://devocean.sk.com/blog/techBoardDetail.do?ID=167403&amp;boardType=techBlog
[15] (ë”¥ëŸ¬ë‹)CUDA out of memory í•´ê²°ë°©ë²• - limmmmm - í‹°ìŠ¤í† ë¦¬ https://limmmmm.tistory.com/10
[16] Linux Out of Memory killer - Knowledge Base - Neo4j https://neo4j.com/developer/kb/linux-out-of-memory-killer/
[17] GPU VRAM Overflow: Causes and Solutions - DiskMFR https://www.diskmfr.com/gpu-vram-overflow-causes-and-solutions/
[18] Here's how to clear GPU memory using 6 methods https://www.pcguide.com/gpu/how-to/clear-memory/
[19] GPU OOMê³¼ ì´ë³„í•˜ëŠ” ë²• https://pizzathiefz.github.io/posts/gpu-out-of-memory/
[20] GPU ë©”ëª¨ë¦¬Â·ì—°ì‚° íš¨ìœ¨ ìµœì í™” ì™„ì „ ê°€ì´ë“œ - Deep Learning study https://hichoe95.tistory.com/143</p>
<h3 id="gpu_1">GPU ë©”ëª¨ë¦¬ ì ˆê° ê¸°ë²•<a class="headerlink" href="#gpu_1" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ê·¸ë ˆì´ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…(Gradient Checkpointing)</strong><br />
  ìˆœì „íŒŒ ê³¼ì •ì—ì„œ ì¤‘ê°„ í™œì„±í™”(activation)ë¥¼ ëª¨ë‘ ì €ì¥í•˜ì§€ ì•Šê³ , í•„ìš”í•œ ì¼ë¶€ë§Œ ì €ì¥í•œ ë’¤ ì—­ì „íŒŒ(backward) ë•Œì—ë§Œ ë‚˜ë¨¸ì§€ëŠ” ì¬ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤. ê³„ì‚°ëŸ‰ì€ ëŠ˜ì–´ë‚˜ì§€ë§Œ, ëŒ€ìš©ëŸ‰ ëª¨ë¸ì˜ í•™ìŠµì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.</li>
<li><strong>ê·¸ë ˆì´ë””ì–¸íŠ¸ ëˆ„ì (Gradient Accumulation)</strong><br />
  ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ ì—¬ëŸ¬ ë¯¸ë‹ˆë°°ì¹˜ì— ëŒ€í•´ ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ ëˆ„ì í•˜ì—¬ í•œ ë²ˆì— ì—…ë°ì´íŠ¸í•¨ìœ¼ë¡œì¨ ì‘ì€ ë°°ì¹˜ë¡œ í° íš¨ê³¼ë¥¼ ë‚´ê³  GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>ë¶„ì‚° ë³‘ë ¬í™”(Data/Model/Tensor Parallelism)</strong><br />
  íŒŒë¼ë¯¸í„°ì™€ ê³„ì‚°ì„ ì—¬ëŸ¬ GPUë¡œ ë¶„ì‚°í•´ ë³‘ë ¬ ì²˜ë¦¬í•˜ë©´ ë‹¨ì¼ GPUë‹¹ ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>ZeRO Optimizer, PEFT(LoRA/QLoRA)</strong><br />
  ì˜µí‹°ë§ˆì´ì €ì˜ ì¤‘ë³µ ë³€ìˆ˜ ì €ì¥ì„ ìµœì†Œí™”(Lora ë“± íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ì¡°ì •)í•¨ìœ¼ë¡œì¨ ëŒ€ê·œëª¨ ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹œ ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤.</li>
<li><strong>KV Cache, Flash Attention</strong><br />
  íŠ¸ëœìŠ¤í¬ë¨¸ ê³„ì—´ì—ì„œ ì£¼ë¡œ ì“°ì´ëŠ” ê¸°ë²•ìœ¼ë¡œ, ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í† í°ì˜ Key/Value í…ì„œë¥¼ ìºì‹±í•˜ê±°ë‚˜, Self-Attention ê³„ì‚°ì„ ë¸”ë¡ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ê³¼ ì—°ì‚° íš¨ìœ¨ì„ ê°œì„ í•©ë‹ˆë‹¤[1][5][4].</li>
</ul>
<h3 id="mixed-precision-training">Mixed Precision Training<a class="headerlink" href="#mixed-precision-training" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>ê°œë…</strong><br />
  ì¼ë¶€ ì—°ì‚°ì„ FP16(16ë¹„íŠ¸ ë¶€ë™ì†Œìˆ˜ì )ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì¤‘ìš”í•œ ì—°ì‚°ì€ FP32(32ë¹„íŠ¸)ë¡œ ìœ ì§€í•˜ëŠ” <em>í˜¼í•© ì •ë°€ë„</em> í•™ìŠµ ë°©ì‹ì…ë‹ˆë‹¤.</li>
<li><strong>íš¨ê³¼</strong><br />
  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ê±°ì˜ ì ˆë°˜ ê°€ê¹Œì´ ì ˆê°ë˜ë©°, ì—°ì‚° ëŒ€ì—­í­ í™œìš© ê·¹ëŒ€í™”ë¡œ í•™ìŠµ ì†ë„ ë˜í•œ ë¹¨ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
<li><strong>ê¸°ìˆ  ì ìš©</strong><br />
  ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬(PyTorch, TensorFlow ë“±)ì—ì„œëŠ” <code>autocast()</code>, <code>GradScaler</code> APIë¡œ ì ìš© ê°€ëŠ¥í•˜ë©°, ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” 32ë¹„íŠ¸ë¡œ ì €ì¥ë˜ê³ , ìˆœì „íŒŒ/ì—­ì „íŒŒ ê³„ì‚° ë° Gradient ì²˜ë¦¬ëŠ” 16ë¹„íŠ¸ ì—°ì‚°ì´ í˜¼í•©ë˜ì–´ ë©”ëª¨ë¦¬/ì†ë„ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤[2][7].</li>
</ul>
<hr />
<p>ì´ì™€ ê°™ì€ GPU ë©”ëª¨ë¦¬ ì ˆê° ë° Mixed Precision ê¸°ìˆ ì€ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ í•™ìŠµê³¼ ì¶”ë¡ ì—ì„œ í•„ìˆ˜ì ì¸ ìš”ì†Œë¡œ, ëª¨ë¸ ê°œë°œì˜ ìƒì‚°ì„±ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì„ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] íš¨ìœ¨ì ì¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìœ„í•œ ì—¬ëŸ¬ ê¸°ë²• - DevOcean - SK https://devocean.sk.com/blog/techBoardDetail.do?ID=167051&amp;boardType=techBlog
[2] GPU ë©”ëª¨ë¦¬Â·ì—°ì‚° íš¨ìœ¨ ìµœì í™” íŒ - Deep Learning study - í‹°ìŠ¤í† ë¦¬ https://hichoe95.tistory.com/136
[3] GPU ë©”ëª¨ë¦¬Â·ì—°ì‚° íš¨ìœ¨ ìµœì í™” ì™„ì „ ê°€ì´ë“œ - Deep Learning study https://hichoe95.tistory.com/143
[4] LLM ì¶”ë¡  ì‹œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•Œì•„ë³´ê¸° https://g3lu.tistory.com/51
[5] íš¨ìœ¨ì ì¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìœ„í•œ ì—¬ëŸ¬ ê¸°ë²• - ë°ë³´ì…˜ - Velopers https://www.velopers.kr/post/2706
[6] GPU ë©”ëª¨ë¦¬ì™€ ëª¨ë¸ ìµœì í™”: ì‹¤ì „ ì‚¬ë¡€ ë¶„ì„ - F-Lab https://f-lab.kr/insight/gpu-memory-and-model-optimization
[7] [ë”¥ëŸ¬ë‹] LLM í•™ìŠµ ë°©ë²• ì •ë¦¬(ëª¨ë¸ ê²½ëŸ‰í™”, GPU ìš”êµ¬ì‚¬í•­, í•™ìŠµ íš¨ìœ¨ ... https://railly-linker.tistory.com/205
[8] GP-GPUë¥¼ ì‚¬ìš©í•œ Deep Learning Inferenceì˜ ë©”ëª¨ë¦¬ ì ˆì•½ ê¸°ë²• https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE10448418
[9] ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì†ë„ë¥¼ 2ë°° ë†’ì´ëŠ” GPU ìµœì í™” ë°©ë²• https://console.runyour.ai/homefeed/gpu-optimization</p>
<hr />
<h2 id="12_1">12. ì¶”ê°€ ê³ ë ¤ ìš”ì†Œ<a class="headerlink" href="#12_1" title="Permanent link">&para;</a></h2>
<h3 id="pruning-quantization-knowledge-distillation">ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²• (Pruning, Quantization, Knowledge Distillation)<a class="headerlink" href="#pruning-quantization-knowledge-distillation" title="Permanent link">&para;</a></h3>
<h4 id="1-pruning">1. Pruning (ê°€ì§€ì¹˜ê¸°)<a class="headerlink" href="#1-pruning" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ê°œë…</strong>: ëª¨ë¸ ë‚´ì—ì„œ ì¤‘ìš”ë„ê°€ ë‚®ê±°ë‚˜ ê±°ì˜ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ” ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ í¬ê¸°ì™€ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.</li>
<li><strong>ì¢…ë¥˜</strong>:  </li>
<li><em>Unstructured Pruning</em>: ê°œë³„ ê°€ì¤‘ì¹˜ë¥¼ ì„ì˜ë¡œ ì œê±°í•´ í¬ì†Œ í–‰ë ¬ì„ ë§Œë“­ë‹ˆë‹¤. í•˜ì§€ë§Œ í•˜ë“œì›¨ì–´ ê°€ì† ìµœì í™”ì—ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.  </li>
<li><em>Structured Pruning</em>: ì±„ë„, í•„í„°, ë ˆì´ì–´ ë‹¨ìœ„ë¡œ ê°€ì§€ì¹˜ê¸°í•˜ì—¬ í•˜ë“œì›¨ì–´ íš¨ìœ¨ì ì¸ ê²½ëŸ‰í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.  </li>
<li><strong>íš¨ê³¼</strong>: ëª¨ë¸ í¬ê¸° ê°ì†Œ, ê³„ì‚° ì†ë„ í–¥ìƒ, ë©”ëª¨ë¦¬ ì ˆê°  </li>
<li><strong>ì ìš©</strong>: ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤ ë° ë¹ ë¥¸ ì¶”ë¡ ì´ í•„ìš”í•œ ì„œë¹„ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤[3][4][5].</li>
</ul>
<h4 id="2-quantization">2. Quantization (ì–‘ìí™”)<a class="headerlink" href="#2-quantization" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ê°œë…</strong>: ëª¨ë¸ íŒŒë¼ë¯¸í„° ë° ì—°ì‚° ê²°ê³¼ë¥¼ ê³ ì •ì†Œìˆ˜ì  ë˜ëŠ” ì €ë¹„íŠ¸ ì •ìˆ˜(ì˜ˆ: 8ë¹„íŠ¸, 4ë¹„íŠ¸)ë¡œ ë³€í™˜í•´ ëª¨ë¸ ì €ì¥ ìš©ëŸ‰ê³¼ ì—°ì‚° ìì›ì„ ì¤„ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.</li>
<li><strong>ë°©ì‹</strong>:  </li>
<li><em>Post-Training Quantization (PTQ)</em>: í›ˆë ¨ ì™„ë£Œ í›„ ì–‘ìí™”  </li>
<li><em>Quantization-Aware Training (QAT)</em>: í•™ìŠµ ê³¼ì •ì—ì„œ ì–‘ìí™”ë¥¼ ê³ ë ¤í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ìµœì†Œí™”  </li>
<li><strong>íš¨ê³¼</strong>: ëª¨ë¸ í¬ê¸° ì¶•ì†Œ, ì—°ì‚° ì†ë„ ì¦ê°€, ì—ë„ˆì§€ íš¨ìœ¨ í–¥ìƒ  </li>
<li>
<p><strong>ì ìš©</strong>: ì œí•œëœ í•˜ë“œì›¨ì–´ì—ì„œ AI ëª¨ë¸ì„ ì›í™œíˆ ì‹¤í–‰í•˜ê³ ì í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤[3][4][5].</p>
</li>
<li>
<p><strong>ì •ì  ì–‘ìí™” (Static Quantization)</strong>:<br />
  ëª¨ë¸ ë°°í¬ ì „, ëª¨ë“  ê°€ì¤‘ì¹˜ì™€ í™œì„±í™”ë¥¼ ê³ ì •ëœ ì €ì •ë°€ë„(ì˜ˆ: INT8)ë¡œ ë³€í™˜  </p>
</li>
<li>ì¥ì : ì¶”ë¡  ì†ë„ í–¥ìƒ, ë©”ëª¨ë¦¬ ì ‘ê·¼ íš¨ìœ¨ ì¦ê°€  </li>
<li>ë‹¨ì : Calibration í•„ìš”(í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ì–‘ìí™” ë²”ìœ„ ë³´ì •), ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥</li>
<li><strong>ë™ì  ì–‘ìí™” (Dynamic Quantization)</strong>:<br />
  í™œì„±í™” ê°’ì„ ì¶”ë¡  ì‹œì ì— ë™ì ìœ¼ë¡œ ì–‘ìí™”  </li>
<li>Per-tensor Dynamic Quantization (Tensor-wise)  </li>
<li>Hybrid Dynamic Quantization (í•˜ì´ë¸Œë¦¬ë“œ ë™ì  ì–‘ìí™”)</li>
</ul>
<h4 id="3-knowledge-distillation">3. Knowledge Distillation (ì§€ì‹ ì¦ë¥˜)<a class="headerlink" href="#3-knowledge-distillation" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>ê°œë…</strong>: í° ëª¨ë¸(teacher)ì´ í•™ìŠµí•œ ì§€ì‹ì„ ì‘ì€ ëª¨ë¸(student)ì—ê²Œ ì „ë‹¬í•˜ì—¬, ì‘ì€ ëª¨ë¸ì´ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚´ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.</li>
<li><strong>ë°©ì‹</strong>: teacher ëª¨ë¸ì˜ ì˜ˆì¸¡(soft targets)ì„ student ëª¨ë¸ì˜ í•™ìŠµ ëª©í‘œë¡œ í•˜ì—¬ ì¼ë°˜ ì •ë‹µ(label)ë³´ë‹¤ ë” í’ë¶€í•œ ì •ë³´ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.</li>
<li><strong>íš¨ê³¼</strong>: ì„±ëŠ¥ì€ ìœ ì§€í•˜ë©´ì„œ ëª¨ë¸ í¬ê¸°ì™€ ì—°ì‚°ëŸ‰ì„ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆìŒ  </li>
<li><strong>ì ìš©</strong>: ëª¨ë°”ì¼, ì„ë² ë””ë“œ ì‹œìŠ¤í…œ ë“± ìì› ì œí•œ í™˜ê²½ì—ì„œ ë³µì¡í•œ ëŒ€í˜• ëª¨ë¸ì„ ê²½ëŸ‰í™”í•˜ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤[3][4][5].</li>
</ul>
<p>ì´ë“¤ ê¸°ë²•ì„ ì ì ˆíˆ ì¡°í•©í•˜ë©´, ë‹¤ì¤‘ ëª©ì ì— ë§ëŠ” ìµœì í™”ëœ ê²½ëŸ‰ AI ëª¨ë¸ ì„¤ê³„ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. íŠ¹íˆ ëª¨ë°”ì¼ ë° ì—£ì§€ ì»´í“¨íŒ…ì—ì„œ ê²½ëŸ‰ ëª¨ë¸ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ë©´ì„œ, Pruning, Quantization, Knowledge Distillationì€ í•„ìˆ˜ì ì¸ í•µì‹¬ ê¸°ìˆ ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] [CNN Networks] 6. ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™” - velog https://velog.io/@woojinn8/LightWeight-Deep-Learning-0.-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EA%B2%BD%EB%9F%89%ED%99%94
[2] [PDF] ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ìˆ  ë¶„ì„ https://repository.kisti.re.kr/bitstream/10580/15591/1/(%EA%B8%B0%EC%88%A0)%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EB%AA%A8%EB%8D%B8%20%EA%B2%BD%EB%9F%89%ED%99%94%20%EA%B8%B0%EC%88%A0%20%EB%B6%84%EC%84%9D.pdf
[3] [ë”¥ëŸ¬ë‹ ê²½ëŸ‰í™”] ëª¨ë¸, ë„¤íŠ¸ì›Œí¬ ê²½ëŸ‰í™” : Quantization - PTQ, QAT https://u-b-h.tistory.com/13
[4] ë”¥ëŸ¬ë‹ ëª¨ë¸ ìµœì í™” ë°©ë²•: ëª¨ë¸ ê²½ëŸ‰í™”ì™€ ëª¨ë¸ ì¶”ë¡  ì†ë„ ê°€ì†í™” https://blog-ko.superb-ai.com/how-to-optimize-deep-learning-models/
[5] [PDF] ê²½ëŸ‰ ë”¥ëŸ¬ë‹ ê¸°ìˆ  ë™í–¥ https://ettrends.etri.re.kr/ettrends/176/0905176005/34-2_40-50.pdf
[6] [ë”¥ëŸ¬ë‹ ê²½ëŸ‰í™”] ì‹¤ë¬´ì—ì„œ ì ìš©ì¤‘ì¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™”/ìµœì í™” ê¸°ë²•ì€? https://developers.hyundaimotorgroup.com/blog/366
[7] [ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™”] ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ Convolution https://sotudy.tistory.com/10
[8] ë”¥ëŸ¬ë‹ ê²½ëŸ‰í™”ë¥¼ ìœ„í•œ êµ¬ì¡°, ê°€ì§€ì¹˜ê¸°, ì§€ì‹ì¦ë¥˜ ë¹„êµ - DBpia https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10672328</p>
<hr />
<h3 id="cnn-transformer">í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ (CNN + Transformer)<a class="headerlink" href="#cnn-transformer" title="Permanent link">&para;</a></h3>
<p>CNNê³¼ Transformerì˜ ê²°í•© í˜•íƒœëŠ” ì´ë¯¸ì§€, ì˜ìƒ ë“± ë³µì¡í•œ ë°ì´í„°ì—ì„œ ì§€ì—­(Local) ë° ì „ì—­(Global) íŠ¹ì§•ì„ ë™ì‹œì— í¬ì°©í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì…ë ¥ì˜ ì €ìˆ˜ì¤€ íŒ¨í„´(ëª¨ì„œë¦¬, í…ìŠ¤ì²˜)ì€ CNNìœ¼ë¡œ ì¶”ì¶œí•˜ê³ , ì´í›„ Transformer ë¸”ë¡ì—ì„œ ì „ì—­ì  ì˜ì¡´ì„±, ë§¥ë½ ì •ë³´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ììœ¨ì£¼í–‰, ì˜ë£Œ ì˜ìƒ ë¶„í•  ë“±ì—ì„œ CNNì€ ë””í…Œì¼í•œ ê°ì²´ ê°ì§€ì—, TransformerëŠ” ì „ì²´ ì¥ë©´ì˜ ì˜ë¯¸ í•´ì„ì— ê°•ì ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŸ° êµ¬ì¡°ëŠ” ì„±ëŠ¥, íš¨ìœ¨ ë‘ ì¸¡ë©´ ëª¨ë‘ì—ì„œ ê¸°ì¡´ ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ë›°ì–´ë‚œ ê· í˜•ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ CMT, BEFUnet, MobileViT, ConvNeXt ë“± ë‹¤ì–‘í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ë“¤ì´ í˜„ì—…ì— ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤[1][2].</p>
<hr />
<h3 id="vision-language-audio-text">ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ ì„¤ê³„ (Vision-Language, Audio-Text)<a class="headerlink" href="#vision-language-audio-text" title="Permanent link">&para;</a></h3>
<p>ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ìœ í˜•(ì˜ˆ: ì´ë¯¸ì§€+í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤+ë¬¸ì)ì—ì„œ ì •ë³´ë¥¼ ê²°í•©í•´ ë” í’ë¶€í•œ ì¶”ë¡  ë° ìƒì„± ëŠ¥ë ¥ì„ íšë“í•˜ë„ë¡ ì„¤ê³„ë©ë‹ˆë‹¤. ê° ëª¨ë‹¬ë¦¬í‹° ë³„ë¡œ ì „ë¬¸ ì¸ì½”ë”(ì˜ˆ: CNN/ViT for vision, Transformer for text, Spectrogram+Transformer for audio)ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , ì´í›„ ê³µí†µ ì˜ë¯¸ ê³µê°„(latent space)ì—ì„œ í†µí•©í•©ë‹ˆë‹¤. ëŒ€í‘œì  ê¸°ìˆ ë¡œ CLIP(ì´ë¯¸ì§€/í…ìŠ¤íŠ¸), VLM(ë¹„ì „-ì–¸ì–´ ëª¨ë¸), AudioLM(ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸) ë“±ì´ ìˆìœ¼ë©°, ì´ë¯¸ì§€ ì„¤ëª…, ì§ˆì˜ì‘ë‹µ, ë©€í‹°ë¯¸ë””ì–´ ë¶„ì„ ê°™ì€ ë³µí•© íƒœìŠ¤í¬ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤[3][4].</p>
<hr />
<h3 id="_19">í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì™€ êµ¬ì¡° ì„¤ê³„ì˜ ê´€ê³„<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h3>
<p>í•˜ì´í¼íŒŒë¼ë¯¸í„°(ì˜ˆ: í•™ìŠµë¥ , ì€ë‹‰ì¸µ/ë…¸ë“œ ìˆ˜, ë“œë¡­ì•„ì›ƒ, ê·œì œ, ë°°ì¹˜ ì‚¬ì´ì¦ˆ ë“±)ëŠ” ëª¨ë¸ êµ¬ì¡°ì˜ ë³µì¡ì„±ê³¼ í•™ìŠµ íŒ¨í„´ì„ ê²°ì •ì§“ëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. ì ì ˆí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì€ ê³¼ì í•©/ê³¼ì†Œì í•© ê· í˜•, ëª¨ë¸ì˜ í‘œí˜„ë ¥, ë°ì´í„° ë° ë¬¸ì œ íŠ¹ì„±ì— ë§ëŠ” ìµœì  êµ¬ì¡° ì„ íƒì— ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ Dropout ë¹„ìœ¨ì´ë‚˜ Layer ìˆ˜ ì„¤ì •ì€ êµ¬ì¡°ì˜ ë³µì¡ì„±ì„ ì œì–´í•˜ê³ , ê·œì œ íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ ì•ˆì •ì„±ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
íŠœë‹ ë°©ì‹ì— ë”°ë¼ ëª¨ë¸ êµ¬ì¡° ì„ íƒê³¼ ì„±ëŠ¥ ë‹¬ì„±ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ì£¼ë¯€ë¡œ, êµ¬ì¡° ì„¤ê³„ ê³¼ì •ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ í•„ì—°ì ìœ¼ë¡œ ë³‘í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤[5][6].</p>
<hr />
<h3 id="explainability">ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±(Explainability)ê³¼ ì„¤ê³„<a class="headerlink" href="#explainability" title="Permanent link">&para;</a></h3>
<p>AI ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±(Explainability)ì€ ì˜ˆì¸¡Â·íŒë‹¨ ê²°ê³¼ì— ëŒ€í•´ ì‚¬ëŒì´ ì›ë¦¬Â·ê·¼ê±°ë¥¼ ì´í•´í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” ì„¤ê³„ ìš”ì†Œì…ë‹ˆë‹¤. ë†’ì€ í•´ì„ ê°€ëŠ¥ì„±ì„ ê°€ì§€ë ¤ë©´, ëª¨ë¸ êµ¬ì¡°ê°€ ëª…í™•í•œ ì¸ê³¼ ê´€ê³„ë¥¼ ë“œëŸ¬ë‚´ê±°ë‚˜(post-hoc ë¶„ì„ ê°€ëŠ¥ì„± ë“±), ë‚´ì¬ì ìœ¼ë¡œ ì§ê´€ì ì¸ ê°€ì‹œì„±ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
ì„¤ëª… ê°€ëŠ¥ì„±ì´ ë³´ì¥ë˜ë©´ AIì˜ ì‹ ë¢°ì„±, íˆ¬ëª…ì„±, ìœ¤ë¦¬ì  ì±…ì„, ë””ë²„ê¹… ë° ê°œì„  ìš©ì´ì„± ë“± ì—¬ëŸ¬ íš¨ìš©ì´ ë†’ì•„ì§‘ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì˜ì‚¬ê²°ì • ê²½ë¡œë¥¼ ê¸°ë¡í•˜ê³ , Feature Importance ë¶„ì„, Attention Map, Rule-based Layer ë“± ë‹¤ì–‘í•œ XAI ê¸°ë²•ì„ ëª¨ë¸ ì„¤ê³„ì— ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤[7].</p>
<hr />
<p>ê²°ë¡ ì ìœ¼ë¡œ, ê° ìš”ì†ŒëŠ” ì‹¤ì „ AI ì‹œìŠ¤í…œ ì„¤ê³„ì—ì„œ ì„±ëŠ¥, í™•ì¥ì„±, ì‹ ë¢°ì„±, íš¨ìœ¨ì„±ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ í•µì‹¬ ê¸°ìˆ ì  ì „ëµì˜ ì¼ë¶€ì…ë‹ˆë‹¤.</p>
<p>ì¶œì²˜
[1] CNN ëŒ€ íŠ¸ëœìŠ¤í¬ë¨¸: ì´ë¯¸ì§€ ì¸ì‹ ëª¨ë¸ ì„¤ëª… - Flypix https://flypix.ai/ko/blog/image-recognition-models-cnns/
[2] [Paper Review] CMT ë…¼ë¬¸ ì´í•´í•˜ê¸° https://rahites.tistory.com/373
[3] ë©€í‹°ëª¨ë‹¬ AIë€? LLMì„ ë„˜ëŠ” ì°¨ì„¸ëŒ€ ì¸ê³µì§€ëŠ¥ì˜ í•µì‹¬ ê¸°ìˆ  https://www.koreadeep.com/blog/multimodal-ai
[4] ë©€í‹°ëª¨ë‹¬ VLM ê¸°ìˆ  ë™í–¥ - í•œì»´í…Œí¬ https://tech.hancom.com/multimodal-vlm-trends/
[5] AI ëª¨ë¸ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì™„ë²½ ê°€ì´ë“œ https://www.impactive-ai.com/insight/what-is-hyper-parameter-tuning
[6] 06-2 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ - ëª¨ë¸ ì„±ëŠ¥ ìµœì í™”í•˜ê¸° - ìœ„í‚¤ë…ìŠ¤ https://wikidocs.net/273831
[7] AI ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± ì—°êµ¬: ì¸ê³µì§€ëŠ¥ì˜ íˆ¬ëª…ì„±ê³¼ ì‹ ë¢°ì„± í™•ë³´ ë°©ì•ˆ https://s1275702.tistory.com/entry/AI-%EB%AA%A8%EB%8D%B8-%ED%95%B4%EC%84%9D-%EA%B0%80%EB%8A%A5%EC%84%B1-%EC%97%B0%EA%B5%AC-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%98-%ED%88%AC%EB%AA%85%EC%84%B1%EA%B3%BC-%EC%8B%A0%EB%A2%B0%EC%84%B1-%ED%99%95%EB%B3%B4-%EB%B0%A9%EC%95%88
[8] [ë…¼ë¬¸ ë¦¬ë·°] CMT: Convolutional Neural Networks Meet Vision ... https://day-to-day.tistory.com/59
[9] [ë…¼ë¬¸ ë¦¬ë·°] BEFUnet: A Hybrid CNN-Transformer Architecture for ... https://www.themoonlight.io/ko/review/befunet-a-hybrid-cnn-transformer-architecture-for-precise-medical-image-segmentation
[10] 01. A survey of the Vision Transformers and its CNN-Transformer ... https://wikidocs.net/237414
[11] [ë…¼ë¬¸ ë¦¬ë·°] X-ray illicit object detection using hybrid CNN-transformer ... https://www.themoonlight.io/ko/review/x-ray-illicit-object-detection-using-hybrid-cnn-transformer-neural-network-architectures</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "search.suggest", "search.highlight", "content.code.copy"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.92b07e13.min.js"></script>
      
    
  </body>
</html>