## 1. 데이터 수집 개요 (추가)
- 데이터 수집의 정의와 목적

> 데이터 수집은 특정 목적을 달성하기 위해 필요한 정보를 체계적으로 모으는 과정으로 설문조사, 실험, 웹 스크래핑, 센서 등을 통해 얻습니다.
> 데이터 수집의 주된 목적은 AI 모델이 유의미한 패턴을 학습하고, 이를 통해 정확한 예측이나 분류를 수행할 수 있도록 하는 것입니다.
> 1. **모델 학습 및 성능 향상**: AI 모델은 방대한 양의 데이터에서 특징을 추출하고 패턴을 인식합니다. 수집된 데이터의 양이 많을수록, 그리고 질이 좋을수록 모델의 성능은 비례하여 향상됩니다.
> 2. **새로운 문제 해결**: 새로운 문제를 해결하거나 새로운 기능을 개발하기 위해 데이터가 필요합니다. 예를 들어, 자율주행 기술을 개발하려면 도로 상황, 보행자, 신호등 등 실제 주행 환경에 대한 데이터를 끊임없이 수집해야 합니다.
> 3. **편향성(Bias) 감소**: 다양한 소스에서 데이터를 수집함으로써 특정 집단이나 상황에 대한 편향을 줄일 수 있습니다. 이는 AI 모델이 더 공정하고 보편적인 결과를 내는 데 필수적입니다.
>   즉, 정 그룹에 편파적 정보로 인한 표현 편향, 데이터 불균형에 다른 특정 부분에 정확도 하락, 그로 인한 서비스 불공정 등의 분포 편향등을 개선함으로써 AI 모델의 공정성과 신뢰성을 높일 수 있습니다.
> 4. **모델 신뢰성 확보**: 모델이 예측한 결과의 근거가 되는 데이터를 명확히 함으로써, 모델의 결정 과정을 이해하고 신뢰도를 높일 수 있습니다.

- 데이터 수집의 중요성

> 데이터 품질이 AI모델의 성능과 직결되므로 수집되는 데이터의 품질을 높이는 것이 중요하다
> 1. **모델 성능의 결정적 요인**: AI 모델의 성능은 알고리즘보다 학습 데이터의 품질과 양에 의해 더 크게 좌우됩니다. 아무리 복잡하고 뛰어난 알고리즘을 사용하더라도, 입력 데이터가 불완전하거나 편향되어 있다면 모델의 예측 정확도는 낮아집니다.
>
>     예시: 챗봇을 만들 때 다양한 대화 패턴을 담은 데이터를 많이 수집해야 사용자의 질문에 정확하고 자연스럽게 답변할 수 있습니다.
> 2. **편향성(Bias) 및 공정성 문제 해결**: 수집된 데이터에 특정 그룹에 대한 편향이 포함되어 있으면, AI 모델도 이러한 편향을 그대로 학습하게 됩니다. 다양한 배경과 상황을 포괄하는 데이터를 수집해야 모델이 더 공정하고 신뢰성 있는 결과를 내놓을 수 있습니다.
>
>     예시: 채용 서류를 심사하는 AI를 개발할 때, 특정 성별이나 출신 대학에 편향된 과거 데이터를 사용하면 불공정한 결과를 초래할 수 있습니다.
> 3. **현실 문제 해결 능력 향상**: AI는 학습한 데이터 내의 패턴만 인식할 수 있습니다. 실제 환경에서 발생하는 다양한 변수들을 반영한 데이터를 수집해야만, AI가 현실의 복잡한 문제를 효과적으로 해결할 수 있습니다.
>
>     예시: 자율주행차는 비 오는 날, 안개가 낀 날, 야간 등 다양한 기상 조건의 도로 데이터를 충분히 학습해야 안전하게 운행할 수 있습니다.
> 4. **모델의 과적합(Overfitting) 방지**: 불충분한 데이터로 모델을 학습시키면, 모델이 일반적인 패턴을 학습하지 못하고 특정 데이터에만 과도하게 맞춰지는 과적합 문제가 발생할 수 있습니다. 충분하고 다양한 데이터를 수집하면 이러한 위험을 줄일 수 있습니다.

- AI 프로젝트에서 데이터 수집의 단계

## 2. 데이터 수집 방법 (추가) 
| 방법 | 설명 |
| :---: | :--- |
|웹 크롤링/스크래핑 (Web Crawling/Scraping)|웹사이트를 자동으로 탐색하고 필요한 데이터를 추출하는 기술입니다. 크롤링은 웹페이지를 돌아다니며 데이터를 수집하는 행위이고, 스크래핑은 특정 페이지에서 원하는 데이터를 긁어오는 행위입니다.|
|오픈 API (Open API)| 서비스 제공자가 데이터에 접할 수 있게 제공하는 interface|
|센서 및 IoT 장치|사물 인터넷(IoT) 장치나 센서를 통해 실시간으로 데이터를 수집하는 방법입니다.|
|공개 데이터셋|일반적으로 CSV나 JSON, XML같은 형식의 파일임|
|UGC(사용자 생성 데이터)|일반 사용자가 자발적으로 만들고 공유하는 모든 형태의 콘텐츠입니다.|

**데이터 수집 시 법적·윤리적 고려 사항**
1. 개인정보 보호법 : 세부 규정으로 동의 원칙, 최소 수집의 원칙, 안전성 확보 의무가 있다.
2. GDPR : 유럽연합(EU)의 개인정보보호 규정으로, 개인정보의 주체(데이터 주체)가 자신의 정보에 대해 더 큰 통제권을 가질 수 있도록 여러 권리를 보장합니다.
    - 정보를 제공받을 권리, 접근권, 정정권, 삭제권 (잊힐 권리), 처리 제한권, 데이터 이동권 등의 정보 소유자의 권리
    - 투명성, 동의 보안, 침해통지 등 기업의 책임
3. 저작권-지적재산 : 저작물을 경제적으로 이용하고 대가를 받을 수 있는 권리입니다. 
    - 복제권, 배포권, 공연권, 공중송신권, 전시권, 2차적 저작물 작성권 등이 있습니다.
4. 저작권-저작인격권 : 저작자의 인격과 관련된 권리입니다
    - 공표권, 성명표시권, 동일성유지권

민감 데이터 처리 가이드라인
> 1. 명확한 동의와 목적 제한 : 명시적 동의, 최소한의 정보 수집, 목적 외 이용 금지
> 2. 강력한 보안 조치 : 접근 통제, 암호화, 접근 기록, 안전한 폐기
> 3. 가명 처리 : 개인을 식별할 수 없도록 하는 방법이나, 개인식별 가능한 정보는 별도로 보관 되므로 추후 결함시 재식별 가능
> 4. 익명 처리 : 다시 개인을 식별하는 것이 불가능하게 만드는 것입니다
> 5. 기타 사항 : PIA(Privacy Impact Assessment), 즉 개인정보 영향평가로 사전에 잠재요인 분석 개선방안 수립등의 절차입니다.
>    사전예방, 법규준수, 효율성 증대, 정보 주체 권리 보호등이 체크 항목이다.

## 3. 데이터 라벨링
### 개념
  * 원시 데이터에 정답(레이블)을 부여하는 작업
  * 주로 지도학습(supervised learning)에서 사용되며, 입력과 출력 간의 관계를 학습시키기 위해 필요
### 데이터 유형에 따른 라벨링 방식
  * 이미지 데이터: 클래스 이름, 바운딩 박스 좌표, 세그멘테이션 마스크 등
  * 텍스트 데이터: 감정 분류, 개체명 인식, 텍스트 요약 등
  * 오디오 데이터: 음성 텍스트 전사, 화자 감정
  * 비디오 데이터: 객체 추적, 이벤트 분류
### 라벨링 주의사항
  * 사람이 라벨을 붙이는 경우 주관성이나 일관성 문제
  * 데이터 불균형으로 인한 모델 편향
  * 라벨 오류로 인해 발생하는 오답 학습

### 라벨링 도구와 플랫폼
* 오픈소스

|툴|설명|
| :---: | :--- |
|CVAT (Computer Vision Annotation Tool)| 이미지 및 동영상 라벨링에 특화된 도구|
|LabelImg|이미지 객체 감지(Object Detection)를 위한 바운딩 박스 라벨링에 초점을 맞춘 간단하고 직관적인 도구|
|Label Studio|이미지, 텍스트, 오디오, 동영상 등 다양한 데이터 유형을 모두 라벨링할 수 있는 범용적인 도구입니다|
|Labelme|폴리곤 기반의 라벨링에 특화된 도구로, 복잡한 모양의 객체를 라벨링하는 데 유용합니다.API를 제공하여 자동화된 라벨링 워크플로우를 구축할 수 있습니다.|

* 상용제

|툴|설명|
| :---: | :--- |
|Labelbox| 데이터 라벨링을 위한 엔드-투-엔드 솔루션을 제공합니다|
|V7| 데이터 라벨링을 위한 엔드-투-엔드 솔루션을 제공합니다|
|Labelbox| 컴퓨터 비전 분야에 강력한 기능을 제공하는 플랫폼입니다. AI 기반 자동 라벨링(Auto-labeling) 기능을 통해 작업자의 라벨링 시간을 단축시켜 생산성을 크게 높일 수 있습니다.|
|Appen / Sama / Scale A| 데이터 라벨링 서비스를 전문적으로 제공하는 업체들입니다.|

### 라벨 품질 검증 방법
* 전문가 검수 (Expert Review) : 가장 확실하고 정확한 방법입니다. 해당 분야의 전문가가 직접 라벨링된 데이터를 확인하고 오류를 수정합니다.
* 크로스 체크 (Cross-Checking) : 여러 명의 작업자가 같은 데이터를 독립적으로 라벨링한 후, 결과물을 비교하여 일치하지 않는 부분을 찾아냅니다.
* 통계적 검증 (Statistical Validation) : 라벨링된 데이터의 통계적 특성을 분석하여 품질을 검증하는 방법입니다.
>    라벨 분포 확인: 라벨링된 데이터의 클래스 분포가 균형을 이루는지 확인합니다. 특정 클래스에 데이터가 너무 적거나 많으면 모델 학습에 문제가 생길 수 있습니다.
>    오류율 분석: 무작위로 추출한 샘플 데이터의 오류율을 측정하고, 전체 데이터셋의 오류율을 추정합니다.
* 자동화된 검증 (Automated Validation)
>    모델 기반 검증: 라벨링된 데이터를 기반으로 모델을 학습시킨 후, 이 모델이 예측한 결과와 사람이 라벨링한 결과를 비교하여 불일치하는 부분을 찾아냅니다.
* 검증 과정에서 발견된 오류를 작업자에게 피드백하여, 라벨링 작업의 정확도를 지속적으로 개선합니다. (피드백 루프 구축 (Feedback Loop))

### **라벨링 효율화 기법**
> 1. **능동학습(Active Learning)** : 모델이 가장 불확실한 샘플만 골라서 사람이 라벨링
> 2. Semi-Supervised Learning (반지도 학습) : 라벨링 데이터와 비 라벨링 데이터를 혼합 사용
>    Pseudo-labeling : 모델이 비라벨링 데이터에 대해 예측을 하고 다시 학습에 사용
>    Consistency Regularization : 입력이 유사할 시 예측이 유사해야 한다는 규칙을 적용
>    Graph-based Methods : 데이터 간 유사성을 그래프로 표현해 라벨 전파
>    Generative Models : 데이터 분포를 학습해 라벨 없는 데이터도 잘 설명
> 3. Weak Supervision : 불완전하거나 부정확한 라벨 소스를 결합해 자동 라벨 생성
> 4. 전이 학습 : 사전 모델을 사용하여 필요한 라벨링 데이터 수를 줄임
> 5. Self-Supervised Learning (자기 지도 학습)
>    1단계. 라벨이 없는 데이터에서 '보조 문제(Pretext Task)'를 만들고, 이 문제를 해결하면서 모델을 학습시킵니다.
>    2단계. 파인튜
> 6. Rule-Based Labeling (규칙 기반 자동 라벨링) : 도메인 지식을 활용해 라벨링 규칙 정의

## 4. 데이터 저장 및 관리 (추가)
* 저장 장소
    > 데이터 레이크 (Data Lake) : 원시 상태의 정형, 비정형 데이터를 모두 저장하는 중앙 집중식 저장소입니다
    > 클라우드 스토리지
* 데이터 파이프라인 (Data Pipeline)
    > 데이터가 원천(source)에서 AI 모델로 전달되는 모든 과정을 자동화하고 효율화하는 시스템입니다. 이 과정은 크게 수집, 전처리, 학습/추론, 재학습 단계로 나뉩니다.
* 데이터 거버넌스 및 관리 (Governance & Management) : 보안 및 접근 제어, 버전 관리, 데이터 품질 관리