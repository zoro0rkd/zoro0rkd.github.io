
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://zoro0rkd.github.io/AI-%EB%AA%A8%EB%8D%B8-%ED%8A%9C%EB%8B%9D-%E2%80%90-NEW/">
      
      
        <link rel="prev" href="../AI-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%EA%B3%BC-%ED%8F%89%EA%B0%80-%E2%80%90-NEW/">
      
      
        <link rel="next" href="../AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%E2%80%90-NEW/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>AI 모델 튜닝 - Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Notes" class="md-header__button md-logo" aria-label="Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              AI 모델 튜닝
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Notes" class="md-nav__button md-logo" aria-label="Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    홈
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 데이터 전처리
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI 데이터 전처리
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%88%98%EC%A7%91-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 수집
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EC%A0%9C-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 정제
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 증강
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 모델 개발
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            AI 모델 개발
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%84%A4%EA%B3%84-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 모델 아키텍처 설계
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../XAI-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    XAI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%EA%B3%BC-%ED%8F%89%EA%B0%80-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 모델 학습과 평가
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    AI 모델 튜닝
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    AI 모델 튜닝
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 모델 튜닝 개요
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-hpo-hyperparameter-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      2. 하이퍼파라미터 최적화(HPO, Hyperparameter Optimization)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 하이퍼파라미터 최적화(HPO, Hyperparameter Optimization)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 HPO 개요
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 HPO 기법
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 HPO 실무 고려사항
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-class-imbalanced" class="md-nav__link">
    <span class="md-ellipsis">
      3. 클래스 불균형(Class Imbalanced) 문제 해결
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 클래스 불균형(Class Imbalanced) 문제 해결">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 클래스 불균형 개요
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-data-level" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 데이터 수준(Data-level) 접근
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-algorithm-level" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 알고리즘 수준(Algorithm-level) 접근
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 평가 단계 고려
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. 모델 튜닝과 평가 연계
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. 실무 적용 사례
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-mlops" class="md-nav__link">
    <span class="md-ellipsis">
      6. 튜닝 자동화와 MLOps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 시스템 구축
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            AI 시스템 구축
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 시스템 설계 및 배포
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%B5%9C%EC%A0%81%ED%99%94-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 시스템 최적화
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EC%A3%BC%EC%9A%94-AI-%EA%B8%B0%EC%88%A0-%ED%8A%B8%EB%9E%9C%EB%93%9C/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    주요 AI 기술 트랜드
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EC%9C%A0%EC%9A%A9%ED%95%9C-%EC%82%AC%EC%9D%B4%ED%8A%B8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    유용한 사이트
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../FSDL2022/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FSDL2022
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 모델 튜닝 개요
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-hpo-hyperparameter-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      2. 하이퍼파라미터 최적화(HPO, Hyperparameter Optimization)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 하이퍼파라미터 최적화(HPO, Hyperparameter Optimization)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 HPO 개요
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 HPO 기법
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-hpo" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 HPO 실무 고려사항
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-class-imbalanced" class="md-nav__link">
    <span class="md-ellipsis">
      3. 클래스 불균형(Class Imbalanced) 문제 해결
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 클래스 불균형(Class Imbalanced) 문제 해결">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 클래스 불균형 개요
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-data-level" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 데이터 수준(Data-level) 접근
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-algorithm-level" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 알고리즘 수준(Algorithm-level) 접근
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 평가 단계 고려
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. 모델 튜닝과 평가 연계
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. 실무 적용 사례
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-mlops" class="md-nav__link">
    <span class="md-ellipsis">
      6. 튜닝 자동화와 MLOps
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>AI 모델 튜닝</h1>

<div><h2 id="1">1. 모델 튜닝 개요<a class="headerlink" href="#1" title="Permanent link">¶</a></h2>
<ul>
<li>모델 튜닝의 정의와 필요성<ul>
<li>하이퍼파라미터 튜닝(Hyperparameter Tuning)은 머신러닝이나 딥러닝 모델의 성능을 최적화하기 위해 사전에 설정하는 매개변수를 조정하는 과정</li>
<li>튜닝이 필요한 이유<ul>
<li>성능 최적화 : 과적합(overfitting)이나 언더피팅(underfitting)을 방지</li>
<li>일반화 능력 향상 : 새로운 데이터에 잘 작동하도록 조정</li>
<li>효율적인 학습 : 더 빠르게 수렴하고 계산 자원 절약</li>
</ul>
</li>
</ul>
</li>
<li>하이퍼파라미터(Hyperparameter)와 파라미터(Parameter) 차이</li>
</ul>
<table>
<thead>
<tr>
<th>항목</th>
<th>파라미터(Parameter)</th>
<th>하이퍼파라미터(Hyperparameter)</th>
</tr>
</thead>
<tbody>
<tr>
<td>정의</td>
<td>모델이 학습을 통해 자동으로 결정하는 값 (e.g. 가중치, 편향)</td>
<td>학습 전 수동으로 설정해야 하는 값 (e.g. learning rate, batch size)</td>
</tr>
<tr>
<td>학습 여부</td>
<td>데이터 기반 학습됨</td>
<td>수동 또는 자동 탐색 필요</td>
</tr>
<tr>
<td>예시</td>
<td>신경망의 weight, bias</td>
<td>optimizer, dropout rate, layer 수, hidden unit 수</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>튜닝 대상 파라미터 우선순위 선정 기준</strong><ul>
<li>모델 성능에 민감한 순으로 조정<ul>
<li>학습률 (learning rate): 가장 큰 영향력</li>
<li>모델 복잡도 관련: hidden units, depth, regularization</li>
<li>데이터 관련: batch size, epoch</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2-hpo-hyperparameter-optimization">2. 하이퍼파라미터 최적화(HPO, Hyperparameter Optimization)<a class="headerlink" href="#2-hpo-hyperparameter-optimization" title="Permanent link">¶</a></h2>
<h3 id="21-hpo">2.1 HPO 개요<a class="headerlink" href="#21-hpo" title="Permanent link">¶</a></h3>
<ul>
<li>정의와 목표<ul>
<li>정의: 최적 성능을 내는 하이퍼파라미터 조합을 자동으로 탐색하는 기법</li>
<li>목표: 최소한의 계산 비용으로 성능을 극대화하는 하이퍼파라미터 조합 탐색</li>
</ul>
</li>
<li>탐색 공간(Search Space) 설정<ul>
<li>튜닝할 하이퍼파라미터의 범위 및 타입을 정의<ul>
<li>범주형 (categorical): optimizer 종류</li>
<li>정수형 (int): layer 수</li>
<li>연속형 (float): learning rate</li>
</ul>
</li>
<li>예시</li>
</ul>
</li>
</ul>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

params = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None]
}

grid = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=5)
grid.fit(X_train, y_train)
print(grid.best_params_)  # 최적 하이퍼파라미터 출력
</code></pre>
<ul>
<li>목적 함수(Objective Function) 정의<ul>
<li>입력: 하이퍼파라미터 조합</li>
<li>출력: 성능 평가 지표 (예: validation accuracy, F1 score)</li>
<li>예시: val_loss = objective(params)</li>
</ul>
</li>
</ul>
<h3 id="22-hpo">2.2 HPO 기법<a class="headerlink" href="#22-hpo" title="Permanent link">¶</a></h3>
<table>
<thead>
<tr>
<th>기법</th>
<th>개요</th>
<th>탐색 전략</th>
<th>장점</th>
<th>단점</th>
<th>활용 예 / 특징</th>
</tr>
</thead>
<tbody>
<tr>
<td>Grid Search</td>
<td>모든 가능한 하이퍼파라미터 조합을 체계적으로 탐색</td>
<td>전수조사(Brute-force)</td>
<td>간단하고 구현 쉬움</td>
<td>계산량이 폭발적으로 증가, 효율성 낮음</td>
<td>소규모 탐색 공간에서만 적합</td>
</tr>
<tr>
<td>Random Search</td>
<td>랜덤하게 조합을 선택하여 탐색</td>
<td>무작위 탐색</td>
<td>고차원 공간에서 효율적, 불필요한 계산 줄임</td>
<td>중요한 조합을 놓칠 수 있음</td>
<td>대규모 탐색 공간에서 더 효과적</td>
</tr>
<tr>
<td>Bayesian Optimization</td>
<td>이전 결과를 기반으로 다음 탐색 지점을 예측</td>
<td>확률 모델 기반 탐색</td>
<td>계산 효율 높음, 적은 반복으로 좋은 결과 가능</td>
<td>초기 모델 설계 복잡, 병렬처리 어려움</td>
<td>Gaussian Process, Tree-structured Parzen Estimator (TPE) 등 사용</td>
</tr>
<tr>
<td>Evolutionary Algorithm</td>
<td>유전 알고리즘 기반으로 생존/돌연변이/교배를 통해 최적 해 탐색</td>
<td>진화 기반 최적화</td>
<td>비선형 공간에서도 작동, 전역 최적화에 강함</td>
<td>수렴 속도 느림, 계산 비용 큼</td>
<td>강화학습, 복잡한 신경망 구조 탐색에 사용</td>
</tr>
<tr>
<td>Hyperband / ASHA</td>
<td>성능 기반 조기 중단과 리소스 재할당을 통해 효율적으로 탐색</td>
<td>Successive Halving 기반</td>
<td>빠른 탐색, 비효율적인 조합에 자원 낭비 적음</td>
<td>초반 성능이 낮은 모델이 좋은 결과일 수 있음</td>
<td>대규모 분산 환경에서 적합</td>
</tr>
<tr>
<td>Meta-Learning</td>
<td>이전 학습 결과를 활용해 새로운 HPO에 빠르게 적응</td>
<td>경험 기반 메타 학습</td>
<td>빠른 적응 가능, 기존 데이터 활용</td>
<td>메타 데이터 구축 필요, 일반화 어려움</td>
<td>AutoML, Task Transfer 기반 학습에 활용</td>
</tr>
<tr>
<td>Population-Based Training (PBT)</td>
<td>여러 모델을 동시에 훈련하고 잘 수행되는 모델로 파라미터 업데이트</td>
<td>진화 + 탐색 동시 수행</td>
<td>탐색과 학습 병렬 수행, 튜닝 자동화 가능</td>
<td>리소스 많이 소모, 구현 복잡</td>
<td>AlphaStar, LLM 미세조정 등에 활용</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>그리드 서치(Grid Search)</strong>  <ul>
<li>모든 하이퍼파라미터 조합을 완전 탐색  </li>
<li>단순, 직관적이지만, 계산 비용 매우 큼, 고차원에서는 비효율적  </li>
<li>탐색 방식: 하이퍼파라미터의 가능한 값들을 격자 형태로 구성하고, 모든 조합을 실험  </li>
<li>장점: 전수조사 방식으로 최적값을 반드시 찾을 수 있음  </li>
<li>단점: 차원이 많아질수록 조합 수가 기하급수적으로 늘어나 계산 비효율 발생</li>
</ul>
</li>
<li><strong>랜덤 서치(Random Search)</strong>  <ul>
<li>무작위 조합으로 탐색  </li>
<li>효율적이고 빠름  </li>
<li>탐색 방식: 각 하이퍼파라미터를 사전 정의된 분포에서 무작위로 샘플링하여 실험  </li>
<li>장점: 탐색 자원을 중요한 파라미터에 집중할 확률이 높음  </li>
<li>단점: 실험 결과의 일관성이 부족하며, 운에 따라 품질 편차 가능  </li>
</ul>
</li>
<li><strong>베이지안 최적화(Bayesian Optimization)</strong><ul>
<li>이전 탐색 결과를 바탕으로 다음 탐색 포인트를 탐색 vs 활용(Exploration vs Exploitation) 균형으로 선택 (대표 라이브러리: Optuna, Hyperopt)  </li>
<li>효율적이지만 구현 복잡  </li>
<li>탐색 방식: 가우시안 프로세스(GP), Tree-structured Parzen Estimator(TPE) 등으로 성능을 예측하는 확률 모델 구축 → 다음 실험 위치 예측  </li>
<li>획득 함수(Acquisition Function): Expected Improvement, UCB 등  </li>
<li>장점: 적은 실험으로도 좋은 성능 가능, 계산 효율성 우수  </li>
<li>단점: 모델링 복잡도와 계산 비용이 존재, 범용성은 낮음</li>
</ul>
</li>
<li><a href="https://jeongchul.tistory.com/845"><strong>진화 알고리즘(Evolutionary Algorithm)</strong></a>  <ul>
<li>하이퍼파라미터를 유전 연산자로 변형하면서 탐색, 개체군(Population) 기반 탐색  </li>
<li>핵심 요소</li>
<li><strong>개체 (Individual)</strong>  <ul>
<li>하나의 하이퍼파라미터 조합(예: <code>learning_rate=0.01, batch_size=64</code>)</li>
</ul>
</li>
<li><strong>집단 (Population)</strong>  <ul>
<li>여러 개체의 집합</li>
<li>각 세대(generation)마다 전체 집단을 평가하고, 성능이 높은 개체를 중심으로 다음 세대를 생성</li>
</ul>
</li>
<li><strong>적합도 함수 (Fitness Function)</strong>  <ul>
<li>개체의 성능을 평가하는 기준 (예: validation accuracy, validation loss)</li>
<li>최적의 하이퍼파라미터를 찾기 위한 지표</li>
</ul>
</li>
<li><strong>진화 연산자</strong><ul>
<li>Selection(선택): Fitness 기반 선택. 뛰어난 개체가 자손을 남길 확률이 높음</li>
<li>Crossover(교배): 두 개체의 하이퍼파라미터를 결합하여 새로운 조합 생성</li>
<li>Mutation(돌연변이): 일부 파라미터를 랜덤하게 변경하여 다양성 증가</li>
</ul>
</li>
<li>탐색 방식</li>
<li>초기 개체군 무작위 생성</li>
<li>각 개체에 대해 fitness 계산 &gt; 종료 조건 만족 여부 확인</li>
<li>선택(selection), 교차(crossover), 돌연변이(mutation)를 통해 다음 세대 구성</li>
<li>장점: 전역 최적 탐색에 유리하고, 복잡한 탐색 공간에서 유연함  </li>
<li>단점: 수렴 속도 느리고, 많은 반복이 필요하며 계산 자원 소모 큼 </li>
</ul>
</li>
<li><a href="https://iyk2h.tistory.com/143"><strong>Hyperband / ASHA (Asynchronous Successive Halving Algorithm)</strong></a>  <ul>
<li>자원을 적게 할당한 실험에서 성능이 좋은 조합만 다음 라운드로 진행  </li>
<li>효율적인 조기 종료(Early Stopping)를 포함함</li>
<li>관련 개념<ul>
<li>Successive Halving (SH)</li>
<li>1) 초기에는 많은 후보를 적은 자원(적은 epoch, 적은 sample 등)으로 학습</li>
<li>2) 성능 좋은 일부만 더 많은 자원을 배분하여 계속 학습</li>
<li>3) 최종적으로 가장 좋은 후보만 남김</li>
<li>Hyperband</li>
<li>1) SH를 여러 번 실행하되, 각기 다른 초기 자원(epochs, budget) 설정을 병렬적으로 수행</li>
<li>2) 탐색 공간을 넓게 커버하면서 자원 효율을 높임</li>
<li>ASHA (Asynchronous SH)</li>
<li>Successive Halving을 <strong>비동기(asynchronous)</strong> 방식으로 실행하여, 느린 실험 때문에 전체 프로세스가 지연되지 않도록 함</li>
</ul>
</li>
<li>탐색 방식<ol>
<li>많은 하이퍼파라미터 후보를 무작위로 선택  </li>
<li>각 후보를 작은 자원(예: 1 epoch, 10% 데이터)으로 학습  </li>
<li>성능 상위 일부를 선택하여 자원을 점점 늘려가며 학습 (예: 3 epoch → 9 epoch → 27 epoch)  </li>
<li>나머지 후보들은 조기 종료(Early Stopping)  </li>
<li>Hyperband: 여러 <code>bracket</code>을 병렬 실행 → 자원 분배 전략 다양화  </li>
<li>ASHA: 개별 실험의 완료 여부와 관계없이, 준비된 후보부터 바로 다음 라운드로 승격 (비동기 실행)  </li>
</ol>
</li>
<li><strong>장점</strong>  <ul>
<li>자원 효율성 우수: 불필요한 후보에 자원 낭비 최소화  </li>
<li>Hyperband: 자원 분배를 여러 bracket으로 분산 → 다양한 자원 스케줄 실험 가능  </li>
<li>ASHA: 느린 후보가 전체 탐색을 지연시키지 않음 → 분산 환경에서 확장성 높음  </li>
</ul>
</li>
<li><strong>단점</strong>  <ul>
<li>조기 종료 때문에 학습 초반에 성능이 낮지만 후반에 좋아질 후보를 놓칠 수 있음  </li>
<li>Hyperband는 bracket 수와 자원 분배 비율 등 추가적인 설정 필요  </li>
</ul>
</li>
<li><strong>활용 예시</strong>  <ul>
<li>대규모 신경망 튜닝에서 GPU/TPU 클러스터 효율적으로 활용  </li>
<li><a href="https://docs.ray.io/en/latest/tune/index.html">Ray Tune</a>에서 Hyperband와 ASHA 지원  </li>
<li>AutoML 시스템에서 기본 HPO 알고리즘으로 자주 사용됨   </li>
</ul>
</li>
</ul>
</li>
<li>메타러닝(Meta-Learning) 기반 HPO<ul>
<li>과거 유사한 문제에서의 튜닝 결과를 학습하여 새로운 문제에 적용  </li>
<li>적은 탐색으로 성능 좋은 하이퍼파라미터 추천  </li>
<li>탐색 방식: 유사 데이터셋이나 태스크에 대해 수집된 튜닝 기록을 학습 → 새로운 문제에서 사전 지식을 바탕으로 초기값 제안  </li>
<li>장점: 빠른 초기 튜닝 가능, 실시간 적응성  </li>
<li>단점: 메타 데이터셋이 충분히 있어야 하고, 새로운 도메인에는 일반화 어려움  </li>
</ul>
</li>
<li><a href="https://rahites.tistory.com/354">Population-Based Training(PBT)</a><ul>
<li>학습 중간에 하이퍼파라미터를 동적으로 조정</li>
<li>여러 개체(모델)를 동시에 학습시키고, 일정 간격마다 성능을 평가하여 <strong>우수한 개체는 활용(Exploit), 성능이 낮은 개체는 탐색(Explore)</strong>으로 전환  </li>
<li>유전 알고리즘의 선택(selection), 돌연변이(mutation) 개념을 차용 </li>
<li>분산 환경에서 매우 유용함</li>
<li><strong>탐색 방식 / Process</strong>  <ol>
<li>여러 모델(개체)을 동시에 다른 하이퍼파라미터 조합으로 학습 시작  </li>
<li>일정 주기마다 각 모델의 성능 평가  </li>
<li>성능이 좋은 모델의 <strong>가중치와 하이퍼파라미터를 복제(Exploit)</strong> → 다른 모델에 적용  </li>
<li>복제된 하이퍼파라미터에 <strong>작은 변화(돌연변이, Explore)</strong>를 주어 새로운 탐색 시도  </li>
<li>위 과정을 학습 종료까지 반복하여, 학습과 튜닝을 동시에 수행  </li>
</ol>
</li>
<li><strong>활용 예시</strong>  <ul>
<li>DeepMind <strong>AlphaStar</strong>: 실시간 전략 게임 <em>스타크래프트 II</em> 에이전트 학습에 PBT 적용  </li>
<li>LLM 튜닝: LoRA/QLoRA 학습 중 Learning rate, Dropout 등을 실시간으로 조정  </li>
<li>강화학습(RL): 환경 적응성을 높이고, 파라미터를 고정하지 않고 계속 개선 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="23-hpo">2.3 HPO 실무 고려사항<a class="headerlink" href="#23-hpo" title="Permanent link">¶</a></h3>
<ul>
<li>계산 자원 관리<ul>
<li>분산/병렬 처리 필수</li>
<li>GPU/TPU 등 자원에 따른 튜닝 전략 변경 필요</li>
</ul>
</li>
<li>조기 종료(Early Stopping) 전략<ul>
<li>성능 개선이 없거나 오버피팅이 감지되면 실험 중단</li>
<li>ASHA, Hyperband에서 핵심 전략</li>
</ul>
</li>
<li>분산/병렬 튜닝<ul>
<li>여러 실험을 동시에 실행하여 탐색 시간 절약</li>
<li>Ray Tune, Optuna Multi-node 지원</li>
</ul>
</li>
<li><strong>AutoML 플랫폼 비교 (Optuna, Ray Tune, KerasTuner 등)</strong></li>
</ul>
<table>
<thead>
<tr>
<th>플랫폼</th>
<th>특징</th>
<th>장점</th>
<th>단점</th>
<th>활용 예시</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Optuna</strong></td>
<td>베이지안 최적화 기반, TPE(Tree-structured Parzen Estimator) 활용, 동적 탐색 공간 지원</td>
<td>Pruning / Early Stopping 강력, 탐색 효율 우수, Pythonic한 API</td>
<td>분산 처리 기본 지원은 제한적, 병렬성은 Ray 등과 연동 필요</td>
<td>딥러닝 하이퍼파라미터 튜닝 (LR, Dropout, Hidden size 등), Kaggle 대회</td>
</tr>
<tr>
<td><strong>Ray Tune</strong></td>
<td>분산 환경에서 확장성 강력, 다양한 search algorithm(Grid, Random, BOHB, PBT 등) 지원</td>
<td>수천 개 실험 병렬 실행 가능, Hyperband/ASHA와 통합 최적화</td>
<td>설정 복잡, 클러스터 구성 필요</td>
<td>대규모 GPU 클러스터에서 LLM/멀티모달 모델 튜닝</td>
</tr>
<tr>
<td><strong>KerasTuner</strong></td>
<td>Keras/Tensorflow에 통합 용이, 직관적인 API</td>
<td>간단한 구현, 초보자 친화적, TF와 매끄러운 통합</td>
<td>PyTorch/Scikit-learn과는 호환성 낮음, 분산 처리 한계</td>
<td>CNN, RNN, Transformer 등 Keras 모델 튜닝</td>
</tr>
<tr>
<td><strong>Hyperopt</strong></td>
<td>TPE 기반 베이지안 최적화, Random/Annealing도 지원</td>
<td>간단한 코드로 빠른 구현 가능</td>
<td>Optuna 대비 기능 제한 (시각화, pruning 약함)</td>
<td>MLP, Random Forest, SVM 등 전통 ML 모델 튜닝</td>
</tr>
<tr>
<td><strong>Google Vizier</strong></td>
<td>Google 내부 AutoML 플랫폼 (비공개), Bayesian Optimization 기반</td>
<td>대규모 분산 최적화 가능, 안정성 검증됨</td>
<td>비공개 플랫폼이라 외부 사용 불가</td>
<td>Google 내부 서비스 최적화, TPU 클러스터에서 대규모 모델 튜닝</td>
</tr>
<tr>
<td><strong>SMAC</strong></td>
<td>랜덤 포레스트 기반 베이지안 최적화</td>
<td>카테고리형 변수 최적화 강점</td>
<td>딥러닝보다는 전통 ML에 최적화</td>
<td>ML benchmark에서 자주 활용</td>
</tr>
<tr>
<td><strong>Microsoft NNI</strong></td>
<td>다양한 HPO 기법(Grid, Random, BO, PBT 등) 지원, 분산 실행 가능</td>
<td>범용 AutoML 프레임워크, 시각화 도구 포함</td>
<td>설정 다소 복잡</td>
<td>산업용 AutoML 파이프라인 구축</td>
</tr>
</tbody>
</table>
<h2 id="3-class-imbalanced">3. 클래스 불균형(Class Imbalanced) 문제 해결<a class="headerlink" href="#3-class-imbalanced" title="Permanent link">¶</a></h2>
<h3 id="31">3.1 클래스 불균형 개요<a class="headerlink" href="#31" title="Permanent link">¶</a></h3>
<ul>
<li>원인<ul>
<li>자연 발생: 예) 이상 탐지(Anomaly Detection), 사기 탐지(Fraud Detection), 의료 진단</li>
<li>데이터 수집 편향: 드문 이벤트는 원천적으로 수집이 어려움</li>
<li>레이블링 비용: 소수 클래스는 수작업 라벨링 비용이 큼</li>
</ul>
</li>
<li>영향<ul>
<li>모델은 주로 다수 클래스에 집중 → 소수 클래스 재현율(Recall) 급감</li>
<li>정확도(Accuracy) 중심 평가 시 허위 고성능 착시 발생</li>
</ul>
</li>
<li>불균형 정도 측정 (불균형 비율, Gini Index 등)<ul>
<li><strong>Imbalance Ratio (IR)</strong> :<br>
  다수 클래스 샘플 수를 소수 클래스 샘플 수로 나눈 비율. 값이 클수록 불균형 심함.<br>
  예: 다수 900, 소수 100 → IR = 9:1</li>
<li><strong>Gini Index</strong> :<br>
  불순도를 나타내는 지표. 클래스 분포가 한쪽으로 치우칠수록 값이 커짐.<br>
  공식: <code>Gini = 1 - Σ(p_i^2)</code> (p_i = 클래스 i의 비율)<br>
  → 균등할수록 낮고, 불균형할수록 높음.</li>
<li><strong>Entropy</strong> :<br>
  데이터의 불확실성을 측정. 불균형할수록 특정 클래스 확률이 크기 때문에 엔트로피 값이 낮아짐.<br>
  공식: <code>Entropy = - Σ(p_i * log2(p_i))</code><br>
  → 값이 높을수록 분포가 균등, 낮을수록 불균형.</li>
</ul>
</li>
</ul>
<h3 id="32-data-level">3.2 데이터 수준(Data-level) 접근<a class="headerlink" href="#32-data-level" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>오버샘플링(Oversampling, SMOTE)</p>
<ul>
<li>소수 클래스 데이터를 복제하거나 생성하여 균형 조정</li>
<li>대표 기법: <a href="http://jaylala.tistory.com/entry/%EB%B6%88%EA%B7%A0%ED%98%95%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B2%98%EB%A6%AC-%EC%98%A4%EB%B2%84%EC%83%98%ED%94%8C%EB%A7%81Oversampling-SMOTE">SMOTE (Synthetic Minority Over-sampling Technique)</a>
    <img alt="image" src="https://github.com/user-attachments/assets/a35de7d4-1427-49df-b9a6-aab0f4f96e92"><ul>
<li><strong>원리</strong>: 소수 클래스 샘플과 그 주변의 k-최근접 이웃(k-NN)을 선택 → 선형 보간(interpolation)하여 합성 샘플 생성  </li>
<li><strong>장점</strong>: 데이터 다양성 확보, 단순 중복보다 일반화 성능 개선  </li>
<li><strong>단점</strong>: 경계 근처에 불필요한 샘플 생성 가능 → 클래스 간 경계 왜곡 위험  </li>
<li>변형 기법: Borderline-SMOTE (경계 데이터만 증강), ADASYN (적응형 합성) 등 </li>
</ul>
</li>
</ul>
</li>
<li>
<p>언더샘플링 (Undersampling)</p>
<ul>
<li>다수 클래스의 일부 데이터를 제거하여 균형 유지</li>
<li>단순 무작위 제거(Random Undersampling)는 정보 손실이 크고, 일반화 성능 저하 가능  </li>
<li>대표 기법:  <ul>
<li>NearMiss: 다수 클래스 중 소수 클래스와 가까운 샘플만 선택
  <img alt="image" src="https://github.com/user-attachments/assets/fc51a06a-1b66-4497-bb40-bad642df7cf4"></li>
<li>Tomek Links: 클래스 경계에 위치한 불필요한 다수 클래스 샘플 제거<br>
  <img alt="image" src="https://github.com/user-attachments/assets/e3e4bdb8-d15e-4ab4-9714-256dd111a1c2"></li>
<li>Cluster Centroids: 다수 클래스를 클러스터링 → 중심점(centroid)만 대표로 사용 
  <img alt="image" src="https://github.com/user-attachments/assets/ac1515f5-92b6-42a3-979a-af784a6d183d"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>데이터 증강 (Augmentation)</p>
<ul>
<li>기존 데이터를 변형하거나 노이즈를 추가하여 새로운 샘플을 생성  </li>
<li><strong>이미지 데이터</strong>: 회전, 반전, 이동, 자르기, 밝기/채도 변화, Gaussian Noise 추가, CutMix, Mixup 등  </li>
<li><strong>텍스트 데이터</strong>: 단어 순서 바꾸기, 동의어 치환(Synonym Replacement), 단어 삽입/삭제, EDA(Easy Data Augmentation) 기법  </li>
<li><strong>시계열 데이터</strong>: 윈도우 슬라이싱, 시프트(shift), 잡음 추가, 스펙트로그램 변환 후 증강  </li>
</ul>
</li>
<li>
<p>합성 데이터 생성 (GAN 기반)</p>
<ul>
<li>GAN(Generative Adversarial Network)을 활용하여 소수 클래스에 대한 <strong>고품질 합성 샘플 생성</strong>  </li>
<li><strong>대표 변형 기법</strong>:  <ul>
<li><strong>cGAN (Conditional GAN)</strong>: 클래스 레이블을 조건으로 입력 → 특정 클래스 데이터를 직접 생성 가능  </li>
<li><strong>CTGAN (Conditional Tabular GAN)</strong>: 범주형/연속형 변수 혼합된 <strong>테이블(tabular) 데이터 생성</strong>에 특화  </li>
<li><strong>Tabular GAN</strong>: 테이블 데이터의 분포를 학습하여 새로운 합성 샘플 생성 (의료 데이터, 금융 데이터에서 활용)  </li>
</ul>
</li>
<li><strong>장점</strong>: 기존 분포와 유사한 데이터를 생성하여 모델 학습 강화  </li>
<li><strong>단점</strong>: 학습 불안정성, 모드 붕괴(mode collapse) 문제 발생 가능  </li>
</ul>
</li>
</ul>
<h3 id="33-algorithm-level">3.3 알고리즘 수준(Algorithm-level) 접근<a class="headerlink" href="#33-algorithm-level" title="Permanent link">¶</a></h3>
<ul>
<li><strong>클래스 가중치(Class Weight) 조정</strong>  <ul>
<li>소수 클래스 샘플에 더 높은 손실 가중치를 부여하여 학습 시 중요도를 강화  </li>
<li>불균형 데이터에서 모델이 다수 클래스에 치우치지 않도록 유도  </li>
<li><strong>예시</strong>:  <ul>
<li><code>sklearn</code> → <code>class_weight='balanced'</code> 옵션  </li>
<li>PyTorch → <code>nn.CrossEntropyLoss(weight=...)</code>에 클래스별 가중치 벡터 적용  </li>
</ul>
</li>
<li>장점: 간단하고 계산 자원 추가 소모가 적음  </li>
<li>단점: 가중치 값 설정이 어렵고, 지나치면 과적합 위험  </li>
</ul>
</li>
<li><strong>비용 민감 학습(Cost-Sensitive Learning)</strong>  <ul>
<li>분류 오류에 대해 클래스별로 다른 비용(cost)을 부여하는 학습 방식  </li>
<li>소수 클래스 예측 실패(FN)에 더 큰 비용을 주어 모델이 이를 최소화하도록 학습  </li>
<li>예: 의료 진단에서 암 환자를 놓치면 비용(위험)이 크므로 FN에 더 높은 비용 부여  </li>
<li>장점: 실제 의사결정 상황에 적합  </li>
<li>단점: 비용 함수 설계가 복잡하며 도메인 지식 필요 </li>
</ul>
</li>
<li><a href="https://data-analysis-science.tistory.com/61">앙상블 기법 (Bagging, Boosting 변형)</a>
   <img alt="image" src="https://github.com/user-attachments/assets/38ffc715-b6e7-4766-8077-a5f8ef6227ef"><ul>
<li>여러 약한 학습기를 결합하여 성능 향상  </li>
<li>클래스 불균형 상황에 맞게 <strong>Bagging/Boosting 알고리즘을 변형</strong>하여 활용  </li>
<li><strong>Bagging 기반 기법</strong>  <ul>
<li>원리: 데이터 샘플링을 통해 여러 개의 서브셋 생성 → 개별 모델 학습 후 투표/평균  </li>
<li>불균형 처리 변형:  <ul>
<li><strong>Balanced Random Forest</strong>: 각 부트스트랩 샘플을 구성할 때, 다수 클래스와 소수 클래스 샘플 수를 맞추어 학습  </li>
<li><strong>EasyEnsemble</strong>: 다수 클래스를 여러 번 언더샘플링하여 여러 서브셋을 만들고, 각각에 학습된 분류기를 앙상블  </li>
</ul>
</li>
</ul>
</li>
<li><strong>Boosting 기반 기법</strong>  <ul>
<li>원리: 오분류된 샘플에 가중치를 점점 높여가며 학습 → 소수 클래스 학습 강화  </li>
<li>불균형 처리 변형:  <ul>
<li><strong>AdaBoost</strong>: 샘플 가중치를 동적으로 조정  </li>
<li><strong>SMOTEBoost</strong>: 각 단계에서 SMOTE로 합성 샘플 생성 후 Boosting 적용  </li>
<li><strong>RUSBoost</strong>: 단계별 학습 시 다수 클래스 샘플을 무작위 제거(Random Undersampling)하여 불균형 완화  </li>
</ul>
</li>
</ul>
</li>
<li><strong>장점</strong>: 단일 모델보다 성능과 안정성이 뛰어나며, 클래스 불균형 상황에서도 강건한 성능 확보 가능  </li>
<li><strong>단점</strong>: 모델 해석이 어려워지고, 계산 비용이 커질 수 있음 </li>
</ul>
</li>
</ul>
<h3 id="34">3.4 평가 단계 고려<a class="headerlink" href="#34" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>클래스 불균형 상황에서의 적합한 평가 지표</p>
<ul>
<li><strong>F1-score (macro/micro)</strong>  <ul>
<li>Precision과 Recall의 조화 평균.  </li>
<li><strong>Macro-F1</strong>: 클래스별 F1을 계산 후 평균 → 클래스 불균형에 민감 (소수 클래스 중요하게 반영).  </li>
<li><strong>Micro-F1</strong>: 전체 샘플 단위로 Precision/Recall을 계산 → 클래스 불균형 영향이 상대적으로 적음.  </li>
</ul>
</li>
<li>
<p><strong>PR-AUC (Precision-Recall AUC)</strong>  </p>
<ul>
<li>Precision-Recall 곡선 아래 면적.  </li>
<li>클래스 불균형 상황에서 <strong>ROC-AUC보다 더 민감</strong>하게 소수 클래스 성능 반영</li>
<li>특히 양성 클래스 비율이 매우 낮을 때 적합.  </li>
<li>ROC-AUC vs. PR-AUC<ul>
<li>ROC-AUC: FPR 낮을수록, TPR 높을수록(곡선이 왼쪽, 위로 향할수록) 좋은 모델</li>
<li>PR-AUC: Recall 높을수록, Precision 높을수록(곡선이 오른쪽, 위로 향할수록) 좋은 모델</li>
<li>확률 분포 히스토그램 vs. 확률 밀도 분포
    <img alt="image" src="https://github.com/user-attachments/assets/b803c9e2-621f-4c2f-a0f1-f53c58667ddb"></li>
<li>ROC curve vs. PR curve
    <img alt="image" src="https://github.com/user-attachments/assets/7f56b293-28a9-4cff-b230-95f2c03390fd"></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Balanced Accuracy</strong>  </p>
<ul>
<li>각 클래스의 Recall을 평균하여 산출.  </li>
<li>다수 클래스 위주로 계산되는 단순 Accuracy의 한계를 보완.  </li>
<li>공식: <code>(Recall_1 + Recall_2 + ... + Recall_n) / n</code>  </li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Threshold Moving 및 Calibration 기법</strong>  </p>
<ul>
<li><strong>Threshold Moving</strong>  <ul>
<li>기본적으로 분류기는 <code>p &gt; 0.5</code>이면 Positive로 분류.  </li>
<li>클래스 불균형 상황에서는 threshold를 조정하여 소수 클래스 탐지를 강화.  </li>
<li>예: threshold를 0.3으로 낮추면 Recall은 올라가지만 Precision은 감소할 수 있음.  </li>
<li>실제 서비스(의료 진단, 이상 탐지)에서 <strong>False Negative 최소화</strong>를 위해 자주 사용.  </li>
</ul>
</li>
<li><strong>Calibration 기법</strong>  <ul>
<li>모델의 출력 확률을 <strong>실제 발생 확률에 가깝게 보정</strong>하는 과정.  </li>
<li>대표 기법:  <ul>
<li><strong>Platt Scaling</strong>: 로지스틱 회귀를 이용해 확률을 보정.  </li>
<li><strong>Isotonic Regression</strong>: 비모수(non-parametric) 회귀로 확률 보정.  </li>
</ul>
</li>
<li>장점: ROC 커브, PR 커브 기반으로 threshold 설정 시 신뢰성 향상.  </li>
<li>활용: 예측 확률이 의사결정에 직접 사용되는 분야(예: 금융, 의료 리스크 평가).  </li>
</ul>
</li>
</ul>
</li>
<li><strong>추가 고려사항</strong>  <ul>
<li><strong>Confusion Matrix 기반 지표</strong>: Precision, Recall, Specificity, G-mean 등 불균형 데이터 상황에 더 유용.  </li>
<li><strong>Cost-sensitive Metrics</strong>: 클래스별 오류 비용(cost)을 반영하여 평가.  </li>
<li><strong>Kappa Score, Matthews Correlation Coefficient(MCC)</strong>: 클래스 불균형에도 강건한 지표로 권장. </li>
</ul>
</li>
</ul>
<h2 id="4">4. 모델 튜닝과 평가 연계<a class="headerlink" href="#4" title="Permanent link">¶</a></h2>
<ul>
<li>HPO와 모델 평가 지표의 관계</li>
<li>튜닝 목적 함수(Objective Function)는 반드시 모델의 평가 지표와 연동되어야 함</li>
<li>회귀: RMSE, MAE 등 → 작을수록 좋음</li>
<li>분류: F1-score, AUC 등 → 클수록 좋음</li>
<li>다중 지표 사용 시
        - 개별 평가 지표를 정규화하여 조합 (예: weighted sum)<br>
        - 혹은 멀티목적 최적화(Multi-objective Optimization) 적용  </li>
<li>클래스 불균형 상황에서의 HPO 전략<ul>
<li>단순 Accuracy 기반 튜닝은 소수 클래스 무시 위험  </li>
<li><strong>권장 지표</strong>: macro F1, PR-AUC, balanced accuracy 등  </li>
<li><strong>데이터 수준 보완</strong>: SMOTE, ADASYN 등 오버샘플링 기법 적용  </li>
<li><strong>알고리즘 수준 보완</strong>: class weighting, cost-sensitive learning  </li>
<li><strong>Threshold 조정 포함</strong>: 소수 클래스 탐지를 강화하기 위해 decision threshold를 낮추거나, cost-sensitive threshold 적용  </li>
</ul>
</li>
<li><strong>멀티목적 최적화(Multi-objective Optimization)</strong></li>
<li>여러 성능 지표를 동시에 고려 (예: F1-score vs. Inference Time)</li>
<li>대표 기법: <a href="https://wikidocs.net/253840">Pareto Optimization</a>, NSGA-II<ul>
<li><strong>Pareto Optimization</strong>  <ul>
<li>여러 목적 함수 간에 <strong>동시에 개선할 수 없는 관계(트레이드오프)</strong>를 고려하여 최적 해를 탐색하는 방법.  </li>
<li><strong>Pareto 최적(Pareto Optimal)</strong>: 어떤 해의 하나의 성능 지표를 개선하면 다른 지표가 반드시 나빠지는 지점.  </li>
<li>결과적으로 단일 최적점이 아닌, <strong>Pareto Front(비지배해 집합)</strong>을 형성 → 의사결정자는 이 중에서 요구사항에 맞는 해를 선택.  </li>
<li>활용: 정확도 vs 연산시간, 모델 크기 vs 성능 등 다중 목적 고려 문제.  </li>
</ul>
</li>
<li><strong>NSGA-II (Non-dominated Sorting Genetic Algorithm II)</strong>  <ul>
<li>Pareto 최적화를 <strong>진화 알고리즘 기반</strong>으로 효율적으로 구현한 방법.  </li>
<li><strong>핵심 특징</strong>:  <ol>
<li><strong>비지배 정렬 (Non-dominated Sorting)</strong>: 개체들을 Pareto 지배 관계에 따라 계층적으로 정렬.  </li>
<li><strong>군집 거리(Crowding Distance)</strong>: Pareto front 상에서 다양성을 유지하기 위해 개체 간 거리를 계산.  </li>
<li><strong>선택/교차/돌연변이 연산</strong>을 통해 새로운 세대 생성.  </li>
</ol>
</li>
<li>장점: 다중 목적 문제에서 <strong>균형 잡힌 Pareto front</strong>를 빠르게 찾을 수 있음.  </li>
<li>활용: 모델 성능 vs 메모리 사용량, 정확도 vs 추론 속도 최적화 등.  </li>
</ul>
</li>
</ul>
</li>
<li>Optuna 등에서는 optuna.multi_objective 지원</li>
<li><strong>튜닝 과정에서의 과적합 방지 전략</strong></li>
<li>Validation set 고정 및 Cross-validation 병행</li>
<li>Early stopping 사용하여 validation loss 증가 시 학습 중단</li>
<li>HPO에서 튜닝 과정을 로그로 추적하고, test set은 절대 objective로 사용하지 않도록 주의</li>
</ul>
<h2 id="5">5. 실무 적용 사례<a class="headerlink" href="#5" title="Permanent link">¶</a></h2>
<ul>
<li>이미지 분류 모델 튜닝 예시</li>
<li>적용 분야: 의료 이미지 분류, 품질 검사, 일반 이미지 인식 등</li>
<li>사용 모델: ResNet, EfficientNet, ConvNeXt 등</li>
<li>튜닝 대상 하이퍼파라미터<ul>
<li>Optimizer 종류: SGD vs AdamW</li>
<li>Learning Rate &amp; Scheduler: CosineAnnealing, ReduceLROnPlateau</li>
<li>Batch Size, Weight Decay</li>
<li>Data Augmentation 기법: RandomCrop, CutMix, MixUp, AutoAugment</li>
</ul>
</li>
<li>튜닝 기법<ul>
<li>Optuna + PyTorch Lightning integration</li>
<li>Early Stopping + Cosine LR Scheduler</li>
<li>실험 자동화: Weights &amp; Biases (sweep) 또는 MLflow 사용</li>
</ul>
</li>
<li>평가 지표<ul>
<li>Top-1 Accuracy, Macro-F1, Confusion Matrix 기반 Recall</li>
</ul>
</li>
</ul>
<pre><code class="language-python">optuna_trial.suggest_float("lr", 1e-5, 1e-2, log=True)
</code></pre>
<ul>
<li>텍스트 분류 모델 튜닝 예시</li>
<li>적용 분야: 감성 분석, 뉴스 카테고리 분류, 고객 문의 자동 분류 등</li>
<li>사용 모델: BERT, RoBERTa, KoBERT, Electra</li>
<li>튜닝 대상 하이퍼파라미터<ul>
<li>Learning rate, Max sequence length</li>
<li>Warmup steps, Weight decay</li>
<li>Tokenizer truncation/padding 방식</li>
</ul>
</li>
<li>튜닝 기법<ul>
<li>Huggingface + Optuna integration</li>
<li>k-fold CV 기반 tuning</li>
<li>Trainer API에서 TrainerCallback으로 metric logging</li>
</ul>
</li>
<li>평가 지표<ul>
<li>Macro-F1, PR-AUC, Weighted Recall</li>
<li>Validation vs. Test performance gap 체크</li>
</ul>
</li>
</ul>
<pre><code class="language-python">training_args = TrainingArguments(
  evaluation_strategy="epoch",
  learning_rate=trial.suggest_float("lr", 1e-5, 5e-5),
  ...
)
</code></pre>
<ul>
<li><strong>대규모 언어 모델(LLM) 튜닝 사례</strong>  </li>
<li>적용 분야: QA, 요약, 대화형 모델 등  </li>
<li>사용 모델: LLaMA, Mistral, Falcon, GPT-NeoX 등  </li>
<li>튜닝 방법  <ul>
<li>Full fine-tuning 대신 <strong>PEFT(Parameter-Efficient Fine-Tuning)</strong> 기법 사용 (LoRA, QLoRA, Prefix Tuning 등)  </li>
<li>Quantization-aware tuning (4bit, 8bit) 적용하여 메모리 효율 개선  </li>
<li>RLHF(Reinforcement Learning from Human Feedback) 기반 보상 학습 연계  </li>
</ul>
</li>
<li>튜닝 대상 파라미터  <ul>
<li>LoRA rank, alpha 값  </li>
<li>Target module (attention, FFN layer)  </li>
<li>Optimizer (AdamW, Adam8bit)  </li>
</ul>
</li>
<li>
<p>평가 지표  </p>
<ul>
<li>전통 지표: BLEU, ROUGE, Perplexity  </li>
<li>벤치마크: MT-Bench, GPT-judge 기반 평가  </li>
</ul>
</li>
<li>
<p><strong>멀티모달 모델 튜닝 사례</strong>  </p>
</li>
<li>적용 분야: 이미지-텍스트 검색, 비전-언어 질의응답(VQA), 멀티모달 대화  </li>
<li>사용 모델: CLIP, BLIP, Flamingo, LLaVA 등  </li>
<li>튜닝 전략  <ul>
<li>텍스트/이미지 인코더별로 <strong>다른 학습률</strong> 적용 (Differential Learning Rate)  </li>
<li>Cross-modal fusion layer 및 projection tuning  </li>
<li>Vision encoder freeze 후, decoder/adapter만 tuning → 효율적 미세조정  </li>
</ul>
</li>
<li>튜닝 기법  <ul>
<li>Prompt tuning, Linear probing  </li>
<li>Mixed precision, Gradient checkpointing을 통한 효율화  </li>
</ul>
</li>
<li>평가 지표  <ul>
<li>Retrieval: Recall@K, mAP  </li>
<li>Generation: BLEU, CIDEr, GPTScore </li>
</ul>
</li>
</ul>
<h2 id="6-mlops">6. 튜닝 자동화와 MLOps<a class="headerlink" href="#6-mlops" title="Permanent link">¶</a></h2>
<ul>
<li>파이프라인 기반 HPO 자동화</li>
<li>ML 파이프라인 도구 (e.g. Kubeflow, Airflow, Vertex AI)를 사용하여 전체 튜닝 흐름 자동화</li>
<li>구성 요소: 데이터 로딩 → 전처리 → 모델 학습 + 튜닝 → 성능 기록 → 최적 모델 저장</li>
<li>MLflow / Weights &amp; Biases를 통한 실험 관리</li>
<li>MLflow : 실험 로그, 파라미터 관리, 모델 아카이빙, API 배포 연계</li>
<li>Weights &amp; Biases (wandb) : 대시보드 기반 실험 비교, HPO 스윕 기능, 커스텀 시각화</li>
<li>(추가) <strong>튜닝-배포-모니터링 연계 자동화</strong></li>
<li>튜닝 완료된 모델을 자동으로 배포 &amp; 서빙 파이프라인 연계</li>
<li>Serving 예시: FastAPI + Docker + Kubernetes</li>
<li>실시간 성능 모니터링 도구 연계: Prometheus, Grafana</li>
<li>성능 저하 감지 시 자동 재튜닝 트리거 (예: concept drift 대응)</li>
</ul></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "search.suggest", "search.highlight", "content.code.copy"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>