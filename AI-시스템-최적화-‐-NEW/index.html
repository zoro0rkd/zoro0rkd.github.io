
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://zoro0rkd.github.io/AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%B5%9C%EC%A0%81%ED%99%94-%E2%80%90-NEW/">
      
      
        <link rel="prev" href="../AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%E2%80%90-NEW/">
      
      
        <link rel="next" href="../%EC%A3%BC%EC%9A%94-AI-%EA%B8%B0%EC%88%A0-%ED%8A%B8%EB%9E%9C%EB%93%9C/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>AI 시스템 최적화 - Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-ai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Notes" class="md-header__button md-logo" aria-label="Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              AI 시스템 최적화
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Notes" class="md-nav__button md-logo" aria-label="Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    홈
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 데이터 전처리
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI 데이터 전처리
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%88%98%EC%A7%91-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 수집
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EC%A0%9C-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 정제
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A6%9D%EA%B0%95-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    데이터 증강
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 모델 개발
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            AI 모델 개발
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%84%A4%EA%B3%84-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 모델 아키텍처 설계
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../XAI-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    XAI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%EA%B3%BC-%ED%8F%89%EA%B0%80-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 모델 학습과 평가
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EB%AA%A8%EB%8D%B8-%ED%8A%9C%EB%8B%9D-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 모델 튜닝
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI 시스템 구축
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            AI 시스템 구축
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AI-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%E2%80%90-NEW/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI 시스템 설계 및 배포
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    AI 시스템 최적화
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    AI 시스템 최적화
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-ai" class="md-nav__link">
    <span class="md-ellipsis">
      1. AI 시스템 최적화 개요
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. AI 시스템 최적화 개요">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 최적화의 정의
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 필요성
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 모델 최적화 기법
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 모델 최적화 기법">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 경량화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 연산 최적화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 하드웨어 가속기 활용
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 시스템 아키텍처 최적화
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 시스템 아키텍처 최적화">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-distributed-processing" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 분산 처리 (Distributed Processing)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 캐싱 전략
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 네트워크 최적화
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-serving-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4. 서빙 최적화 (Serving Optimization)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. 서빙 최적화 (Serving Optimization)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-deployment-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 배포 구조 (Deployment Architecture)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-scaling-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 스케일링 최적화 (Scaling Optimization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      요약 비교
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-data-pipeline-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 데이터 파이프라인 최적화 (Data Pipeline Optimization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 지연 최소화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      요약 포인트
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-monitoring-feedback-loop" class="md-nav__link">
    <span class="md-ellipsis">
      5. 모니터링과 피드백 루프 (Monitoring &amp; Feedback Loop)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. 모니터링과 피드백 루프 (Monitoring &amp; Feedback Loop)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-performance-monitoring" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 성능 모니터링 (Performance Monitoring)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-auto-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 자동 스케일링 (Auto-Scaling)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. 최적화 사례 연구
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. 최적화 사례 연구">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 대규모 LLM 서빙 최적화 사례
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 이미지 검색 서비스 최적화 사례
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 실시간 음성 인식 시스템 최적화 사례
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. 클라우드 환경에서의 최적화
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. 클라우드 환경에서의 최적화">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 서버리스 서빙 구조
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-gpucpu" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 GPU/CPU 오토스케일링
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 비용 기반 오토스케일링
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 스팟 인스턴스 활용
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EC%A3%BC%EC%9A%94-AI-%EA%B8%B0%EC%88%A0-%ED%8A%B8%EB%9E%9C%EB%93%9C/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    주요 AI 기술 트랜드
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../%EC%9C%A0%EC%9A%A9%ED%95%9C-%EC%82%AC%EC%9D%B4%ED%8A%B8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    유용한 사이트
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-ai" class="md-nav__link">
    <span class="md-ellipsis">
      1. AI 시스템 최적화 개요
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. AI 시스템 최적화 개요">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 최적화의 정의
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 필요성
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 모델 최적화 기법
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 모델 최적화 기법">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 경량화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 연산 최적화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 하드웨어 가속기 활용
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 시스템 아키텍처 최적화
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 시스템 아키텍처 최적화">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-distributed-processing" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 분산 처리 (Distributed Processing)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 캐싱 전략
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 네트워크 최적화
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-serving-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4. 서빙 최적화 (Serving Optimization)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. 서빙 최적화 (Serving Optimization)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-deployment-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 배포 구조 (Deployment Architecture)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-scaling-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 스케일링 최적화 (Scaling Optimization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      요약 비교
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-data-pipeline-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 데이터 파이프라인 최적화 (Data Pipeline Optimization)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 지연 최소화
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      요약 포인트
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-monitoring-feedback-loop" class="md-nav__link">
    <span class="md-ellipsis">
      5. 모니터링과 피드백 루프 (Monitoring &amp; Feedback Loop)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. 모니터링과 피드백 루프 (Monitoring &amp; Feedback Loop)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-performance-monitoring" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 성능 모니터링 (Performance Monitoring)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-auto-scaling" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 자동 스케일링 (Auto-Scaling)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6. 최적화 사례 연구
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. 최적화 사례 연구">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 대규모 LLM 서빙 최적화 사례
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 이미지 검색 서비스 최적화 사례
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 실시간 음성 인식 시스템 최적화 사례
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7. 클라우드 환경에서의 최적화
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. 클라우드 환경에서의 최적화">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 서버리스 서빙 구조
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-gpucpu" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 GPU/CPU 오토스케일링
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 비용 기반 오토스케일링
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 스팟 인스턴스 활용
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>AI 시스템 최적화</h1>

<hr />
<h2 id="1-ai">1. AI 시스템 최적화 개요<a class="headerlink" href="#1-ai" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 최적화의 정의<a class="headerlink" href="#11" title="Permanent link">&para;</a></h3>
<ul>
<li>성능 최적화 (Performance Optimization)</li>
<li>Latency(응답 지연) 감소</li>
<li>Throughput(처리량) 향상</li>
<li>모델 압축, 지식 증류(Distillation), 프루닝(Pruning), 양자화(Quantization)</li>
<li>자원 사용 최적화 (Resource Utilization)</li>
<li>GPU/CPU/메모리 효율적 활용</li>
<li>컨테이너·오케스트레이션(Kubernetes) 기반 스케일링</li>
<li>분산 학습/추론 최적화</li>
<li>비용 최적화 (Cost Optimization)</li>
<li>클라우드 비용 절감 (스팟 인스턴스, 자동 스케일링)</li>
<li>불필요한 연산/스토리지 제거</li>
<li>모델 사이즈 축소로 인한 인프라 비용 절감</li>
<li>운영 안정성 최적화 (Operational Stability)</li>
<li>MLOps를 통한 배포·모니터링 자동화</li>
<li>장애 최소화, 롤백 전략</li>
<li>
<p>모델 드리프트 감지 및 자동 재학습</p>
<ul>
<li>MLOps의 핵심: 수동 프로세스 vs 자동화된 ML 프로세스</li>
<li>
<p>수동 프로세스 (Manual Process)</p>
<ul>
<li>데이터 준비 → 모델 학습 → 검증 → 배포 → 모니터링 과정을 사람이 직접 수행  </li>
<li>장점: 소규모 프로젝트에서 유연성↑, 단순  </li>
<li>단점: 재현성 부족, 시간/비용↑, 에러 발생률↑  </li>
<li>예: 연구 단계에서 Python 스크립트로 수작업 학습 및 모델 파일(.pkl, .h5) 업로드  </li>
</ul>
</li>
<li>
<p>ML 프로세스 자동화 (Automated ML Pipeline)</p>
<ul>
<li>데이터 파이프라인, 학습, 검증, 배포, 모니터링 과정을 자동화(CI/CD)  </li>
<li>장점: <strong>재현성↑, 신속한 배포, 운영 비용↓, 품질 관리 체계화</strong>  </li>
<li>단점: 초기 시스템 구축 복잡, 엔지니어링 역량 필요  </li>
<li>예: Kubeflow, MLflow, TFX, Airflow 기반 자동화 파이프라인  </li>
</ul>
</li>
<li>Feature Store(피처 스토어) 개념</li>
<li>(정의) 모델 학습과 추론에 사용하는 <strong>피처(Feature, 입력 변수)</strong>를 중앙 집중식으로 저장·관리하는 시스템  </li>
<li>(필요성)  <ul>
<li>수동 파이프라인에서는 <strong>학습 시 사용한 피처와 서비스 서빙 시 사용하는 피처가 불일치</strong>할 위험이 있음 → 데이터 드리프트 발생  </li>
<li>Feature Store는 <strong>학습/추론 피처를 동일한 소스에서 관리</strong>하여 <strong>재현성·일관성 확보</strong>  </li>
</ul>
</li>
<li>(장점)  <ul>
<li>학습·추론 데이터의 <strong>Consistency 보장</strong>  </li>
<li>피처 재사용 가능 → 중복 엔지니어링 방지, 개발 속도 향상  </li>
<li>실시간 피처 업데이트 지원 → 온라인 서비스 품질 유지  </li>
</ul>
</li>
<li>(단점)  <ul>
<li>초기 구축 복잡 (데이터 엔지니어링 + 인프라 필요)  </li>
<li>저장소·캐시 관리 비용 발생  </li>
</ul>
</li>
<li>(활용)  <ul>
<li>Uber <strong>Michelangelo Feature Store</strong>, Tecton, Feast(오픈소스)  </li>
<li>추천 시스템: 사용자 프로필 피처 저장/실시간 서빙  </li>
<li>금융 서비스: 거래 데이터 기반 Fraud Detection 피처 공유  </li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="12">1.2 필요성<a class="headerlink" href="#12" title="Permanent link">&para;</a></h3>
<ul>
<li>(Latency 감소) 실시간 서비스 품질 개선</li>
<li>(Throughput 향상) 대규모 트래픽 대응</li>
<li>(에너지 효율성) 지속가능성, 친환경 운영</li>
<li>(모델 유지보수 비용 절감) 비용 절감</li>
</ul>
<hr />
<h2 id="2">2. 모델 최적화 기법<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 경량화<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<ul>
<li>프루닝(Pruning)</li>
<li>(정의) 중요하지 않은 뉴런/가중치를 제거해 모델을 간소화하는 기법</li>
<li>(효과) 파라미터 수와 연산량 감소 → 속도 향상, 메모리 절약</li>
<li>(단점) 지나친 프루닝 시 정확도 손실  </li>
<li>(활용) CNN 경량화, 모바일/엣지 배포</li>
<li>
<p><img width="400" height="400" alt="image" src="https://github.com/user-attachments/assets/33bc31ec-505e-4544-b3aa-913ddd570cfe" /></p>
</li>
<li>
<p>양자화(Quantization)</p>
</li>
<li>(정의) 모델의 가중치 및 연산을 저정밀도(예: FP32 → INT8)로 변환</li>
<li>(효과) 메모리 사용량 절감, 추론 속도 개선</li>
<li>(단점) 정밀도 손실 가능  </li>
<li>(활용) 스마트폰 AI 칩, 실시간 서비스</li>
<li>
<p><img width="400" height="400" alt="image" src="https://github.com/user-attachments/assets/e279b84b-0bc4-4b18-aa40-58ec679eae2b" /></p>
</li>
<li>
<p>지식 증류(Knowledge Distillation)</p>
</li>
<li>(정의) 큰 모델(Teacher)의 지식을 작은 모델(Student)에 전달</li>
<li>(효과) 경량 모델이 큰 모델의 성능을 일부 유지하면서 가볍게 동작</li>
<li>(단점) Teacher 품질에 의존  </li>
<li>(활용) LLM 압축, 모바일 챗봇  </li>
<li>
<p><img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/690ffb67-0eb1-4042-af41-1325f755f983" /></p>
</li>
<li>
<p>가중치 공유(Weight Sharing)</p>
</li>
<li>(정의) 서로 다른 네트워크 파라미터를 공유해 저장 공간 절약</li>
<li>(효과) 모델 크기 감소, 연산량 감소</li>
<li>(단점) 표현력 저하 가능  </li>
<li>(활용) NAS(Network Architecture Search), RNN </li>
<li><img width="600" height="400" alt="image" src="https://github.com/user-attachments/assets/ea637a69-3d36-4623-a7c8-c25fcb21ee18" /></li>
</ul>
<h3 id="22">2.2 연산 최적화<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<ul>
<li>연산 Fusion</li>
<li>(정의) 여러 연산(예: Conv + BatchNorm + ReLU)을 하나로 합쳐 계산</li>
<li>(효과) 메모리 접근 최소화, 연산 효율 상승</li>
<li>(단점) 구현 복잡성 증가  </li>
<li>
<p>(활용) TensorRT, ONNX Runtime  </p>
</li>
<li>
<p>Sparse Matrix 활용</p>
</li>
<li>(정의) 0이 많은 희소 행렬의 구조를 활용해 불필요한 연산 제거</li>
<li>(효과) 연산량 감소, 메모리 절약</li>
<li>(단점) 라이브러리/하드웨어 지원 필요  </li>
<li>
<p>(활용) NLP 임베딩, LLM 파라미터 압축  </p>
</li>
<li>
<p>Mixed Precision</p>
</li>
<li>(정의) 일부 연산은 FP16(반정밀도), 일부는 FP32(단정밀도)로 수행</li>
<li>(효과) 속도와 메모리 효율 향상, 성능 손실 최소화</li>
<li>(단점) 정밀도 손실 가능  </li>
<li>(활용) NVIDIA GPU, 대규모 LLM 학습  </li>
</ul>
<h3 id="23">2.3 하드웨어 가속기 활용<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<ul>
<li>GPU (Graphics Processing Unit)</li>
<li>(특징) 대규모 병렬 연산에 최적화 → 딥러닝 학습·추론 기본 장비 </li>
<li>TPU (Tensor Processing Unit)</li>
<li>(특징) Google이 설계한 AI 전용 칩, Tensor 연산 최적화</li>
<li>(효과) 대규모 ML 학습에 특화, TPU Pods로 확장 가능</li>
<li>NPU (Neural Processing Unit)</li>
<li>(특징) 모바일/엣지 기기에서 AI 연산 가속 (삼성·애플 AP에 내장)</li>
<li>(효과) 저전력·실시간 AI 처리</li>
<li>FPGA (Field Programmable Gate Array)</li>
<li>(특징) 하드웨어 레벨에서 연산 경로를 프로그래밍 가능</li>
<li>(효과) 특정 AI 연산(예: CNN, RNN) 맞춤형 최적화 가능</li>
</ul>
<hr />
<h2 id="3">3. 시스템 아키텍처 최적화<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<h3 id="31-distributed-processing">3.1 분산 처리 (Distributed Processing)<a class="headerlink" href="#31-distributed-processing" title="Permanent link">&para;</a></h3>
<ul>
<li>데이터 병렬 처리 (Data Parallelism)</li>
<li>(정의) 동일한 모델 복제본을 여러 장비에 배치하고, 데이터를 나눠 학습시키는 방식</li>
<li>(동작 방식) 각 GPU/노드가 다른 미니배치를 학습 → Gradient 계산 → 집계(All-Reduce) 후 파라미터 동기화</li>
<li>(장점) 구현이 단순, 대부분의 학습 시나리오에 적용 가능</li>
<li>(단점) 통신 비용 증가(노드 간 파라미터 동기화 오버헤드)</li>
<li>(활용) 딥러닝 프레임워크(PyTorch DDP, TensorFlow MirroredStrategy 등)에서 기본 제공</li>
<li>모델 병렬 처리 (Model Parallelism)</li>
<li>(정의) 하나의 큰 모델을 여러 장비에 나누어 저장/계산하는 방식</li>
<li>(동작 방식) Layer 단위 또는 연산 단위를 나눠 각 GPU에 배치 (예: 첫 번째 GPU는 112 Layer, 두 번째 GPU는 1324 Layer)</li>
<li>(장점) 단일 GPU 메모리에 올라가지 않는 초거대 모델 학습 가능</li>
<li>(단점) 계층 간 통신 지연 발생, 구현 난이도 높음</li>
<li>(활용) GPT, LLaMA 등 수십억~수천억 파라미터 대규모 LLM 학습</li>
<li>파이프라인 병렬 처리 (Pipeline Parallelism)</li>
<li>(정의) 모델을 여러 Stage로 분할하고, 데이터를 순차적으로 흘려보내면서 동시에 처리하는 방식</li>
<li>(동작 방식) Stage 1이 Batch의 일부를 처리 → Stage 2로 전달하는 동안, Stage 1은 다음 Batch를 처리 (파이프라인처럼 겹침 처리)</li>
<li>(장점) GPU 활용률 극대화, 메모리 분산 가능</li>
<li>(단점) 파이프라인 버블(빈 시간)이 발생할 수 있음</li>
<li>(활용) Megatron-LM, DeepSpeed 등 대규모 Transformer 학습</li>
</ul>
<h3 id="32">3.2 캐싱 전략<a class="headerlink" href="#32" title="Permanent link">&para;</a></h3>
<ul>
<li>모델 캐싱</li>
<li>(정의) AI 모델의 가중치, 구조, 또는 컴파일된 중간 결과를 저장해두고, 재사용하는 전략</li>
<li>적용 목적 및 방식<ul>
<li>모델 로딩/컴파일 시간 단축</li>
<li>대규모 모델을 매번 디스크에서 로딩하거나, 디바이스별로 컴파일하는 과정은 매우 느릴 수 있습니다.</li>
<li>엣지/브라우저/서버 캐싱</li>
<li>클라우드 서버, 엣지 서버, 또는 브라우저의 로컬 스토리지(Cache API, IndexedDB 등)에 모델 파일을 저장</li>
<li>OpenVINO, TensorRT 등에서는 컴파일된 모델을 캐시 디렉토리에 저장하여 추론 시작 시간을 단축</li>
<li>파라미터 공유/블록 캐싱</li>
<li>여러 모델이 공통으로 사용하는 파라미터 블록만 따로 캐싱해 스토리지 효율을 높임</li>
</ul>
</li>
<li>
<p>대표 사례</p>
<ul>
<li>브라우저에서 AI 모델 파일을 Cache API로 저장해, 앱 재실행 시 빠르게 로드</li>
<li>엣지 서버에서 여러 모델의 파라미터 블록을 공유 캐싱하여, 네트워크 지연 및 저장 공간 절감</li>
</ul>
</li>
<li>
<p>데이터 캐싱</p>
</li>
<li>(정의) 학습, 추론, 또는 데이터 전처리 과정에서 반복적으로 접근하는 데이터를 미리 저장해두고 재사용하는 전략</li>
<li>적용 목적 및 방식<ul>
<li>데이터 로딩 및 I/O 병목 해소</li>
<li>대용량 이미지, 텍스트, 벡터 등 반복적으로 사용하는 데이터를 메모리, SSD, 또는 파일(.npy 등)로 캐싱</li>
<li>전처리 결과 캐싱</li>
<li>예를 들어, 이미지 벡터화, 토큰화 등 전처리 결과를 미리 저장해, 이후 반복 작업에서 빠르게 불러옴</li>
<li>예측 캐싱</li>
<li>AI가 이전 쿼리 패턴을 학습해 앞으로 자주 사용할 데이터를 미리 캐싱(프리페칭)</li>
</ul>
</li>
<li>
<p>대표 사례</p>
<ul>
<li>PyTorch 등에서 첫 에폭에 데이터를 벡터화해 메모리에 저장, 이후 에폭에서는 빠르게 재사용</li>
<li>자주 접근하는 금융 데이터, 사용자 맞춤형 데이터 등을 메모리 기반 캐시(예: Redis)로 관리</li>
</ul>
</li>
<li>
<p>결과(프롬프트/쿼리) 캐싱</p>
</li>
<li>(정의) AI 모델의 입력(프롬프트, 쿼리)과 그에 대한 출력(응답, 예측 결과)을 저장해두고, 동일하거나 유사한 요청이 들어올 때 즉시 반환하는 전략</li>
<li>적용 목적 및 방식<ul>
<li>응답 속도 및 비용 절감</li>
<li>동일/유사한 프롬프트에 대해 모델을 다시 실행하지 않고, 캐시된 결과를 반환해 응답 속도와 비용을 크게 줄임</li>
<li>정확 매칭 캐싱</li>
<li>입력 프롬프트가 완전히 동일할 때만 캐시 사용(문자열 기반)</li>
<li>시맨틱(의미 기반) 캐싱</li>
<li>임베딩 비교를 통해 의미가 유사한 요청에도 캐시된 결과를 반환(벡터 DB 활용)</li>
<li>프롬프트 분리/키 설계</li>
<li>고정 영역(시스템 메시지 등)과 가변 영역(사용자 입력 등)을 분리해, 캐시 효율을 높임</li>
<li>캐시 무효화 및 TTL:</li>
<li>데이터 변경, 모델 업데이트, 시간 기반(예: 10분, 1시간)으로 캐시를 자동 만료</li>
</ul>
</li>
<li>대표 사례<ul>
<li>OpenAI, Google Gemini, Anthropic Claude 등 주요 LLM API에서 프롬프트 캐싱을 통해 최대 75% 비용 절감, 80% 이상 응답 속도 단축</li>
<li>RAG(Retrieval-Augmented Generation) 시스템에서 쿼리-응답 쌍을 캐싱해, 반복 질의에 빠른 응답 제공</li>
<li>Stable Diffusion 등 생성형 모델에서 중간 결과(라텐트, 임베딩 등)를 벡터 DB에 캐싱, 유사 프롬프트에 재사용</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>구분</th>
<th>캐싱 대상</th>
<th>주요 목적</th>
<th>적용 위치</th>
<th>대표 기술/사례</th>
</tr>
</thead>
<tbody>
<tr>
<td>모델 캐싱</td>
<td>모델 파일/파라미터</td>
<td>로딩/컴파일 속도 개선</td>
<td>서버, 엣지, 클라이언트</td>
<td>OpenVINO, Cache API</td>
</tr>
<tr>
<td>데이터 캐싱</td>
<td>입력/전처리 데이터</td>
<td>I/O 병목 해소, 반복 작업 최적화</td>
<td>메모리, 파일, DB</td>
<td>.npy, Redis, 예측 캐싱</td>
</tr>
<tr>
<td>결과(프롬프트) 캐싱</td>
<td>입력-출력 쌍</td>
<td>응답 속도/비용 절감</td>
<td>LLM API, RAG, 생성형 모델</td>
<td>프롬프트 캐싱, 벡터 DB</td>
</tr>
</tbody>
</table>
<h3 id="33">3.3 네트워크 최적화<a class="headerlink" href="#33" title="Permanent link">&para;</a></h3>
<ul>
<li>배치 요청 처리 (Batch Request Processing)</li>
<li>(정의) 여러 개의 작은 요청을 한 번에 묶어서 전송/처리하는 방식</li>
<li>(동작 방식) 실시간으로 개별 요청을 처리하지 않고, 일정 시간 동안 모은 후 한 번에 처리</li>
<li>(장점) 네트워크 호출 횟수 감소 → 오버헤드 줄어듦, Throughput 증가</li>
<li>(단점) 개별 요청의 응답 속도(Latency)는 다소 늦어질 수 있음</li>
<li>활용<ul>
<li>온라인 추천 시스템에서 다수 사용자 요청을 묶어 처리</li>
<li>LLM API 호출 시 batch inference</li>
</ul>
</li>
<li>압축 전송 (Compressed Transmission)</li>
<li>(정의) 데이터를 네트워크로 전송하기 전에 압축하여 크기를 줄이는 기법</li>
<li>동작 방식<ul>
<li>전송 전: 데이터/모델 가중치 압축 (예: Huffman coding, Zip, Quantization 기반)</li>
<li>수신 후: 압축 해제 후 처리</li>
</ul>
</li>
<li>(장점) 전송 지연 및 대역폭 사용량 감소</li>
<li>(단점) 압축/해제 과정의 CPU 오버헤드 추가</li>
<li>활용<ul>
<li>분산 학습 시 Gradient 압축 (Gradient Compression)</li>
<li>IoT 센서 데이터 전송 시 경량화</li>
</ul>
</li>
<li>Edge Computing 활용</li>
<li>(정의) 데이터를 클라우드로 모두 보내지 않고, 사용자 단말·로컬 서버(Edge)에서 1차 처리하는 방식</li>
<li>동작 방식<ul>
<li>데이터 전처리·간단한 추론은 Edge에서 수행</li>
<li>복잡한 연산만 클라우드/데이터센터에서 수행</li>
</ul>
</li>
<li>(장점) 네트워크 전송량 감소, 응답 속도 단축, 개인정보 보호 강화</li>
<li>(단점) Edge 디바이스 성능 한계, 분산 관리 복잡성</li>
<li>활용<ul>
<li>자율주행 차량: 객체 탐지/추적은 차량 내 NPU에서 처리, 대규모 맵 업데이트는 클라우드로 전송</li>
<li>스마트 팩토리: IoT 게이트웨이에서 실시간 데이터 필터링</li>
</ul>
</li>
</ul>
<hr />
<h2 id="4-serving-optimization">4. 서빙 최적화 (Serving Optimization)<a class="headerlink" href="#4-serving-optimization" title="Permanent link">&para;</a></h2>
<p>AI 시스템에서 서빙(Serving)은 학습된 모델을 실제 서비스 환경(API, 앱, 로봇, IoT 등)에 배포해 <strong>실시간 추론을 제공</strong>하는 과정이다.<br />
서빙 최적화는 배포 구조와 스케일링 전략을 효율적으로 운영하는 것이 핵심이다.  </p>
<h3 id="41-deployment-architecture">4.1 배포 구조 (Deployment Architecture)<a class="headerlink" href="#41-deployment-architecture" title="Permanent link">&para;</a></h3>
<ul>
<li>단일 모델 vs 멀티 모델 서빙  </li>
<li>
<p>1) 단일 모델 서빙 (Single-Model Serving)  </p>
<ul>
<li>(정의) 한 서버/엔진에서 하나의 모델만 로드해 서비스하는 방식  </li>
<li>(장점) 단순 구조, 관리 용이, Latency 최소화  </li>
<li>(단점) 다양한 모델 제공 불가, 확장성 한계  </li>
<li>(활용) 특정 업무(스팸 분류, 얼굴 인식 등) 전용 서비스  </li>
</ul>
</li>
<li>
<p>2) 멀티 모델 서빙 (Multi-Model Serving)  </p>
<ul>
<li>(정의) 하나의 서빙 엔진에서 여러 모델을 로드하고 요청에 따라 선택적으로 추론하는 방식  </li>
<li>(장점) 다양한 모델 유연 제공, 리소스 활용 효율화  </li>
<li>(단점) 메모리 사용량 증가, 모델 로딩/교체 시 Latency 발생  </li>
<li>(활용) 사용자 맞춤형 추천, 다국어 번역 서비스(언어별 모델 선택)  </li>
</ul>
</li>
<li>
<p>Ensemble 서빙 최적화 (Ensemble Serving Optimization)  </p>
</li>
<li>(정의) 여러 모델의 추론 결과를 결합해 최종 결과를 생성하는 방식  </li>
<li>(장점) 성능 향상, 일반화 능력 강화  </li>
<li>(단점) 연산 비용 증가, 응답 지연 가능  </li>
<li>(최적화 전략)  <ul>
<li>병렬 처리: 여러 모델 동시 추론 후 결합  </li>
<li>캐싱 활용: 동일 입력의 중간 결과 저장  </li>
<li>경량 모델 + Heavy 모델 혼합: 빠른 모델로 1차 필터링, 정밀 모델로 최종 판별  </li>
</ul>
</li>
<li>(활용) 금융 사기 탐지, 음성 인식(음향 모델 + 언어 모델 결합)  </li>
</ul>
<h3 id="42-scaling-optimization">4.2 스케일링 최적화 (Scaling Optimization)<a class="headerlink" href="#42-scaling-optimization" title="Permanent link">&para;</a></h3>
<ul>
<li>Auto-Scaling  </li>
<li>(정의) 요청량(트래픽)에 따라 서버/컨테이너 수를 자동으로 증감시키는 기법  </li>
<li>(장점) 자원 낭비 방지, 비용 최적화  </li>
<li>(단점) Scale-out 시 초기 지연 발생 가능  </li>
<li>
<p>(활용) Kubernetes HPA(Horizontal Pod Autoscaler), 클라우드 Auto-scaling 그룹  </p>
</li>
<li>
<p>GPU/CPU 혼합 서빙  </p>
</li>
<li>(정의) 연산량이 큰 작업은 GPU, 경량 작업은 CPU에 분산하는 방식  </li>
<li>(장점) 자원 활용 극대화, 비용 절감  </li>
<li>(단점) 워크로드 분배 전략 필요  </li>
<li>
<p>(활용) 실시간 LLM 추론에서 GPU + CPU 오프로딩  </p>
</li>
<li>
<p>캐싱 기반 최적화  </p>
</li>
<li>(정의) 반복 입력에 대한 추론 결과나 중간 결과를 캐싱 후 재사용하는 방식  </li>
<li>(장점) Latency 감소, Throughput 증가  </li>
<li>(단점) 캐시 메모리 관리 필요  </li>
<li>
<p>(활용) LLM KV-Cache, 추천시스템 상위 후보 재사용  </p>
</li>
<li>
<p>Multi-Region/Edge Deployment  </p>
</li>
<li>(정의) 사용자와 가까운 Region/Edge 서버에서 모델을 배포·서빙하는 방식  </li>
<li>(장점) 네트워크 지연 최소화, 안정성 확보  </li>
<li>(단점) 배포·관리 복잡성 증가  </li>
<li>(활용) 글로벌 서비스(번역, 음성비서), 로봇/IoT 현장 추론  </li>
</ul>
<h3 id="_1">요약 비교<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>구분</th>
<th>개념</th>
<th>장점</th>
<th>단점</th>
<th>대표 활용</th>
</tr>
</thead>
<tbody>
<tr>
<td>단일 모델 서빙</td>
<td>한 서버에서 하나의 모델 제공</td>
<td>단순, Latency 최소화</td>
<td>확장성 부족</td>
<td>전용 분류기</td>
</tr>
<tr>
<td>멀티 모델 서빙</td>
<td>여러 모델을 한 서버에서 선택 제공</td>
<td>유연성, 리소스 효율</td>
<td>메모리↑, 로딩 지연</td>
<td>추천, 번역</td>
</tr>
<tr>
<td>Ensemble 서빙</td>
<td>여러 모델 결과 결합</td>
<td>성능↑, 일반화↑</td>
<td>연산 비용↑, Latency↑</td>
<td>사기 탐지, 음성 인식</td>
</tr>
<tr>
<td>Auto-Scaling</td>
<td>트래픽에 따라 서버 증감</td>
<td>비용↓, 자원 효율↑</td>
<td>Scale-out 지연</td>
<td>클라우드 서빙</td>
</tr>
<tr>
<td>GPU/CPU 혼합</td>
<td>작업 특성별 분산</td>
<td>비용 절감, 자원 효율↑</td>
<td>워크로드 분배 난이도↑</td>
<td>대규모 LLM 추론</td>
</tr>
<tr>
<td>캐싱 기반 최적화</td>
<td>추론 결과 재사용</td>
<td>Latency↓, Throughput↑</td>
<td>캐시 관리 필요</td>
<td>KV-Cache, 추천</td>
</tr>
<tr>
<td>Multi-Region/Edge</td>
<td>지역·엣지 서버 활용</td>
<td>지연↓, 안정성↑</td>
<td>관리 복잡성↑</td>
<td>글로벌 서비스, IoT</td>
</tr>
</tbody>
</table>
<h3 id="44-data-pipeline-optimization">4.4 데이터 파이프라인 최적화 (Data Pipeline Optimization)<a class="headerlink" href="#44-data-pipeline-optimization" title="Permanent link">&para;</a></h3>
<ul>
<li>(정의) 데이터 수집, 전처리, 학습/추론, 저장으로 이어지는 전체 흐름에서 병목을 제거하고 효율성을 높이는 과정  </li>
<li>(장점) Latency 감소, Throughput 향상, 자원 활용 극대화, 비용 절감  </li>
<li>(단점) 초기 설계/구축 비용이 큼, 최적화된 파이프라인이 특정 워크로드에 종속될 수 있음  </li>
<li>(활용)  </li>
<li>분산 데이터 처리 프레임워크(Spark, Flink) 활용  </li>
<li>데이터 캐싱 및 스트리밍 처리 적용  </li>
<li>ETL(Extract-Transform-Load) 자동화  </li>
</ul>
<h3 id="43">4.3 지연 최소화<a class="headerlink" href="#43" title="Permanent link">&para;</a></h3>
<ul>
<li>배치 처리 (Batch Processing)  </li>
<li>(정의) 일정량의 요청을 모아 한 번에 처리하는 방식  </li>
<li>(장점) 처리 효율 증가, Throughput 향상, 네트워크 오버헤드 감소  </li>
<li>(단점) 개별 요청의 응답 지연 발생, 실시간성이 부족  </li>
<li>
<p>(활용) 대규모 로그 분석, 오프라인 추천 시스템, 모델 재학습 파이프라인  </p>
</li>
<li>
<p>실시간 처리 (Real-Time Processing)  </p>
</li>
<li>(정의) 요청이 들어오는 즉시 처리하는 방식  </li>
<li>(장점) 응답 지연 최소화, 사용자 경험 개선  </li>
<li>(단점) 자원 사용량 증가, 트래픽 폭주 시 안정성 저하 가능  </li>
<li>
<p>(활용) 챗봇 응답, 자율주행 차량 인식, 온라인 Fraud Detection  </p>
</li>
<li>
<p>비동기 처리 (Asynchronous Processing)  </p>
</li>
<li>(정의) 요청과 응답을 분리하여, 요청 즉시 수신 확인(ACK)을 보내고 실제 처리는 별도 프로세스에서 수행하는 방식  </li>
<li>(장점) 서버 부하 분산, 응답 속도 향상 (사용자는 기다리지 않음)  </li>
<li>(단점) 즉각적인 결과가 필요한 경우 부적합, 상태 관리 복잡성 증가  </li>
<li>(활용) 대용량 이미지/영상 처리, LLM API 호출(Streaming 응답), IoT 이벤트 처리  </li>
</ul>
<h3 id="_2">요약 포인트<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>단일 vs 멀티 모델 서빙</strong> → Latency 최소화 vs 유연성 확보  </li>
<li><strong>Ensemble 서빙</strong> → 성능↑ but 연산 비용↑  </li>
<li><strong>Auto-scaling</strong> → 비용 최적화, 트래픽 대응  </li>
<li><strong>GPU/CPU 혼합 서빙</strong> → 자원 활용 극대화  </li>
<li><strong>캐싱 기반 최적화</strong> → Latency↓, Throughput↑  </li>
<li><strong>Edge Deployment</strong> → 지연 최소화, 안정성↑  </li>
<li><strong>배치 처리</strong> → Throughput↑, 실시간성↓  </li>
<li><strong>실시간 처리</strong> → Latency↓, 자원↑  </li>
<li><strong>비동기 처리</strong> → 응답 속도↑, 상태 관리 복잡↑  </li>
</ul>
<hr />
<h2 id="5-monitoring-feedback-loop">5. 모니터링과 피드백 루프 (Monitoring &amp; Feedback Loop)<a class="headerlink" href="#5-monitoring-feedback-loop" title="Permanent link">&para;</a></h2>
<h3 id="51-performance-monitoring">5.1 성능 모니터링 (Performance Monitoring)<a class="headerlink" href="#51-performance-monitoring" title="Permanent link">&para;</a></h3>
<ul>
<li>(정의) 데이터 파이프라인과 모델 운영 과정에서 주요 성능 지표를 실시간으로 추적·분석하는 과정  </li>
<li>(장점) 성능 저하 조기 감지, 모델 품질 유지, 자원 효율성 확보  </li>
<li>(단점) 모니터링 인프라 구축 비용 및 운영 복잡성 증가  </li>
<li>(활용)  </li>
<li>Latency / Throughput 모니터링 → 응답 지연 및 처리량 확인  </li>
<li>CPU/GPU 사용량, 메모리 사용량 추적 → 자원 최적화 검증  </li>
<li>모델 정확도 변화 관찰 → 데이터/개념 드리프트 감지  </li>
</ul>
<hr />
<h3 id="52-auto-scaling">5.2 자동 스케일링 (Auto-Scaling)<a class="headerlink" href="#52-auto-scaling" title="Permanent link">&para;</a></h3>
<ul>
<li>(정의) 트래픽 변동 및 자원 사용량에 따라 서버/컨테이너 자원을 자동으로 확장 또는 축소하는 기법  </li>
<li>(장점) 트래픽 급증 대응, 비용 최적화, 무중단 운영 가능  </li>
<li>(단점) Scale-out 시 초기 지연 발생, 지나친 확장/축소로 불안정성 초래 가능  </li>
<li>(활용)  </li>
<li>수평 확장(Horizontal Scaling): 서버/컨테이너 개수를 늘려 처리량 증가  </li>
<li>수직 확장(Vertical Scaling): CPU/GPU/메모리 성능 업그레이드로 단일 자원 성능 강화  </li>
<li>Kubernetes HPA, 클라우드 Auto-scaling 그룹 적용  </li>
</ul>
<hr />
<hr />
<h2 id="6">6. 최적화 사례 연구<a class="headerlink" href="#6" title="Permanent link">&para;</a></h2>
<h3 id="61-llm">6.1 대규모 LLM 서빙 최적화 사례<a class="headerlink" href="#61-llm" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  수십억~수천억 파라미터를 가진 초거대 언어 모델(LLM)을 효율적으로 서빙하기 위한 최적화 기법.<br />
  대표적으로 KV-Cache, 프롬프트 캐싱, 멀티리전 배포, 스트리밍 응답 등을 활용한다.  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>KV-Cache 활용 → 과거 토큰 재계산 방지 → 토큰당 추론 속도 2~5배 향상  </li>
<li>스트리밍 응답 → 사용자는 결과를 점진적으로 받아 체감 지연 감소  </li>
<li>
<p>멀티 리전 배포 → 글로벌 사용자에게 낮은 네트워크 지연 제공  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>KV-Cache 관리 시 GPU 메모리 사용량이 증가  </li>
<li>멀티 리전 운영 시 인프라 관리 및 동기화 복잡성  </li>
<li>
<p>스트리밍 방식은 클라이언트/네트워크 프로토콜 지원 필요  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>ChatGPT·Claude·Gemini 등 LLM API 서비스  </li>
<li>대규모 고객 상담 챗봇, 다국어 번역 서비스  </li>
</ul>
<hr />
<h3 id="62">6.2 이미지 검색 서비스 최적화 사례<a class="headerlink" href="#62" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  이미지 특징 벡터(Embedding)를 활용한 대규모 검색 시스템을 빠르게 서비스하기 위한 최적화 기법.<br />
  벡터 DB, 캐싱, 단계적 검색(2-stage retrieval)을 적용한다.  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>오프라인 임베딩 캐싱 → 검색 시 실시간 연산 부담 감소  </li>
<li>2단계 검색(경량 필터링 → 정밀 모델) → Throughput 2배 이상 향상  </li>
<li>
<p>벡터DB(FAISS, Milvus) 활용 → 수백만 건 이상 이미지 검색 가능  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>임베딩 주기적 갱신 필요(데이터 신선도 관리)  </li>
<li>
<p>대규모 벡터 인덱스 관리 및 업데이트 비용 부담  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>전자상거래 상품 이미지 검색  </li>
<li>온라인 플랫폼(예: Pinterest, Instagram) 이미지 추천  </li>
</ul>
<hr />
<h3 id="63">6.3 실시간 음성 인식 시스템 최적화 사례<a class="headerlink" href="#63" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  사용자 음성을 실시간으로 받아 텍스트로 변환하는 과정에서 지연 최소화와 정확도 확보를 동시에 달성하는 최적화 기법.  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>Edge NPU에서 음향 특징 추출 및 1차 추론 → 클라우드 전송량 및 지연 감소  </li>
<li>클라우드 언어모델로 후처리 → 문맥 정확도 향상  </li>
<li>
<p>스트리밍 처리 → 사용자는 발화 중에도 텍스트 확인 가능  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>Edge 기기의 성능 한계로 복잡한 모델은 처리 불가  </li>
<li>
<p>네트워크 불안정 시 클라우드 단계 지연 발생  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>음성 비서(시리, 구글 어시스턴트)  </li>
<li>콜센터 자동 음성 인식(ASR)  </li>
<li>자율주행 차량 내 명령어 인식  </li>
</ul>
<hr />
<h2 id="7">7. 클라우드 환경에서의 최적화<a class="headerlink" href="#7" title="Permanent link">&para;</a></h2>
<h3 id="71">7.1 서버리스 서빙 구조<a class="headerlink" href="#71" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  서버 인프라를 직접 관리하지 않고, 요청 발생 시 함수 단위로 실행되는 <strong>서버리스(Serverless)</strong> 환경을 활용하는 구조. (예: AWS Lambda, GCP Cloud Functions)  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>요청 기반 실행 → 유휴 자원 비용 없음  </li>
<li>관리 포인트 최소화 → 빠른 개발/배포 가능  </li>
<li>
<p>소규모·비정기적 요청 처리에 적합  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>콜드 스타트(Cold Start)로 초기 지연 발생  </li>
<li>
<p>GPU 지원 제한적 (복잡한 AI 모델엔 부적합)  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>소규모 모델 추론 API  </li>
<li>이벤트 기반 AI 워크로드 (예: 이미지 분류, 간단한 챗봇 응답)  </li>
</ul>
<hr />
<h3 id="72-gpucpu">7.2 GPU/CPU 오토스케일링<a class="headerlink" href="#72-gpucpu" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  AI 워크로드 특성에 따라 GPU/CPU 자원을 자동 증감시키는 방식. GPU 전용 노드풀, CPU 전용 노드풀을 분리해 사용.  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>연산량 큰 모델은 GPU, 경량 작업은 CPU로 분산 → 비용 절감  </li>
<li>
<p>GPU 자원이 비쌀 때 효율적 활용 가능  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>워크로드 분배 전략 설계 필요  </li>
<li>
<p>GPU 인스턴스는 클라우드에서 가용성 제한 가능  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>LLM API 추론 (GPU + CPU 하이브리드 처리)  </li>
<li>이미지/영상 인코딩 + 경량 추천 모델 동시 운영  </li>
</ul>
<hr />
<h3 id="73">7.3 비용 기반 오토스케일링<a class="headerlink" href="#73" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  단순 트래픽 지표가 아니라 <strong>비용 최적화 목표</strong>를 기준으로 자동 확장/축소하는 방식.  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>클라우드 비용 초과 방지  </li>
<li>
<p>워크로드 특성과 SLA에 맞춘 운영 가능  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>비용 예측 모델 필요 (단순 사용량 기반이 아님)  </li>
<li>
<p>과도한 절감은 성능 저하 위험  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>예산 한정 AI 프로젝트  </li>
<li>비즈니스 KPI 기반 인프라 최적화  </li>
</ul>
<hr />
<h3 id="74">7.4 스팟 인스턴스 활용<a class="headerlink" href="#74" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>(정의)<br />
  클라우드 제공자가 남는 컴퓨팅 자원을 저렴한 가격에 제공하는 <strong>스팟 인스턴스(Spot Instance)</strong>를 활용하는 방식. (AWS Spot, GCP Preemptible VM 등)  </p>
</li>
<li>
<p>(장점)  </p>
</li>
<li>비용 최대 70~90% 절감 가능  </li>
<li>
<p>대규모 분산 학습 시 저비용 인프라 확보  </p>
</li>
<li>
<p>(단점)  </p>
</li>
<li>언제든 회수될 수 있음 (중단 가능성)  </li>
<li>
<p>실시간 추론·서비스에는 부적합  </p>
</li>
<li>
<p>(활용)  </p>
</li>
<li>대규모 학습/배치 처리  </li>
<li>Fault-tolerant 워크로드 (분산 학습, 데이터 전처리 파이프라인)  </li>
</ul>
<hr />
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "search.suggest", "search.highlight", "content.code.copy"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="../javascripts/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>